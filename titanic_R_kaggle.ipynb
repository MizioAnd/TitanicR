{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'merge_train_and_test_dataframe'"
      ],
      "text/latex": [
       "'merge\\_train\\_and\\_test\\_dataframe'"
      ],
      "text/markdown": [
       "'merge_train_and_test_dataframe'"
      ],
      "text/plain": [
       "[1] \"merge_train_and_test_dataframe\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'merge_train_and_test_dataframe'"
      ],
      "text/latex": [
       "'merge\\_train\\_and\\_test\\_dataframe'"
      ],
      "text/markdown": [
       "'merge_train_and_test_dataframe'"
      ],
      "text/plain": [
       "[1] \"merge_train_and_test_dataframe\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'drop_variable_before_preparation'"
      ],
      "text/latex": [
       "'drop\\_variable\\_before\\_preparation'"
      ],
      "text/markdown": [
       "'drop_variable_before_preparation'"
      ],
      "text/plain": [
       "[1] \"drop_variable_before_preparation\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'drop_variable_before_preparation'"
      ],
      "text/latex": [
       "'drop\\_variable\\_before\\_preparation'"
      ],
      "text/markdown": [
       "'drop_variable_before_preparation'"
      ],
      "text/plain": [
       "[1] \"drop_variable_before_preparation\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'clean_data'"
      ],
      "text/latex": [
       "'clean\\_data'"
      ],
      "text/markdown": [
       "'clean_data'"
      ],
      "text/plain": [
       "[1] \"clean_data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'clean_data'"
      ],
      "text/latex": [
       "'clean\\_data'"
      ],
      "text/markdown": [
       "'clean_data'"
      ],
      "text/plain": [
       "[1] \"clean_data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'numerical_feature_logical_incl_hidden_num'"
      ],
      "text/latex": [
       "'numerical\\_feature\\_logical\\_incl\\_hidden\\_num'"
      ],
      "text/markdown": [
       "'numerical_feature_logical_incl_hidden_num'"
      ],
      "text/plain": [
       "[1] \"numerical_feature_logical_incl_hidden_num\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'numerical_feature_logical_incl_hidden_num'"
      ],
      "text/latex": [
       "'numerical\\_feature\\_logical\\_incl\\_hidden\\_num'"
      ],
      "text/markdown": [
       "'numerical_feature_logical_incl_hidden_num'"
      ],
      "text/plain": [
       "[1] \"numerical_feature_logical_incl_hidden_num\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'numerical_feature_logical'"
      ],
      "text/latex": [
       "'numerical\\_feature\\_logical'"
      ],
      "text/markdown": [
       "'numerical_feature_logical'"
      ],
      "text/plain": [
       "[1] \"numerical_feature_logical\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'numerical_feature_logical'"
      ],
      "text/latex": [
       "'numerical\\_feature\\_logical'"
      ],
      "text/markdown": [
       "'numerical_feature_logical'"
      ],
      "text/plain": [
       "[1] \"numerical_feature_logical\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'extract_numerical_features'"
      ],
      "text/latex": [
       "'extract\\_numerical\\_features'"
      ],
      "text/markdown": [
       "'extract_numerical_features'"
      ],
      "text/plain": [
       "[1] \"extract_numerical_features\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'extract_numerical_features'"
      ],
      "text/latex": [
       "'extract\\_numerical\\_features'"
      ],
      "text/markdown": [
       "'extract_numerical_features'"
      ],
      "text/plain": [
       "[1] \"extract_numerical_features\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'extract_non_numerical_features'"
      ],
      "text/latex": [
       "'extract\\_non\\_numerical\\_features'"
      ],
      "text/markdown": [
       "'extract_non_numerical_features'"
      ],
      "text/plain": [
       "[1] \"extract_non_numerical_features\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'extract_non_numerical_features'"
      ],
      "text/latex": [
       "'extract\\_non\\_numerical\\_features'"
      ],
      "text/markdown": [
       "'extract_non_numerical_features'"
      ],
      "text/plain": [
       "[1] \"extract_non_numerical_features\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'encode_labels_in_numeric_format'"
      ],
      "text/latex": [
       "'encode\\_labels\\_in\\_numeric\\_format'"
      ],
      "text/markdown": [
       "'encode_labels_in_numeric_format'"
      ],
      "text/plain": [
       "[1] \"encode_labels_in_numeric_format\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'encode_labels_in_numeric_format'"
      ],
      "text/latex": [
       "'encode\\_labels\\_in\\_numeric\\_format'"
      ],
      "text/markdown": [
       "'encode_labels_in_numeric_format'"
      ],
      "text/plain": [
       "[1] \"encode_labels_in_numeric_format\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'one_hot_encoder'"
      ],
      "text/latex": [
       "'one\\_hot\\_encoder'"
      ],
      "text/markdown": [
       "'one_hot_encoder'"
      ],
      "text/plain": [
       "[1] \"one_hot_encoder\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'one_hot_encoder'"
      ],
      "text/latex": [
       "'one\\_hot\\_encoder'"
      ],
      "text/markdown": [
       "'one_hot_encoder'"
      ],
      "text/plain": [
       "[1] \"one_hot_encoder\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_mapping_to_numerical_values'"
      ],
      "text/latex": [
       "'feature\\_mapping\\_to\\_numerical\\_values'"
      ],
      "text/markdown": [
       "'feature_mapping_to_numerical_values'"
      ],
      "text/plain": [
       "[1] \"feature_mapping_to_numerical_values\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_mapping_to_numerical_values'"
      ],
      "text/latex": [
       "'feature\\_mapping\\_to\\_numerical\\_values'"
      ],
      "text/markdown": [
       "'feature_mapping_to_numerical_values'"
      ],
      "text/plain": [
       "[1] \"feature_mapping_to_numerical_values\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_names_num_drop'"
      ],
      "text/latex": [
       "'feature\\_names\\_num\\_drop'"
      ],
      "text/markdown": [
       "'feature_names_num_drop'"
      ],
      "text/plain": [
       "[1] \"feature_names_num_drop\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_names_num_drop'"
      ],
      "text/latex": [
       "'feature\\_names\\_num\\_drop'"
      ],
      "text/markdown": [
       "'feature_names_num_drop'"
      ],
      "text/plain": [
       "[1] \"feature_names_num_drop\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_names_num'"
      ],
      "text/latex": [
       "'feature\\_names\\_num'"
      ],
      "text/markdown": [
       "'feature_names_num'"
      ],
      "text/plain": [
       "[1] \"feature_names_num\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_names_num'"
      ],
      "text/latex": [
       "'feature\\_names\\_num'"
      ],
      "text/markdown": [
       "'feature_names_num'"
      ],
      "text/plain": [
       "[1] \"feature_names_num\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'drop_features_num'"
      ],
      "text/latex": [
       "'drop\\_features\\_num'"
      ],
      "text/markdown": [
       "'drop_features_num'"
      ],
      "text/plain": [
       "[1] \"drop_features_num\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'drop_features_num'"
      ],
      "text/latex": [
       "'drop\\_features\\_num'"
      ],
      "text/markdown": [
       "'drop_features_num'"
      ],
      "text/plain": [
       "[1] \"drop_features_num\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'get_is_one_hot_encoder'"
      ],
      "text/latex": [
       "'get\\_is\\_one\\_hot\\_encoder'"
      ],
      "text/markdown": [
       "'get_is_one_hot_encoder'"
      ],
      "text/plain": [
       "[1] \"get_is_one_hot_encoder\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'get_is_one_hot_encoder'"
      ],
      "text/latex": [
       "'get\\_is\\_one\\_hot\\_encoder'"
      ],
      "text/markdown": [
       "'get_is_one_hot_encoder'"
      ],
      "text/plain": [
       "[1] \"get_is_one_hot_encoder\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'set_is_one_hot_encoder'"
      ],
      "text/latex": [
       "'set\\_is\\_one\\_hot\\_encoder'"
      ],
      "text/markdown": [
       "'set_is_one_hot_encoder'"
      ],
      "text/plain": [
       "[1] \"set_is_one_hot_encoder\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'set_is_one_hot_encoder'"
      ],
      "text/latex": [
       "'set\\_is\\_one\\_hot\\_encoder'"
      ],
      "text/markdown": [
       "'set_is_one_hot_encoder'"
      ],
      "text/plain": [
       "[1] \"set_is_one_hot_encoder\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'skew_correction'"
      ],
      "text/latex": [
       "'skew\\_correction'"
      ],
      "text/markdown": [
       "'skew_correction'"
      ],
      "text/plain": [
       "[1] \"skew_correction\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'skew_correction'"
      ],
      "text/latex": [
       "'skew\\_correction'"
      ],
      "text/markdown": [
       "'skew_correction'"
      ],
      "text/plain": [
       "[1] \"skew_correction\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'skew_correction'"
      ],
      "text/latex": [
       "'skew\\_correction'"
      ],
      "text/markdown": [
       "'skew_correction'"
      ],
      "text/plain": [
       "[1] \"skew_correction\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_engineering'"
      ],
      "text/latex": [
       "'feature\\_engineering'"
      ],
      "text/markdown": [
       "'feature_engineering'"
      ],
      "text/plain": [
       "[1] \"feature_engineering\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_engineering'"
      ],
      "text/latex": [
       "'feature\\_engineering'"
      ],
      "text/markdown": [
       "'feature_engineering'"
      ],
      "text/plain": [
       "[1] \"feature_engineering\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_scaling'"
      ],
      "text/latex": [
       "'feature\\_scaling'"
      ],
      "text/markdown": [
       "'feature_scaling'"
      ],
      "text/plain": [
       "[1] \"feature_scaling\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'feature_scaling'"
      ],
      "text/latex": [
       "'feature\\_scaling'"
      ],
      "text/markdown": [
       "'feature_scaling'"
      ],
      "text/plain": [
       "[1] \"feature_scaling\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'plot_histogram'"
      ],
      "text/latex": [
       "'plot\\_histogram'"
      ],
      "text/markdown": [
       "'plot_histogram'"
      ],
      "text/plain": [
       "[1] \"plot_histogram\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'plot_histogram'"
      ],
      "text/latex": [
       "'plot\\_histogram'"
      ],
      "text/markdown": [
       "'plot_histogram'"
      ],
      "text/plain": [
       "[1] \"plot_histogram\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'plot_function'"
      ],
      "text/latex": [
       "'plot\\_function'"
      ],
      "text/markdown": [
       "'plot_function'"
      ],
      "text/plain": [
       "[1] \"plot_function\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'plot_function'"
      ],
      "text/latex": [
       "'plot\\_function'"
      ],
      "text/markdown": [
       "'plot_function'"
      ],
      "text/plain": [
       "[1] \"plot_function\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'plot_density'"
      ],
      "text/latex": [
       "'plot\\_density'"
      ],
      "text/markdown": [
       "'plot_density'"
      ],
      "text/plain": [
       "[1] \"plot_density\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'plot_density'"
      ],
      "text/latex": [
       "'plot\\_density'"
      ],
      "text/markdown": [
       "'plot_density'"
      ],
      "text/plain": [
       "[1] \"plot_density\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'extract_numerical_value_from_character'"
      ],
      "text/latex": [
       "'extract\\_numerical\\_value\\_from\\_character'"
      ],
      "text/markdown": [
       "'extract_numerical_value_from_character'"
      ],
      "text/plain": [
       "[1] \"extract_numerical_value_from_character\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'extract_numerical_value_from_character'"
      ],
      "text/latex": [
       "'extract\\_numerical\\_value\\_from\\_character'"
      ],
      "text/markdown": [
       "'extract_numerical_value_from_character'"
      ],
      "text/plain": [
       "[1] \"extract_numerical_value_from_character\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'drop_features'"
      ],
      "text/latex": [
       "'drop\\_features'"
      ],
      "text/markdown": [
       "'drop_features'"
      ],
      "text/plain": [
       "[1] \"drop_features\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'drop_features'"
      ],
      "text/latex": [
       "'drop\\_features'"
      ],
      "text/markdown": [
       "'drop_features'"
      ],
      "text/plain": [
       "[1] \"drop_features\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'prepare_data'"
      ],
      "text/latex": [
       "'prepare\\_data'"
      ],
      "text/markdown": [
       "'prepare_data'"
      ],
      "text/plain": [
       "[1] \"prepare_data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'prepare_data'"
      ],
      "text/latex": [
       "'prepare\\_data'"
      ],
      "text/markdown": [
       "'prepare_data'"
      ],
      "text/plain": [
       "[1] \"prepare_data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " iter imp variable\n",
      "  1   1  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  1   2  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  1   3  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  1   4  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  1   5  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  2   1  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  2   2  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  2   3  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  2   4  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  2   5  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  3   1  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  3   2  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  3   3  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  3   4  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  3   5  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  4   1  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  4   2  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  4   3  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  4   4  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  4   5  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  5   1  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  5   2  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  5   3  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  5   4  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "  5   5  Age  Fare  EmbarkedC  EmbarkedQ  EmbarkedS\n",
      "\n",
      " iter imp variable\n",
      "  1   1  Age  Fare\n",
      "  1   2  Age  Fare\n",
      "  1   3  Age  Fare\n",
      "  1   4  Age  Fare\n",
      "  1   5  Age  Fare\n",
      "  2   1  Age  Fare\n",
      "  2   2  Age  Fare\n",
      "  2   3  Age  Fare\n",
      "  2   4  Age  Fare\n",
      "  2   5  Age  Fare\n",
      "  3   1  Age  Fare\n",
      "  3   2  Age  Fare\n",
      "  3   3  Age  Fare\n",
      "  3   4  Age  Fare\n",
      "  3   5  Age  Fare\n",
      "  4   1  Age  Fare\n",
      "  4   2  Age  Fare\n",
      "  4   3  Age  Fare\n",
      "  4   4  Age  Fare\n",
      "  4   5  Age  Fare\n",
      "  5   1  Age  Fare\n",
      "  5   2  Age  Fare\n",
      "  5   3  Age  Fare\n",
      "  5   4  Age  Fare\n",
      "  5   5  Age  Fare\n",
      "            sort(sapply(train_test_merged, function(x) sum(is.na(x))), decreasing = TRUE)\n",
      "Age                                                                                   263\n",
      "Fare                                                                                    1\n",
      "PassengerId                                                                             0\n",
      "Pclass                                                                                  0\n",
      "Name                                                                                    0\n",
      "Sex                                                                                     0\n",
      "SibSp                                                                                   0\n",
      "Parch                                                                                   0\n",
      "Ticket                                                                                  0\n",
      "Cabin                                                                                   0\n",
      "Embarked                                                                                0\n",
      "'data.frame':\t1309 obs. of  11 variables:\n",
      " $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...\n",
      " $ Name       : chr  \"Braund, Mr. Owen Harris\" \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" \"Heikkinen, Miss. Laina\" \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" ...\n",
      " $ Sex        : chr  \"male\" \"female\" \"female\" \"female\" ...\n",
      " $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...\n",
      " $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...\n",
      " $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...\n",
      " $ Ticket     : chr  \"A/5 21171\" \"PC 17599\" \"STON/O2. 3101282\" \"113803\" ...\n",
      " $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...\n",
      " $ Cabin      : chr  \"\" \"C85\" \"\" \"C123\" ...\n",
      " $ Embarked   : chr  \"S\" \"C\" \"S\" \"S\" ...\n",
      "   colnames(train_test_merged)\n",
      "1                  PassengerId\n",
      "2                       Pclass\n",
      "3                         Name\n",
      "4                          Sex\n",
      "5                          Age\n",
      "6                        SibSp\n",
      "7                        Parch\n",
      "8                       Ticket\n",
      "9                         Fare\n",
      "10                       Cabin\n",
      "11                    Embarked\n",
      "[1] \"After preperation =================\"\n",
      "   colnames(train_test_merged_prepared)\n",
      "1                                   Age\n",
      "2                                  Fare\n",
      "3                                SexNum\n",
      "4                             EmbarkedC\n",
      "5                             EmbarkedQ\n",
      "6                             EmbarkedS\n",
      "7                               Pclass1\n",
      "8                               Pclass2\n",
      "9                               Pclass3\n",
      "10                               SibSp0\n",
      "11                               SibSp1\n",
      "12                               SibSp2\n",
      "13                               SibSp3\n",
      "14                               SibSp4\n",
      "15                               SibSp5\n",
      "16                               SibSp8\n",
      "17                               Parch0\n",
      "18                               Parch1\n",
      "19                               Parch2\n",
      "20                               Parch3\n",
      "21                               Parch4\n",
      "22                               Parch5\n",
      "23                               Parch6\n",
      "24                               Parch9\n",
      "Train has 891 rows and 12 columns. \n",
      "Test has 418 rows and 11  columns.The percentage of data missing in train 0.01655443 \n",
      "The percentage of data missing in test 0.01892127 \n",
      "The number of row duplicates: 0 \n",
      "[1]\ttrain-error:0.334178+0.027318\ttest-error:0.344592+0.026189 \n",
      "Multiple eval metrics are present. Will use test_error for early stopping.\n",
      "Will train until test_error hasn't improved in 250 rounds.\n",
      "\n",
      "[2]\ttrain-error:0.255593+0.051930\ttest-error:0.287364+0.056538 \n",
      "[3]\ttrain-error:0.252506+0.059669\ttest-error:0.296353+0.063320 \n",
      "[4]\ttrain-error:0.239618+0.029861\ttest-error:0.276122+0.048129 \n",
      "[5]\ttrain-error:0.233443+0.025754\ttest-error:0.282845+0.045817 \n",
      "[6]\ttrain-error:0.233448+0.023735\ttest-error:0.272739+0.047809 \n",
      "[7]\ttrain-error:0.232890+0.021488\ttest-error:0.274980+0.041022 \n",
      "[8]\ttrain-error:0.227002+0.023781\ttest-error:0.255866+0.041951 \n",
      "[9]\ttrain-error:0.223913+0.023224\ttest-error:0.268219+0.040593 \n",
      "[10]\ttrain-error:0.222230+0.021155\ttest-error:0.251403+0.024456 \n",
      "[11]\ttrain-error:0.212127+0.022473\ttest-error:0.245791+0.040101 \n",
      "[12]\ttrain-error:0.208475+0.018508\ttest-error:0.241309+0.035399 \n",
      "[13]\ttrain-error:0.201180+0.021607\ttest-error:0.231203+0.028083 \n",
      "[14]\ttrain-error:0.201742+0.022007\ttest-error:0.231203+0.020860 \n",
      "[15]\ttrain-error:0.202018+0.018565\ttest-error:0.234574+0.021789 \n",
      "[16]\ttrain-error:0.200053+0.018240\ttest-error:0.226715+0.021528 \n",
      "[17]\ttrain-error:0.200335+0.016634\ttest-error:0.228956+0.025468 \n",
      "[18]\ttrain-error:0.205105+0.018707\ttest-error:0.226715+0.020321 \n",
      "[19]\ttrain-error:0.203140+0.018353\ttest-error:0.237939+0.019369 \n",
      "[20]\ttrain-error:0.205384+0.020169\ttest-error:0.233457+0.023021 \n",
      "[21]\ttrain-error:0.207628+0.020131\ttest-error:0.233463+0.025668 \n",
      "[22]\ttrain-error:0.210717+0.019485\ttest-error:0.233450+0.027003 \n",
      "[23]\ttrain-error:0.207349+0.018826\ttest-error:0.232308+0.022747 \n",
      "[24]\ttrain-error:0.206228+0.017486\ttest-error:0.228943+0.024845 \n",
      "[25]\ttrain-error:0.206791+0.016379\ttest-error:0.232314+0.026646 \n",
      "[26]\ttrain-error:0.205949+0.014479\ttest-error:0.237926+0.018541 \n",
      "[27]\ttrain-error:0.207353+0.017743\ttest-error:0.233432+0.020729 \n",
      "[28]\ttrain-error:0.206509+0.017943\ttest-error:0.233438+0.020189 \n",
      "[29]\ttrain-error:0.210718+0.019131\ttest-error:0.234549+0.019980 \n",
      "[30]\ttrain-error:0.208193+0.018142\ttest-error:0.233425+0.019710 \n",
      "[31]\ttrain-error:0.207915+0.015829\ttest-error:0.227814+0.021842 \n",
      "[32]\ttrain-error:0.206795+0.016864\ttest-error:0.228931+0.022009 \n",
      "[33]\ttrain-error:0.207076+0.018090\ttest-error:0.233413+0.024671 \n",
      "[34]\ttrain-error:0.209040+0.017177\ttest-error:0.233406+0.025353 \n",
      "[35]\ttrain-error:0.207915+0.014162\ttest-error:0.235666+0.020099 \n",
      "[36]\ttrain-error:0.207915+0.015432\ttest-error:0.237913+0.022945 \n",
      "[37]\ttrain-error:0.208758+0.015824\ttest-error:0.234543+0.022003 \n",
      "[38]\ttrain-error:0.208478+0.016234\ttest-error:0.240154+0.021415 \n",
      "[39]\ttrain-error:0.208198+0.015780\ttest-error:0.241278+0.023021 \n",
      "[40]\ttrain-error:0.204550+0.014793\ttest-error:0.237907+0.022590 \n",
      "[41]\ttrain-error:0.201181+0.009709\ttest-error:0.231178+0.018623 \n",
      "[42]\ttrain-error:0.201743+0.009854\ttest-error:0.230042+0.022033 \n",
      "[43]\ttrain-error:0.204269+0.009904\ttest-error:0.225554+0.021884 \n",
      "[44]\ttrain-error:0.203988+0.012914\ttest-error:0.226671+0.021582 \n",
      "[45]\ttrain-error:0.202025+0.012495\ttest-error:0.225560+0.020168 \n",
      "[46]\ttrain-error:0.201184+0.014484\ttest-error:0.219942+0.023827 \n",
      "[47]\ttrain-error:0.200624+0.015708\ttest-error:0.219942+0.022180 \n",
      "[48]\ttrain-error:0.199221+0.014153\ttest-error:0.222183+0.024354 \n",
      "[49]\ttrain-error:0.195574+0.016707\ttest-error:0.223307+0.026070 \n",
      "[50]\ttrain-error:0.195013+0.017108\ttest-error:0.225548+0.022652 \n",
      "[51]\ttrain-error:0.191928+0.020157\ttest-error:0.218806+0.030134 \n",
      "[52]\ttrain-error:0.193611+0.019695\ttest-error:0.218806+0.028630 \n",
      "[53]\ttrain-error:0.193050+0.019054\ttest-error:0.212064+0.030361 \n",
      "[54]\ttrain-error:0.194172+0.018377\ttest-error:0.216559+0.026452 \n",
      "[55]\ttrain-error:0.193331+0.019356\ttest-error:0.216559+0.026452 \n",
      "[56]\ttrain-error:0.194171+0.018021\ttest-error:0.217689+0.024508 \n",
      "[57]\ttrain-error:0.194172+0.017960\ttest-error:0.217689+0.023455 \n",
      "[58]\ttrain-error:0.196416+0.018081\ttest-error:0.218812+0.022254 \n",
      "[59]\ttrain-error:0.193891+0.018518\ttest-error:0.224430+0.019937 \n",
      "[60]\ttrain-error:0.194733+0.018285\ttest-error:0.221059+0.019439 \n",
      "[61]\ttrain-error:0.196416+0.015694\ttest-error:0.221059+0.021000 \n",
      "[62]\ttrain-error:0.193889+0.014799\ttest-error:0.219936+0.021223 \n",
      "[63]\ttrain-error:0.191924+0.013149\ttest-error:0.217701+0.016721 \n",
      "[64]\ttrain-error:0.192483+0.011894\ttest-error:0.217707+0.014827 \n",
      "[65]\ttrain-error:0.191923+0.012269\ttest-error:0.219955+0.014437 \n",
      "[66]\ttrain-error:0.192203+0.012255\ttest-error:0.221078+0.016188 \n",
      "[67]\ttrain-error:0.192765+0.010965\ttest-error:0.222196+0.014452 \n",
      "[68]\ttrain-error:0.189960+0.012065\ttest-error:0.219942+0.021603 \n",
      "[69]\ttrain-error:0.185189+0.011064\ttest-error:0.215467+0.016581 \n",
      "[70]\ttrain-error:0.186871+0.008707\ttest-error:0.214337+0.018211 \n",
      "[71]\ttrain-error:0.187714+0.009799\ttest-error:0.218831+0.016689 \n",
      "[72]\ttrain-error:0.188275+0.009045\ttest-error:0.214337+0.020184 \n",
      "[73]\ttrain-error:0.189117+0.010038\ttest-error:0.221066+0.018874 \n",
      "[74]\ttrain-error:0.188556+0.011853\ttest-error:0.219936+0.022382 \n",
      "[75]\ttrain-error:0.187994+0.008976\ttest-error:0.221072+0.015280 \n",
      "[76]\ttrain-error:0.187995+0.010231\ttest-error:0.219948+0.015987 \n",
      "[77]\ttrain-error:0.187434+0.009583\ttest-error:0.216578+0.021406 \n",
      "[78]\ttrain-error:0.187434+0.010514\ttest-error:0.215454+0.020488 \n",
      "[79]\ttrain-error:0.186030+0.009230\ttest-error:0.215460+0.017593 \n",
      "[80]\ttrain-error:0.186029+0.007807\ttest-error:0.213213+0.018055 \n",
      "[81]\ttrain-error:0.185467+0.008039\ttest-error:0.215460+0.017949 \n",
      "[82]\ttrain-error:0.184625+0.007155\ttest-error:0.214337+0.018892 \n",
      "[83]\ttrain-error:0.184064+0.008697\ttest-error:0.221078+0.014105 \n",
      "[84]\ttrain-error:0.183503+0.009480\ttest-error:0.218831+0.016689 \n",
      "[85]\ttrain-error:0.182943+0.007958\ttest-error:0.214337+0.021399 \n",
      "[86]\ttrain-error:0.180695+0.008793\ttest-error:0.215467+0.019389 \n",
      "[87]\ttrain-error:0.181259+0.008560\ttest-error:0.214337+0.021399 \n",
      "[88]\ttrain-error:0.180134+0.007546\ttest-error:0.215473+0.015085 \n",
      "[89]\ttrain-error:0.180415+0.008048\ttest-error:0.214349+0.015398 \n",
      "[90]\ttrain-error:0.180134+0.006093\ttest-error:0.212108+0.017381 \n",
      "[91]\ttrain-error:0.179572+0.007114\ttest-error:0.213232+0.015313 \n",
      "[92]\ttrain-error:0.179572+0.007049\ttest-error:0.213238+0.010541 \n",
      "[93]\ttrain-error:0.179290+0.007789\ttest-error:0.209867+0.014332 \n",
      "[94]\ttrain-error:0.178727+0.009701\ttest-error:0.209867+0.015187 \n",
      "[95]\ttrain-error:0.176763+0.010611\ttest-error:0.210991+0.016014 \n",
      "[96]\ttrain-error:0.177606+0.010237\ttest-error:0.210991+0.014785 \n",
      "[97]\ttrain-error:0.177324+0.012183\ttest-error:0.214356+0.015495 \n",
      "[98]\ttrain-error:0.176482+0.012708\ttest-error:0.210985+0.017795 \n",
      "[99]\ttrain-error:0.175641+0.009208\ttest-error:0.209867+0.017140 \n",
      "[100]\ttrain-error:0.175921+0.010105\ttest-error:0.210985+0.017795 \n",
      "[101]\ttrain-error:0.174518+0.010445\ttest-error:0.208738+0.016203 \n",
      "[102]\ttrain-error:0.173676+0.009612\ttest-error:0.210985+0.013334 \n",
      "[103]\ttrain-error:0.171993+0.008994\ttest-error:0.209861+0.014667 \n",
      "[104]\ttrain-error:0.172274+0.008495\ttest-error:0.209861+0.015906 \n",
      "[105]\ttrain-error:0.171151+0.009268\ttest-error:0.207614+0.018239 \n",
      "[106]\ttrain-error:0.170870+0.012010\ttest-error:0.212102+0.015360 \n",
      "[107]\ttrain-error:0.171431+0.011369\ttest-error:0.214349+0.014555 \n",
      "[108]\ttrain-error:0.169187+0.009422\ttest-error:0.212102+0.015360 \n",
      "[109]\ttrain-error:0.167223+0.010328\ttest-error:0.210985+0.015522 \n",
      "[110]\ttrain-error:0.168346+0.009354\ttest-error:0.207620+0.014469 \n",
      "[111]\ttrain-error:0.168907+0.009584\ttest-error:0.210985+0.014250 \n",
      "[112]\ttrain-error:0.169187+0.009291\ttest-error:0.208738+0.016203 \n",
      "[113]\ttrain-error:0.169748+0.008878\ttest-error:0.207608+0.016705 \n",
      "[114]\ttrain-error:0.169468+0.009419\ttest-error:0.208731+0.017605 \n",
      "[115]\ttrain-error:0.168346+0.008390\ttest-error:0.207614+0.016418 \n",
      "[116]\ttrain-error:0.167785+0.008742\ttest-error:0.205367+0.015016 \n",
      "[117]\ttrain-error:0.167224+0.008639\ttest-error:0.206490+0.014081 \n",
      "[118]\ttrain-error:0.168067+0.007325\ttest-error:0.208738+0.011674 \n",
      "[119]\ttrain-error:0.168066+0.008687\ttest-error:0.207614+0.013460 \n",
      "[120]\ttrain-error:0.167224+0.009334\ttest-error:0.208738+0.013197 \n",
      "[121]\ttrain-error:0.169468+0.009787\ttest-error:0.208738+0.013197 \n",
      "[122]\ttrain-error:0.168346+0.009845\ttest-error:0.209861+0.011258 \n",
      "[123]\ttrain-error:0.169187+0.010484\ttest-error:0.210985+0.011283 \n",
      "[124]\ttrain-error:0.168627+0.009290\ttest-error:0.208738+0.013197 \n",
      "[125]\ttrain-error:0.168346+0.009359\ttest-error:0.209861+0.014230 \n",
      "[126]\ttrain-error:0.169749+0.010761\ttest-error:0.208738+0.016203 \n",
      "[127]\ttrain-error:0.169468+0.010917\ttest-error:0.209861+0.016298 \n",
      "[128]\ttrain-error:0.168627+0.010063\ttest-error:0.208738+0.018392 \n",
      "[129]\ttrain-error:0.169468+0.010405\ttest-error:0.210985+0.014250 \n",
      "[130]\ttrain-error:0.167504+0.009753\ttest-error:0.210985+0.014250 \n",
      "[131]\ttrain-error:0.164418+0.009867\ttest-error:0.210985+0.014250 \n",
      "[132]\ttrain-error:0.165259+0.009581\ttest-error:0.209861+0.013313 \n",
      "[133]\ttrain-error:0.164417+0.009035\ttest-error:0.207614+0.017533 \n",
      "[134]\ttrain-error:0.165821+0.009792\ttest-error:0.207614+0.017533 \n",
      "[135]\ttrain-error:0.164979+0.010539\ttest-error:0.209861+0.011258 \n",
      "[136]\ttrain-error:0.163296+0.008967\ttest-error:0.210985+0.009457 \n",
      "[137]\ttrain-error:0.164138+0.009367\ttest-error:0.209861+0.011258 \n",
      "[138]\ttrain-error:0.164980+0.009188\ttest-error:0.209861+0.011258 \n",
      "[139]\ttrain-error:0.165260+0.009178\ttest-error:0.208738+0.011674 \n",
      "[140]\ttrain-error:0.164419+0.008959\ttest-error:0.212108+0.007888 \n",
      "[141]\ttrain-error:0.164138+0.009367\ttest-error:0.210985+0.009457 \n",
      "[142]\ttrain-error:0.162455+0.008379\ttest-error:0.209861+0.011258 \n",
      "[143]\ttrain-error:0.162735+0.008492\ttest-error:0.208738+0.013197 \n",
      "[144]\ttrain-error:0.162735+0.009368\ttest-error:0.209861+0.011258 \n",
      "[145]\ttrain-error:0.162735+0.008538\ttest-error:0.209861+0.011258 \n",
      "[146]\ttrain-error:0.163296+0.008879\ttest-error:0.210985+0.009457 \n",
      "[147]\ttrain-error:0.162173+0.009390\ttest-error:0.209861+0.011258 \n",
      "[148]\ttrain-error:0.162454+0.008950\ttest-error:0.214362+0.006400 \n",
      "[149]\ttrain-error:0.162735+0.007664\ttest-error:0.213238+0.008558 \n",
      "[150]\ttrain-error:0.162735+0.007140\ttest-error:0.209867+0.010218 \n",
      "[151]\ttrain-error:0.162455+0.007005\ttest-error:0.209867+0.010218 \n",
      "[152]\ttrain-error:0.161613+0.007843\ttest-error:0.208744+0.010067 \n",
      "[153]\ttrain-error:0.162735+0.007723\ttest-error:0.209867+0.012944 \n",
      "[154]\ttrain-error:0.164138+0.007873\ttest-error:0.207620+0.014469 \n",
      "[155]\ttrain-error:0.162736+0.007211\ttest-error:0.205379+0.013446 \n",
      "[156]\ttrain-error:0.162736+0.006643\ttest-error:0.206503+0.011327 \n",
      "[157]\ttrain-error:0.161895+0.006565\ttest-error:0.206503+0.011327 \n",
      "[158]\ttrain-error:0.162736+0.006760\ttest-error:0.209874+0.009725 \n",
      "[159]\ttrain-error:0.164139+0.007980\ttest-error:0.209874+0.007529 \n",
      "[160]\ttrain-error:0.164138+0.008119\ttest-error:0.208750+0.009566 \n",
      "[161]\ttrain-error:0.163857+0.008962\ttest-error:0.207626+0.005952 \n",
      "[162]\ttrain-error:0.162736+0.006515\ttest-error:0.208750+0.006404 \n",
      "[163]\ttrain-error:0.162736+0.007523\ttest-error:0.209874+0.004338 \n",
      "[164]\ttrain-error:0.162455+0.007546\ttest-error:0.208750+0.003970 \n",
      "[165]\ttrain-error:0.161894+0.007801\ttest-error:0.209874+0.005607 \n",
      "[166]\ttrain-error:0.162175+0.006257\ttest-error:0.208750+0.006404 \n",
      "[167]\ttrain-error:0.159931+0.005775\ttest-error:0.207626+0.007789 \n",
      "[168]\ttrain-error:0.158809+0.005451\ttest-error:0.208750+0.006404 \n",
      "[169]\ttrain-error:0.159090+0.005339\ttest-error:0.207626+0.007789 \n",
      "[170]\ttrain-error:0.158247+0.005658\ttest-error:0.210997+0.005655 \n",
      "[171]\ttrain-error:0.158528+0.005049\ttest-error:0.208750+0.007323 \n",
      "[172]\ttrain-error:0.157967+0.004699\ttest-error:0.208744+0.007130 \n",
      "[173]\ttrain-error:0.158247+0.005929\ttest-error:0.210997+0.004399 \n",
      "[174]\ttrain-error:0.158808+0.004909\ttest-error:0.210991+0.008191 \n",
      "[175]\ttrain-error:0.159369+0.005732\ttest-error:0.209874+0.007529 \n",
      "[176]\ttrain-error:0.159089+0.006196\ttest-error:0.209867+0.005354 \n",
      "[177]\ttrain-error:0.158247+0.006116\ttest-error:0.208744+0.009419 \n",
      "[178]\ttrain-error:0.158528+0.005766\ttest-error:0.209867+0.007343 \n",
      "[179]\ttrain-error:0.157686+0.005157\ttest-error:0.206497+0.007052 \n",
      "[180]\ttrain-error:0.156564+0.005023\ttest-error:0.207620+0.009117 \n",
      "[181]\ttrain-error:0.156283+0.005526\ttest-error:0.208744+0.007130 \n",
      "[182]\ttrain-error:0.157967+0.006400\ttest-error:0.209867+0.008157 \n",
      "[183]\ttrain-error:0.159650+0.005657\ttest-error:0.208744+0.010067 \n",
      "[184]\ttrain-error:0.158528+0.005266\ttest-error:0.207620+0.010410 \n",
      "[185]\ttrain-error:0.158808+0.005066\ttest-error:0.208738+0.010537 \n",
      "[186]\ttrain-error:0.158528+0.005049\ttest-error:0.208738+0.010537 \n",
      "[187]\ttrain-error:0.157967+0.005604\ttest-error:0.206497+0.009360 \n",
      "[188]\ttrain-error:0.157406+0.005231\ttest-error:0.208744+0.007130 \n",
      "[189]\ttrain-error:0.156002+0.005655\ttest-error:0.206497+0.009360 \n",
      "[190]\ttrain-error:0.156564+0.005327\ttest-error:0.206497+0.009360 \n",
      "[191]\ttrain-error:0.155723+0.005977\ttest-error:0.208738+0.011120 \n",
      "[192]\ttrain-error:0.154600+0.005870\ttest-error:0.208738+0.011120 \n",
      "[193]\ttrain-error:0.154320+0.006245\ttest-error:0.207614+0.010865 \n",
      "[194]\ttrain-error:0.155442+0.006080\ttest-error:0.208738+0.011674 \n",
      "[195]\ttrain-error:0.155722+0.006043\ttest-error:0.208738+0.010537 \n",
      "[196]\ttrain-error:0.154881+0.004714\ttest-error:0.205367+0.010576 \n",
      "[197]\ttrain-error:0.156004+0.004700\ttest-error:0.206490+0.011069 \n",
      "[198]\ttrain-error:0.155723+0.004903\ttest-error:0.208738+0.009262 \n",
      "[199]\ttrain-error:0.156003+0.005733\ttest-error:0.207614+0.010865 \n",
      "[200]\ttrain-error:0.156004+0.004352\ttest-error:0.206497+0.009360 \n",
      "[201]\ttrain-error:0.154320+0.005921\ttest-error:0.207614+0.010865 \n",
      "[202]\ttrain-error:0.155441+0.006316\ttest-error:0.207620+0.009117 \n",
      "[203]\ttrain-error:0.155722+0.006413\ttest-error:0.207614+0.010865 \n",
      "[204]\ttrain-error:0.156283+0.006269\ttest-error:0.207614+0.010865 \n",
      "[205]\ttrain-error:0.154880+0.006982\ttest-error:0.205367+0.012742 \n",
      "[206]\ttrain-error:0.155161+0.006751\ttest-error:0.205367+0.012742 \n",
      "[207]\ttrain-error:0.154600+0.006312\ttest-error:0.207614+0.010865 \n",
      "[208]\ttrain-error:0.152636+0.006688\ttest-error:0.205367+0.010576 \n",
      "[209]\ttrain-error:0.152917+0.006544\ttest-error:0.203120+0.012086 \n",
      "[210]\ttrain-error:0.153197+0.006331\ttest-error:0.204243+0.012214 \n",
      "[211]\ttrain-error:0.153197+0.007084\ttest-error:0.204243+0.012214 \n",
      "[212]\ttrain-error:0.152356+0.008325\ttest-error:0.203120+0.012086 \n",
      "[213]\ttrain-error:0.153478+0.007628\ttest-error:0.202002+0.010277 \n",
      "[214]\ttrain-error:0.153197+0.007773\ttest-error:0.200879+0.011634 \n",
      "[215]\ttrain-error:0.155161+0.007100\ttest-error:0.202002+0.011979 \n",
      "[216]\ttrain-error:0.154039+0.007252\ttest-error:0.201996+0.014704 \n",
      "[217]\ttrain-error:0.154600+0.007671\ttest-error:0.202002+0.011979 \n",
      "[218]\ttrain-error:0.153478+0.008086\ttest-error:0.200879+0.011634 \n",
      "[219]\ttrain-error:0.152636+0.008639\ttest-error:0.201996+0.014704 \n",
      "[220]\ttrain-error:0.152075+0.008913\ttest-error:0.203126+0.011128 \n",
      "[221]\ttrain-error:0.152636+0.008455\ttest-error:0.202002+0.011979 \n",
      "[222]\ttrain-error:0.152075+0.010190\ttest-error:0.203126+0.011128 \n",
      "[223]\ttrain-error:0.152355+0.009087\ttest-error:0.204249+0.011813 \n",
      "[224]\ttrain-error:0.150672+0.010113\ttest-error:0.204249+0.011813 \n",
      "[225]\ttrain-error:0.151514+0.010328\ttest-error:0.203126+0.012717 \n",
      "[226]\ttrain-error:0.150672+0.009272\ttest-error:0.204249+0.013320 \n",
      "[227]\ttrain-error:0.150953+0.009932\ttest-error:0.205373+0.012358 \n",
      "[228]\ttrain-error:0.150392+0.009633\ttest-error:0.206497+0.011752 \n",
      "[229]\ttrain-error:0.148989+0.007686\ttest-error:0.203126+0.010546 \n",
      "[230]\ttrain-error:0.149270+0.008238\ttest-error:0.203126+0.010546 \n",
      "[231]\ttrain-error:0.149830+0.009090\ttest-error:0.206490+0.013625 \n",
      "[232]\ttrain-error:0.150392+0.009006\ttest-error:0.205367+0.014150 \n",
      "[233]\ttrain-error:0.150673+0.008612\ttest-error:0.204249+0.012837 \n",
      "[234]\ttrain-error:0.151234+0.007884\ttest-error:0.204249+0.012837 \n",
      "[235]\ttrain-error:0.151234+0.007884\ttest-error:0.204249+0.014673 \n",
      "[236]\ttrain-error:0.150392+0.008134\ttest-error:0.198631+0.016603 \n",
      "[237]\ttrain-error:0.150392+0.008134\ttest-error:0.201996+0.015539 \n",
      "[238]\ttrain-error:0.150392+0.008092\ttest-error:0.203120+0.014021 \n",
      "[239]\ttrain-error:0.150392+0.008472\ttest-error:0.202002+0.012494 \n",
      "[240]\ttrain-error:0.150392+0.007737\ttest-error:0.201996+0.015128 \n",
      "[241]\ttrain-error:0.150673+0.007651\ttest-error:0.200879+0.013633 \n",
      "[242]\ttrain-error:0.150392+0.007219\ttest-error:0.202002+0.012494 \n",
      "[243]\ttrain-error:0.149269+0.006999\ttest-error:0.202008+0.009791 \n",
      "[244]\ttrain-error:0.148989+0.007531\ttest-error:0.204249+0.010083 \n",
      "[245]\ttrain-error:0.148989+0.007418\ttest-error:0.203126+0.011128 \n",
      "[246]\ttrain-error:0.148428+0.007784\ttest-error:0.202002+0.011439 \n",
      "[247]\ttrain-error:0.148147+0.006941\ttest-error:0.204249+0.010083 \n",
      "[248]\ttrain-error:0.148989+0.006876\ttest-error:0.199768+0.010254 \n",
      "[249]\ttrain-error:0.149270+0.008197\ttest-error:0.202002+0.012494 \n",
      "[250]\ttrain-error:0.148709+0.006797\ttest-error:0.202008+0.009791 \n",
      "[251]\ttrain-error:0.148708+0.007399\ttest-error:0.200891+0.008825 \n",
      "[252]\ttrain-error:0.148428+0.006518\ttest-error:0.199768+0.008938 \n",
      "[253]\ttrain-error:0.148147+0.006472\ttest-error:0.200885+0.010019 \n",
      "[254]\ttrain-error:0.148989+0.006215\ttest-error:0.200885+0.010019 \n",
      "[255]\ttrain-error:0.148709+0.005590\ttest-error:0.200885+0.010019 \n",
      "[256]\ttrain-error:0.148989+0.005616\ttest-error:0.200885+0.010019 \n",
      "[257]\ttrain-error:0.148708+0.005520\ttest-error:0.200885+0.010019 \n",
      "[258]\ttrain-error:0.148709+0.005519\ttest-error:0.199761+0.011297 \n",
      "[259]\ttrain-error:0.148708+0.004905\ttest-error:0.200879+0.012673 \n",
      "[260]\ttrain-error:0.148428+0.006928\ttest-error:0.199755+0.014158 \n",
      "[261]\ttrain-error:0.148989+0.006206\ttest-error:0.198638+0.012843 \n",
      "[262]\ttrain-error:0.149269+0.006280\ttest-error:0.199761+0.011297 \n",
      "[263]\ttrain-error:0.149269+0.006033\ttest-error:0.198644+0.010228 \n",
      "[264]\ttrain-error:0.147586+0.005169\ttest-error:0.199768+0.010254 \n",
      "[265]\ttrain-error:0.147305+0.006371\ttest-error:0.199768+0.010254 \n",
      "[266]\ttrain-error:0.147586+0.005402\ttest-error:0.198650+0.009728 \n",
      "[267]\ttrain-error:0.145902+0.004659\ttest-error:0.198644+0.008909 \n",
      "[268]\ttrain-error:0.146463+0.005105\ttest-error:0.198644+0.008909 \n",
      "[269]\ttrain-error:0.147024+0.004929\ttest-error:0.197520+0.010686 \n",
      "[270]\ttrain-error:0.146463+0.005105\ttest-error:0.197520+0.010686 \n",
      "[271]\ttrain-error:0.146183+0.004935\ttest-error:0.196397+0.007624 \n",
      "[272]\ttrain-error:0.146743+0.005393\ttest-error:0.197520+0.007981 \n",
      "[273]\ttrain-error:0.146463+0.005883\ttest-error:0.197520+0.007981 \n",
      "[274]\ttrain-error:0.146183+0.004935\ttest-error:0.197520+0.007981 \n",
      "[275]\ttrain-error:0.145902+0.005206\ttest-error:0.197520+0.007981 \n",
      "[276]\ttrain-error:0.145902+0.005053\ttest-error:0.197520+0.007981 \n",
      "[277]\ttrain-error:0.146744+0.004866\ttest-error:0.197520+0.007981 \n",
      "[278]\ttrain-error:0.145902+0.005428\ttest-error:0.198638+0.009445 \n",
      "[279]\ttrain-error:0.146464+0.004960\ttest-error:0.198638+0.009445 \n",
      "[280]\ttrain-error:0.147025+0.004778\ttest-error:0.198638+0.009445 \n",
      "[281]\ttrain-error:0.146464+0.004186\ttest-error:0.199761+0.010118 \n",
      "[282]\ttrain-error:0.146183+0.004690\ttest-error:0.199761+0.010118 \n",
      "[283]\ttrain-error:0.145902+0.004398\ttest-error:0.198638+0.009445 \n",
      "[284]\ttrain-error:0.145902+0.004398\ttest-error:0.198638+0.009445 \n",
      "[285]\ttrain-error:0.146182+0.005309\ttest-error:0.196397+0.007624 \n",
      "[286]\ttrain-error:0.145902+0.004562\ttest-error:0.198638+0.009445 \n",
      "[287]\ttrain-error:0.145622+0.003659\ttest-error:0.197514+0.009281 \n",
      "[288]\ttrain-error:0.145903+0.003824\ttest-error:0.196397+0.007624 \n",
      "[289]\ttrain-error:0.145902+0.003720\ttest-error:0.196397+0.007624 \n",
      "[290]\ttrain-error:0.146744+0.003990\ttest-error:0.196397+0.007624 \n",
      "[291]\ttrain-error:0.146745+0.003363\ttest-error:0.198638+0.009445 \n",
      "[292]\ttrain-error:0.146183+0.003210\ttest-error:0.195267+0.009884 \n",
      "[293]\ttrain-error:0.145061+0.003791\ttest-error:0.195267+0.010503 \n",
      "[294]\ttrain-error:0.145061+0.003351\ttest-error:0.195267+0.010503 \n",
      "[295]\ttrain-error:0.144780+0.003085\ttest-error:0.191902+0.008585 \n",
      "[296]\ttrain-error:0.145341+0.003575\ttest-error:0.193020+0.010572 \n",
      "[297]\ttrain-error:0.145622+0.003337\ttest-error:0.195267+0.009223 \n",
      "[298]\ttrain-error:0.145061+0.003351\ttest-error:0.195267+0.010503 \n",
      "[299]\ttrain-error:0.144219+0.002826\ttest-error:0.194143+0.011177 \n",
      "[300]\ttrain-error:0.144780+0.003653\ttest-error:0.195267+0.010503 \n",
      "[301]\ttrain-error:0.143938+0.002975\ttest-error:0.195267+0.010503 \n",
      "[302]\ttrain-error:0.143938+0.003104\ttest-error:0.194143+0.009984 \n",
      "[303]\ttrain-error:0.144500+0.002300\ttest-error:0.197514+0.011136 \n",
      "[304]\ttrain-error:0.144219+0.002200\ttest-error:0.197514+0.011136 \n",
      "[305]\ttrain-error:0.144780+0.002524\ttest-error:0.197514+0.011136 \n",
      "[306]\ttrain-error:0.144219+0.002807\ttest-error:0.197514+0.011136 \n",
      "[307]\ttrain-error:0.144219+0.003200\ttest-error:0.197514+0.011136 \n",
      "[308]\ttrain-error:0.143658+0.003351\ttest-error:0.197514+0.011136 \n",
      "[309]\ttrain-error:0.143938+0.002975\ttest-error:0.197514+0.011136 \n",
      "[310]\ttrain-error:0.143657+0.003451\ttest-error:0.197514+0.011136 \n",
      "[311]\ttrain-error:0.143939+0.003245\ttest-error:0.197514+0.011136 \n",
      "[312]\ttrain-error:0.144500+0.002905\ttest-error:0.197514+0.011136 \n",
      "[313]\ttrain-error:0.144219+0.002684\ttest-error:0.198638+0.010091 \n",
      "[314]\ttrain-error:0.144219+0.002663\ttest-error:0.197514+0.011136 \n",
      "[315]\ttrain-error:0.143377+0.003653\ttest-error:0.197514+0.011136 \n",
      "[316]\ttrain-error:0.143938+0.002975\ttest-error:0.197514+0.011136 \n",
      "[317]\ttrain-error:0.144500+0.003038\ttest-error:0.197514+0.011136 \n",
      "[318]\ttrain-error:0.143658+0.002843\ttest-error:0.197514+0.011136 \n",
      "[319]\ttrain-error:0.143377+0.003210\ttest-error:0.197514+0.011136 \n",
      "[320]\ttrain-error:0.143097+0.002466\ttest-error:0.197514+0.011136 \n",
      "[321]\ttrain-error:0.143097+0.003182\ttest-error:0.198638+0.010091 \n",
      "[322]\ttrain-error:0.143378+0.003364\ttest-error:0.198638+0.010091 \n",
      "[323]\ttrain-error:0.143659+0.002862\ttest-error:0.197514+0.011136 \n",
      "[324]\ttrain-error:0.143659+0.002862\ttest-error:0.197514+0.010554 \n",
      "[325]\ttrain-error:0.143378+0.003086\ttest-error:0.198638+0.010091 \n",
      "[326]\ttrain-error:0.143938+0.002975\ttest-error:0.198638+0.010091 \n",
      "[327]\ttrain-error:0.143658+0.003351\ttest-error:0.198638+0.010091 \n",
      "[328]\ttrain-error:0.143939+0.003684\ttest-error:0.198638+0.010091 \n",
      "[329]\ttrain-error:0.143939+0.003684\ttest-error:0.198638+0.010091 \n",
      "[330]\ttrain-error:0.144219+0.003868\ttest-error:0.197514+0.010554 \n",
      "[331]\ttrain-error:0.144500+0.004122\ttest-error:0.197514+0.010554 \n",
      "[332]\ttrain-error:0.145060+0.004705\ttest-error:0.197514+0.010554 \n",
      "[333]\ttrain-error:0.144499+0.004825\ttest-error:0.197514+0.010554 \n",
      "[334]\ttrain-error:0.144780+0.004432\ttest-error:0.199761+0.009473 \n",
      "[335]\ttrain-error:0.144499+0.004216\ttest-error:0.198638+0.010091 \n",
      "[336]\ttrain-error:0.144780+0.004618\ttest-error:0.199761+0.009473 \n",
      "[337]\ttrain-error:0.144500+0.004228\ttest-error:0.198638+0.010091 \n",
      "[338]\ttrain-error:0.144219+0.004437\ttest-error:0.198638+0.010091 \n",
      "[339]\ttrain-error:0.143938+0.004183\ttest-error:0.198638+0.010091 \n",
      "[340]\ttrain-error:0.144219+0.004437\ttest-error:0.199761+0.010118 \n",
      "[341]\ttrain-error:0.143377+0.004680\ttest-error:0.198638+0.010091 \n",
      "[342]\ttrain-error:0.142816+0.004684\ttest-error:0.199761+0.009473 \n",
      "[343]\ttrain-error:0.143377+0.005093\ttest-error:0.198638+0.011273 \n",
      "[344]\ttrain-error:0.142816+0.004611\ttest-error:0.198638+0.010091 \n",
      "[345]\ttrain-error:0.142536+0.004809\ttest-error:0.198638+0.010091 \n",
      "[346]\ttrain-error:0.142536+0.004726\ttest-error:0.199761+0.009473 \n",
      "[347]\ttrain-error:0.141975+0.004276\ttest-error:0.199755+0.011719 \n",
      "[348]\ttrain-error:0.141975+0.004276\ttest-error:0.199755+0.011719 \n",
      "[349]\ttrain-error:0.141694+0.003954\ttest-error:0.199755+0.011719 \n",
      "[350]\ttrain-error:0.141975+0.004183\ttest-error:0.198631+0.013216 \n",
      "[351]\ttrain-error:0.141133+0.003714\ttest-error:0.198638+0.010091 \n",
      "[352]\ttrain-error:0.141694+0.004148\ttest-error:0.198638+0.010091 \n",
      "[353]\ttrain-error:0.141133+0.003906\ttest-error:0.198638+0.010091 \n",
      "[354]\ttrain-error:0.141413+0.004360\ttest-error:0.198638+0.010091 \n",
      "[355]\ttrain-error:0.141133+0.004005\ttest-error:0.198638+0.010091 \n",
      "[356]\ttrain-error:0.140291+0.003643\ttest-error:0.199755+0.011719 \n",
      "[357]\ttrain-error:0.140853+0.003249\ttest-error:0.197508+0.014902 \n",
      "[358]\ttrain-error:0.140853+0.003249\ttest-error:0.197508+0.014902 \n",
      "[359]\ttrain-error:0.140572+0.003683\ttest-error:0.199755+0.011719 \n",
      "[360]\ttrain-error:0.140010+0.003454\ttest-error:0.199755+0.011719 \n",
      "[361]\ttrain-error:0.140852+0.004371\ttest-error:0.198631+0.013216 \n",
      "[362]\ttrain-error:0.140852+0.004371\ttest-error:0.198631+0.013216 \n",
      "[363]\ttrain-error:0.141132+0.004184\ttest-error:0.197508+0.014030 \n",
      "[364]\ttrain-error:0.140852+0.003995\ttest-error:0.198631+0.012729 \n",
      "[365]\ttrain-error:0.140572+0.003775\ttest-error:0.197508+0.014030 \n",
      "[366]\ttrain-error:0.140852+0.003467\ttest-error:0.197508+0.014030 \n",
      "[367]\ttrain-error:0.140572+0.003086\ttest-error:0.197508+0.014030 \n",
      "[368]\ttrain-error:0.140011+0.003338\ttest-error:0.197508+0.014030 \n",
      "[369]\ttrain-error:0.140291+0.002906\ttest-error:0.197508+0.014030 \n",
      "[370]\ttrain-error:0.139730+0.003122\ttest-error:0.196384+0.014278 \n",
      "[371]\ttrain-error:0.139449+0.003579\ttest-error:0.197508+0.014030 \n",
      "[372]\ttrain-error:0.140010+0.002963\ttest-error:0.198631+0.014139 \n",
      "[373]\ttrain-error:0.140011+0.002828\ttest-error:0.197508+0.014030 \n",
      "[374]\ttrain-error:0.139730+0.003246\ttest-error:0.199755+0.015024 \n",
      "[375]\ttrain-error:0.139169+0.002974\ttest-error:0.198631+0.016218 \n",
      "[376]\ttrain-error:0.138888+0.002642\ttest-error:0.198631+0.016218 \n",
      "[377]\ttrain-error:0.138888+0.002642\ttest-error:0.198631+0.014139 \n",
      "[378]\ttrain-error:0.138888+0.002489\ttest-error:0.198631+0.014139 \n",
      "[379]\ttrain-error:0.138608+0.002396\ttest-error:0.198631+0.014139 \n",
      "[380]\ttrain-error:0.138327+0.002266\ttest-error:0.197508+0.014030 \n",
      "[381]\ttrain-error:0.138047+0.002271\ttest-error:0.197508+0.014030 \n",
      "[382]\ttrain-error:0.137486+0.002348\ttest-error:0.195261+0.014865 \n",
      "[383]\ttrain-error:0.137486+0.002348\ttest-error:0.195261+0.014865 \n",
      "[384]\ttrain-error:0.137486+0.002348\ttest-error:0.195261+0.014865 \n",
      "[385]\ttrain-error:0.137486+0.002348\ttest-error:0.195261+0.014865 \n",
      "[386]\ttrain-error:0.137486+0.002348\ttest-error:0.195261+0.013532 \n",
      "[387]\ttrain-error:0.137486+0.002348\ttest-error:0.194137+0.014061 \n",
      "[388]\ttrain-error:0.137486+0.002348\ttest-error:0.195261+0.013532 \n",
      "[389]\ttrain-error:0.137486+0.002012\ttest-error:0.194137+0.014061 \n",
      "[390]\ttrain-error:0.136364+0.002877\ttest-error:0.194137+0.014061 \n",
      "[391]\ttrain-error:0.136925+0.003413\ttest-error:0.194137+0.014061 \n",
      "[392]\ttrain-error:0.136645+0.003416\ttest-error:0.195261+0.013532 \n",
      "[393]\ttrain-error:0.137206+0.003268\ttest-error:0.194137+0.014061 \n",
      "[394]\ttrain-error:0.136364+0.002877\ttest-error:0.194137+0.014061 \n",
      "[395]\ttrain-error:0.136364+0.002084\ttest-error:0.194137+0.014061 \n",
      "[396]\ttrain-error:0.136364+0.002610\ttest-error:0.195261+0.013532 \n",
      "[397]\ttrain-error:0.136084+0.002980\ttest-error:0.195261+0.013532 \n",
      "[398]\ttrain-error:0.136364+0.003933\ttest-error:0.194137+0.014503 \n",
      "[399]\ttrain-error:0.136084+0.003580\ttest-error:0.193013+0.014041 \n",
      "[400]\ttrain-error:0.135803+0.003938\ttest-error:0.193013+0.014041 \n",
      "[401]\ttrain-error:0.135803+0.003285\ttest-error:0.193013+0.014041 \n",
      "[402]\ttrain-error:0.136084+0.002980\ttest-error:0.193013+0.014041 \n",
      "[403]\ttrain-error:0.135523+0.003191\ttest-error:0.193013+0.014041 \n",
      "[404]\ttrain-error:0.135803+0.002884\ttest-error:0.193013+0.014041 \n",
      "[405]\ttrain-error:0.135803+0.002744\ttest-error:0.193013+0.014041 \n",
      "[406]\ttrain-error:0.135522+0.002631\ttest-error:0.194137+0.013132 \n",
      "[407]\ttrain-error:0.136083+0.002682\ttest-error:0.193013+0.014041 \n",
      "[408]\ttrain-error:0.135523+0.003312\ttest-error:0.191896+0.012107 \n",
      "[409]\ttrain-error:0.135242+0.003415\ttest-error:0.191896+0.012107 \n",
      "[410]\ttrain-error:0.135522+0.002610\ttest-error:0.193013+0.014041 \n",
      "[411]\ttrain-error:0.134399+0.003111\ttest-error:0.193013+0.014041 \n",
      "[412]\ttrain-error:0.135241+0.002882\ttest-error:0.191890+0.014377 \n",
      "[413]\ttrain-error:0.134399+0.003235\ttest-error:0.193013+0.014041 \n",
      "[414]\ttrain-error:0.134119+0.002757\ttest-error:0.191890+0.014377 \n",
      "[415]\ttrain-error:0.134119+0.002757\ttest-error:0.191890+0.014377 \n",
      "[416]\ttrain-error:0.133838+0.002574\ttest-error:0.191890+0.014377 \n",
      "[417]\ttrain-error:0.133838+0.002574\ttest-error:0.191890+0.014377 \n",
      "[418]\ttrain-error:0.134960+0.002388\ttest-error:0.195254+0.016382 \n",
      "[419]\ttrain-error:0.134961+0.002264\ttest-error:0.194137+0.014503 \n",
      "[420]\ttrain-error:0.135242+0.002636\ttest-error:0.195261+0.015284 \n",
      "[421]\ttrain-error:0.135242+0.002636\ttest-error:0.194137+0.016537 \n",
      "[422]\ttrain-error:0.135802+0.002419\ttest-error:0.193013+0.015737 \n",
      "[423]\ttrain-error:0.135522+0.002111\ttest-error:0.193013+0.015737 \n",
      "[424]\ttrain-error:0.134961+0.001885\ttest-error:0.194137+0.014503 \n",
      "[425]\ttrain-error:0.134961+0.001885\ttest-error:0.193013+0.015737 \n",
      "[426]\ttrain-error:0.135522+0.001447\ttest-error:0.193013+0.015737 \n",
      "[427]\ttrain-error:0.135241+0.001417\ttest-error:0.193013+0.015737 \n",
      "[428]\ttrain-error:0.134680+0.002150\ttest-error:0.194137+0.016537 \n",
      "[429]\ttrain-error:0.134961+0.001631\ttest-error:0.193007+0.018925 \n",
      "[430]\ttrain-error:0.134400+0.002418\ttest-error:0.193007+0.018925 \n",
      "[431]\ttrain-error:0.133838+0.002594\ttest-error:0.191884+0.018505 \n",
      "[432]\ttrain-error:0.133557+0.002217\ttest-error:0.194131+0.016442 \n",
      "[433]\ttrain-error:0.133837+0.003110\ttest-error:0.194131+0.016442 \n",
      "[434]\ttrain-error:0.133276+0.002304\ttest-error:0.195254+0.016763 \n",
      "[435]\ttrain-error:0.133838+0.002417\ttest-error:0.193007+0.017176 \n",
      "[436]\ttrain-error:0.132715+0.002570\ttest-error:0.194131+0.016442 \n",
      "[437]\ttrain-error:0.132435+0.002594\ttest-error:0.194131+0.016442 \n",
      "[438]\ttrain-error:0.132434+0.002846\ttest-error:0.194131+0.016442 \n",
      "[439]\ttrain-error:0.132995+0.002811\ttest-error:0.194131+0.016442 \n",
      "[440]\ttrain-error:0.132716+0.002590\ttest-error:0.194131+0.018261 \n",
      "[441]\ttrain-error:0.132154+0.002698\ttest-error:0.194131+0.018261 \n",
      "[442]\ttrain-error:0.132154+0.002822\ttest-error:0.194131+0.018261 \n",
      "[443]\ttrain-error:0.131593+0.003339\ttest-error:0.194131+0.018261 \n",
      "[444]\ttrain-error:0.131312+0.003578\ttest-error:0.194131+0.018261 \n",
      "[445]\ttrain-error:0.131312+0.003366\ttest-error:0.194131+0.018261 \n",
      "[446]\ttrain-error:0.132154+0.002822\ttest-error:0.193007+0.017176 \n",
      "[447]\ttrain-error:0.132154+0.002822\ttest-error:0.195254+0.016763 \n",
      "[448]\ttrain-error:0.132154+0.003088\ttest-error:0.195254+0.016763 \n",
      "[449]\ttrain-error:0.131592+0.003325\ttest-error:0.196378+0.017372 \n",
      "[450]\ttrain-error:0.131873+0.003167\ttest-error:0.196378+0.017372 \n",
      "[451]\ttrain-error:0.131593+0.003455\ttest-error:0.196378+0.017372 \n",
      "[452]\ttrain-error:0.131313+0.003140\ttest-error:0.194131+0.018261 \n",
      "[453]\ttrain-error:0.132154+0.003562\ttest-error:0.195254+0.018888 \n",
      "[454]\ttrain-error:0.132715+0.003686\ttest-error:0.195254+0.018888 \n",
      "[455]\ttrain-error:0.132715+0.002570\ttest-error:0.195254+0.018888 \n",
      "[456]\ttrain-error:0.132996+0.002397\ttest-error:0.197502+0.018238 \n",
      "[457]\ttrain-error:0.132716+0.001888\ttest-error:0.196378+0.019752 \n",
      "[458]\ttrain-error:0.132996+0.002397\ttest-error:0.196378+0.019102 \n",
      "[459]\ttrain-error:0.133277+0.002489\ttest-error:0.196378+0.019102 \n",
      "[460]\ttrain-error:0.132996+0.002397\ttest-error:0.194131+0.017556 \n",
      "[461]\ttrain-error:0.132715+0.002244\ttest-error:0.195254+0.016763 \n",
      "[462]\ttrain-error:0.132435+0.001381\ttest-error:0.194131+0.016442 \n",
      "[463]\ttrain-error:0.132154+0.001599\ttest-error:0.196378+0.017372 \n",
      "[464]\ttrain-error:0.132716+0.001888\ttest-error:0.195254+0.016763 \n",
      "[465]\ttrain-error:0.132716+0.001888\ttest-error:0.195254+0.016763 \n",
      "[466]\ttrain-error:0.132716+0.001666\ttest-error:0.195254+0.016763 \n",
      "[467]\ttrain-error:0.132435+0.002090\ttest-error:0.196378+0.017372 \n",
      "[468]\ttrain-error:0.132435+0.002882\ttest-error:0.196378+0.017372 \n",
      "[469]\ttrain-error:0.132435+0.002090\ttest-error:0.197502+0.018238 \n",
      "[470]\ttrain-error:0.132716+0.002110\ttest-error:0.196378+0.017372 \n",
      "[471]\ttrain-error:0.132716+0.002110\ttest-error:0.196378+0.017372 \n",
      "[472]\ttrain-error:0.132997+0.002419\ttest-error:0.197502+0.018238 \n",
      "[473]\ttrain-error:0.131875+0.003215\ttest-error:0.196378+0.017372 \n",
      "[474]\ttrain-error:0.132997+0.001644\ttest-error:0.196378+0.017372 \n",
      "[475]\ttrain-error:0.132716+0.002266\ttest-error:0.197502+0.018238 \n",
      "[476]\ttrain-error:0.132715+0.002244\ttest-error:0.198619+0.019891 \n",
      "[477]\ttrain-error:0.132154+0.002975\ttest-error:0.198619+0.019891 \n",
      "[478]\ttrain-error:0.131874+0.002806\ttest-error:0.198619+0.019891 \n",
      "[479]\ttrain-error:0.131874+0.002643\ttest-error:0.198619+0.019891 \n",
      "[480]\ttrain-error:0.132155+0.002568\ttest-error:0.198619+0.019891 \n",
      "[481]\ttrain-error:0.132154+0.002975\ttest-error:0.198619+0.019891 \n",
      "[482]\ttrain-error:0.131593+0.003111\ttest-error:0.198619+0.019891 \n",
      "[483]\ttrain-error:0.131032+0.002595\ttest-error:0.198619+0.019891 \n",
      "[484]\ttrain-error:0.131312+0.001861\ttest-error:0.197502+0.018238 \n",
      "[485]\ttrain-error:0.131593+0.002204\ttest-error:0.197502+0.018238 \n",
      "[486]\ttrain-error:0.131873+0.001933\ttest-error:0.197502+0.018238 \n",
      "[487]\ttrain-error:0.131312+0.003124\ttest-error:0.197502+0.018238 \n",
      "[488]\ttrain-error:0.130471+0.003183\ttest-error:0.198625+0.016889 \n",
      "[489]\ttrain-error:0.131593+0.002018\ttest-error:0.199742+0.018593 \n",
      "[490]\ttrain-error:0.131313+0.002413\ttest-error:0.198619+0.019891 \n",
      "[491]\ttrain-error:0.131032+0.002249\ttest-error:0.198619+0.019891 \n",
      "[492]\ttrain-error:0.131313+0.002413\ttest-error:0.198619+0.019891 \n",
      "[493]\ttrain-error:0.131593+0.002982\ttest-error:0.198619+0.019891 \n",
      "[494]\ttrain-error:0.131032+0.002864\ttest-error:0.198619+0.019891 \n",
      "[495]\ttrain-error:0.131313+0.004303\ttest-error:0.198619+0.019891 \n",
      "[496]\ttrain-error:0.131313+0.003495\ttest-error:0.198619+0.019891 \n",
      "[497]\ttrain-error:0.131313+0.003495\ttest-error:0.198619+0.019891 \n",
      "[498]\ttrain-error:0.130471+0.004436\ttest-error:0.198619+0.019891 \n",
      "[499]\ttrain-error:0.130191+0.004973\ttest-error:0.198619+0.019891 \n",
      "[500]\ttrain-error:0.131032+0.004213\ttest-error:0.198619+0.019891 \n",
      "[501]\ttrain-error:0.130752+0.005566\ttest-error:0.198619+0.019891 \n",
      "[502]\ttrain-error:0.131032+0.005061\ttest-error:0.198619+0.019891 \n",
      "[503]\ttrain-error:0.130471+0.005468\ttest-error:0.198619+0.019891 \n",
      "[504]\ttrain-error:0.130752+0.005566\ttest-error:0.198619+0.019891 \n",
      "[505]\ttrain-error:0.130471+0.005387\ttest-error:0.197495+0.019165 \n",
      "[506]\ttrain-error:0.131312+0.004727\ttest-error:0.198619+0.019891 \n",
      "[507]\ttrain-error:0.131312+0.004198\ttest-error:0.197495+0.019165 \n",
      "[508]\ttrain-error:0.131312+0.004198\ttest-error:0.197495+0.019165 \n",
      "[509]\ttrain-error:0.130190+0.004873\ttest-error:0.197495+0.019165 \n",
      "[510]\ttrain-error:0.130190+0.004873\ttest-error:0.197495+0.019165 \n",
      "[511]\ttrain-error:0.130190+0.004873\ttest-error:0.197495+0.019165 \n",
      "[512]\ttrain-error:0.130471+0.004767\ttest-error:0.197495+0.019165 \n",
      "[513]\ttrain-error:0.130471+0.004767\ttest-error:0.197495+0.019165 \n",
      "[514]\ttrain-error:0.130471+0.004767\ttest-error:0.197495+0.019165 \n",
      "[515]\ttrain-error:0.130190+0.004635\ttest-error:0.198619+0.019891 \n",
      "[516]\ttrain-error:0.130752+0.004725\ttest-error:0.198619+0.019891 \n",
      "[517]\ttrain-error:0.130471+0.004436\ttest-error:0.198619+0.019891 \n",
      "[518]\ttrain-error:0.130191+0.004294\ttest-error:0.198619+0.019891 \n",
      "[519]\ttrain-error:0.129349+0.005423\ttest-error:0.198619+0.019891 \n",
      "[520]\ttrain-error:0.129629+0.005508\ttest-error:0.198619+0.019891 \n",
      "[521]\ttrain-error:0.129349+0.005423\ttest-error:0.198619+0.019891 \n",
      "[522]\ttrain-error:0.129910+0.004222\ttest-error:0.198619+0.019891 \n",
      "[523]\ttrain-error:0.130191+0.004384\ttest-error:0.198619+0.019891 \n",
      "[524]\ttrain-error:0.130471+0.004436\ttest-error:0.198619+0.019891 \n",
      "[525]\ttrain-error:0.129349+0.004556\ttest-error:0.198619+0.019891 \n",
      "[526]\ttrain-error:0.129068+0.004599\ttest-error:0.198619+0.019891 \n",
      "[527]\ttrain-error:0.129910+0.004749\ttest-error:0.198619+0.019891 \n",
      "[528]\ttrain-error:0.129068+0.004346\ttest-error:0.198619+0.019891 \n",
      "[529]\ttrain-error:0.129629+0.004740\ttest-error:0.198619+0.019891 \n",
      "[530]\ttrain-error:0.129629+0.004740\ttest-error:0.197495+0.019165 \n",
      "[531]\ttrain-error:0.129630+0.004582\ttest-error:0.199742+0.018593 \n",
      "[532]\ttrain-error:0.129629+0.004021\ttest-error:0.198619+0.019891 \n",
      "[533]\ttrain-error:0.130191+0.004373\ttest-error:0.198619+0.019891 \n",
      "[534]\ttrain-error:0.130190+0.004462\ttest-error:0.198619+0.019891 \n",
      "[535]\ttrain-error:0.129629+0.004740\ttest-error:0.198619+0.019891 \n",
      "[536]\ttrain-error:0.129910+0.004210\ttest-error:0.199742+0.018593 \n",
      "[537]\ttrain-error:0.130191+0.004373\ttest-error:0.199742+0.018593 \n",
      "[538]\ttrain-error:0.129068+0.005313\ttest-error:0.199742+0.018593 \n",
      "[539]\ttrain-error:0.129629+0.004740\ttest-error:0.200866+0.017847 \n",
      "[540]\ttrain-error:0.129349+0.005276\ttest-error:0.200866+0.017847 \n",
      "[541]\ttrain-error:0.128788+0.005119\ttest-error:0.200866+0.017847 \n",
      "[542]\ttrain-error:0.129068+0.005313\ttest-error:0.199742+0.017182 \n",
      "[543]\ttrain-error:0.129630+0.005436\ttest-error:0.200866+0.017847 \n",
      "[544]\ttrain-error:0.129349+0.005276\ttest-error:0.200866+0.017847 \n",
      "[545]\ttrain-error:0.129068+0.005313\ttest-error:0.200866+0.017847 \n",
      "[546]\ttrain-error:0.128788+0.005837\ttest-error:0.200866+0.017847 \n",
      "[547]\ttrain-error:0.128788+0.005837\ttest-error:0.200866+0.017847 \n",
      "[548]\ttrain-error:0.128788+0.005837\ttest-error:0.199742+0.019260 \n",
      "[549]\ttrain-error:0.128507+0.005647\ttest-error:0.198625+0.017620 \n",
      "[550]\ttrain-error:0.127946+0.005975\ttest-error:0.197502+0.016797 \n",
      "[551]\ttrain-error:0.128227+0.006244\ttest-error:0.197502+0.018238 \n",
      "[552]\ttrain-error:0.129068+0.004684\ttest-error:0.198625+0.017620 \n",
      "[553]\ttrain-error:0.129068+0.005459\ttest-error:0.198625+0.017620 \n",
      "[554]\ttrain-error:0.129068+0.005459\ttest-error:0.198619+0.018578 \n",
      "[555]\ttrain-error:0.128507+0.006490\ttest-error:0.196372+0.017994 \n",
      "[556]\ttrain-error:0.128788+0.005970\ttest-error:0.196378+0.016245 \n",
      "[557]\ttrain-error:0.128507+0.006043\ttest-error:0.197495+0.018150 \n",
      "[558]\ttrain-error:0.128787+0.006283\ttest-error:0.197495+0.017440 \n",
      "[559]\ttrain-error:0.129067+0.006381\ttest-error:0.196372+0.018682 \n",
      "[560]\ttrain-error:0.129067+0.006381\ttest-error:0.196372+0.017278 \n",
      "[561]\ttrain-error:0.128507+0.006043\ttest-error:0.196372+0.018682 \n",
      "[562]\ttrain-error:0.128507+0.006043\ttest-error:0.196372+0.018682 \n",
      "[563]\ttrain-error:0.128226+0.005979\ttest-error:0.196372+0.018682 \n",
      "[564]\ttrain-error:0.128507+0.005785\ttest-error:0.197495+0.017440 \n",
      "[565]\ttrain-error:0.128507+0.006171\ttest-error:0.197495+0.017440 \n",
      "[566]\ttrain-error:0.128507+0.006171\ttest-error:0.196365+0.020528 \n",
      "[567]\ttrain-error:0.128226+0.006663\ttest-error:0.197489+0.019405 \n",
      "[568]\ttrain-error:0.128507+0.005985\ttest-error:0.198613+0.019485 \n",
      "[569]\ttrain-error:0.128788+0.006101\ttest-error:0.198613+0.019485 \n",
      "[570]\ttrain-error:0.129068+0.005601\ttest-error:0.198613+0.019485 \n",
      "[571]\ttrain-error:0.129068+0.005601\ttest-error:0.196378+0.015448 \n",
      "[572]\ttrain-error:0.128788+0.006101\ttest-error:0.195254+0.016763 \n",
      "[573]\ttrain-error:0.129068+0.006202\ttest-error:0.195254+0.016763 \n",
      "[574]\ttrain-error:0.129068+0.005601\ttest-error:0.195254+0.016763 \n",
      "[575]\ttrain-error:0.128788+0.006101\ttest-error:0.195254+0.016763 \n",
      "[576]\ttrain-error:0.128507+0.006171\ttest-error:0.195261+0.015692 \n",
      "[577]\ttrain-error:0.129068+0.006065\ttest-error:0.194137+0.014932 \n",
      "[578]\ttrain-error:0.128787+0.006529\ttest-error:0.195261+0.015692 \n",
      "[579]\ttrain-error:0.128788+0.006101\ttest-error:0.194137+0.014932 \n",
      "[580]\ttrain-error:0.128507+0.005985\ttest-error:0.194137+0.014932 \n",
      "[581]\ttrain-error:0.127946+0.005350\ttest-error:0.194137+0.014932 \n",
      "[582]\ttrain-error:0.128507+0.005434\ttest-error:0.193013+0.014484 \n",
      "[583]\ttrain-error:0.128227+0.004822\ttest-error:0.193013+0.014484 \n",
      "[584]\ttrain-error:0.127666+0.004694\ttest-error:0.193013+0.014484 \n",
      "[585]\ttrain-error:0.127385+0.005271\ttest-error:0.194137+0.014932 \n",
      "[586]\ttrain-error:0.127385+0.005119\ttest-error:0.194137+0.014932 \n",
      "[587]\ttrain-error:0.127105+0.005656\ttest-error:0.193013+0.014484 \n",
      "[588]\ttrain-error:0.127104+0.005785\ttest-error:0.193013+0.014484 \n",
      "[589]\ttrain-error:0.127104+0.005977\ttest-error:0.194137+0.014932 \n",
      "[590]\ttrain-error:0.127384+0.005481\ttest-error:0.195254+0.016763 \n",
      "[591]\ttrain-error:0.127384+0.005481\ttest-error:0.195254+0.016763 \n",
      "[592]\ttrain-error:0.126543+0.005826\ttest-error:0.195261+0.015692 \n",
      "[593]\ttrain-error:0.126543+0.005557\ttest-error:0.194137+0.017283 \n",
      "[594]\ttrain-error:0.127104+0.006042\ttest-error:0.194137+0.017283 \n",
      "[595]\ttrain-error:0.126262+0.007138\ttest-error:0.195261+0.015692 \n",
      "[596]\ttrain-error:0.126262+0.007355\ttest-error:0.196378+0.017372 \n",
      "[597]\ttrain-error:0.125981+0.007162\ttest-error:0.194131+0.016442 \n",
      "[598]\ttrain-error:0.125701+0.006837\ttest-error:0.194131+0.016442 \n",
      "[599]\ttrain-error:0.126542+0.006878\ttest-error:0.194131+0.016442 \n",
      "[600]\ttrain-error:0.126542+0.007429\ttest-error:0.194131+0.016442 \n",
      "[601]\ttrain-error:0.126542+0.006878\ttest-error:0.195248+0.018463 \n",
      "[602]\ttrain-error:0.125981+0.007162\ttest-error:0.195254+0.016763 \n",
      "[603]\ttrain-error:0.126542+0.006763\ttest-error:0.196372+0.018682 \n",
      "[604]\ttrain-error:0.126262+0.006623\ttest-error:0.196372+0.018682 \n",
      "[605]\ttrain-error:0.126542+0.006763\ttest-error:0.196372+0.018682 \n",
      "[606]\ttrain-error:0.125982+0.006346\ttest-error:0.195254+0.016763 \n",
      "[607]\ttrain-error:0.125982+0.005692\ttest-error:0.195254+0.016763 \n",
      "[608]\ttrain-error:0.125420+0.006109\ttest-error:0.195254+0.016763 \n",
      "[609]\ttrain-error:0.125420+0.006109\ttest-error:0.195254+0.016763 \n",
      "[610]\ttrain-error:0.126262+0.005868\ttest-error:0.196372+0.018682 \n",
      "[611]\ttrain-error:0.126543+0.005959\ttest-error:0.195254+0.016763 \n",
      "[612]\ttrain-error:0.126262+0.006443\ttest-error:0.195254+0.016763 \n",
      "[613]\ttrain-error:0.126262+0.006265\ttest-error:0.194137+0.014932 \n",
      "[614]\ttrain-error:0.125982+0.006346\ttest-error:0.195254+0.016763 \n",
      "[615]\ttrain-error:0.126262+0.006122\ttest-error:0.195254+0.016763 \n",
      "[616]\ttrain-error:0.125701+0.005969\ttest-error:0.195254+0.015992 \n",
      "[617]\ttrain-error:0.125981+0.006020\ttest-error:0.194131+0.017556 \n",
      "[618]\ttrain-error:0.125981+0.005253\ttest-error:0.195254+0.017857 \n",
      "[619]\ttrain-error:0.125981+0.005253\ttest-error:0.196378+0.016245 \n",
      "[620]\ttrain-error:0.126543+0.004959\ttest-error:0.196378+0.016245 \n",
      "[621]\ttrain-error:0.126543+0.005766\ttest-error:0.194137+0.014061 \n",
      "[622]\ttrain-error:0.126262+0.006122\ttest-error:0.196378+0.016245 \n",
      "[623]\ttrain-error:0.126262+0.006443\ttest-error:0.195254+0.015992 \n",
      "[624]\ttrain-error:0.126543+0.006351\ttest-error:0.195254+0.015992 \n",
      "[625]\ttrain-error:0.125982+0.006101\ttest-error:0.194131+0.017556 \n",
      "[626]\ttrain-error:0.125701+0.006051\ttest-error:0.194131+0.017556 \n",
      "[627]\ttrain-error:0.125701+0.006051\ttest-error:0.194131+0.017556 \n",
      "[628]\ttrain-error:0.125982+0.006101\ttest-error:0.194131+0.017556 \n",
      "[629]\ttrain-error:0.126823+0.005280\ttest-error:0.194131+0.017556 \n",
      "[630]\ttrain-error:0.126543+0.005115\ttest-error:0.194131+0.017556 \n",
      "[631]\ttrain-error:0.126543+0.005115\ttest-error:0.194131+0.017556 \n",
      "[632]\ttrain-error:0.126823+0.005205\ttest-error:0.191890+0.015639 \n",
      "[633]\ttrain-error:0.126543+0.005115\ttest-error:0.194131+0.017556 \n",
      "[634]\ttrain-error:0.126823+0.005280\ttest-error:0.194131+0.017556 \n",
      "[635]\ttrain-error:0.126262+0.004243\ttest-error:0.194131+0.017556 \n",
      "[636]\ttrain-error:0.126543+0.004277\ttest-error:0.193007+0.017540 \n",
      "[637]\ttrain-error:0.126543+0.004277\ttest-error:0.193007+0.017540 \n",
      "[638]\ttrain-error:0.125982+0.003897\ttest-error:0.195254+0.015992 \n",
      "[639]\ttrain-error:0.125982+0.003690\ttest-error:0.191884+0.017810 \n",
      "[640]\ttrain-error:0.126262+0.003955\ttest-error:0.191884+0.017810 \n",
      "[641]\ttrain-error:0.126823+0.004646\ttest-error:0.193007+0.017540 \n",
      "[642]\ttrain-error:0.127104+0.004199\ttest-error:0.194131+0.017556 \n",
      "[643]\ttrain-error:0.126543+0.005115\ttest-error:0.193007+0.017896 \n",
      "[644]\ttrain-error:0.126823+0.004646\ttest-error:0.193007+0.017896 \n",
      "[645]\ttrain-error:0.126262+0.004767\ttest-error:0.193007+0.017896 \n",
      "[646]\ttrain-error:0.126262+0.004767\ttest-error:0.191884+0.017810 \n",
      "[647]\ttrain-error:0.125982+0.004271\ttest-error:0.194124+0.019511 \n",
      "[648]\ttrain-error:0.125701+0.004728\ttest-error:0.194124+0.019832 \n",
      "[649]\ttrain-error:0.126262+0.004149\ttest-error:0.194124+0.019832 \n",
      "[650]\ttrain-error:0.125982+0.003795\ttest-error:0.194124+0.019832 \n",
      "[651]\ttrain-error:0.125701+0.003688\ttest-error:0.193001+0.019818 \n",
      "[652]\ttrain-error:0.125701+0.003908\ttest-error:0.194124+0.019832 \n",
      "[653]\ttrain-error:0.125140+0.003980\ttest-error:0.194131+0.018261 \n",
      "[654]\ttrain-error:0.125140+0.003778\ttest-error:0.193007+0.018588 \n",
      "[655]\ttrain-error:0.125420+0.004095\ttest-error:0.193007+0.018588 \n",
      "[656]\ttrain-error:0.125701+0.004461\ttest-error:0.194124+0.020459 \n",
      "[657]\ttrain-error:0.125420+0.004374\ttest-error:0.194124+0.020459 \n",
      "[658]\ttrain-error:0.125982+0.003457\ttest-error:0.193001+0.020134 \n",
      "[659]\ttrain-error:0.125700+0.003995\ttest-error:0.193001+0.020134 \n",
      "[660]\ttrain-error:0.125420+0.004374\ttest-error:0.193001+0.021053 \n",
      "[661]\ttrain-error:0.125140+0.003980\ttest-error:0.191877+0.020676 \n",
      "[662]\ttrain-error:0.125140+0.003465\ttest-error:0.191877+0.020676 \n",
      "[663]\ttrain-error:0.124859+0.003631\ttest-error:0.191877+0.020676 \n",
      "[664]\ttrain-error:0.125140+0.003980\ttest-error:0.193001+0.020134 \n",
      "[665]\ttrain-error:0.125139+0.004611\ttest-error:0.191877+0.020057 \n",
      "[666]\ttrain-error:0.125140+0.003980\ttest-error:0.193001+0.020134 \n",
      "[667]\ttrain-error:0.125140+0.003980\ttest-error:0.193001+0.020134 \n",
      "[668]\ttrain-error:0.124859+0.003842\ttest-error:0.194124+0.019832 \n",
      "[669]\ttrain-error:0.125420+0.004374\ttest-error:0.194124+0.019832 \n",
      "[670]\ttrain-error:0.124859+0.004414\ttest-error:0.194124+0.019832 \n",
      "[671]\ttrain-error:0.124578+0.004615\ttest-error:0.194124+0.019832 \n",
      "[672]\ttrain-error:0.124859+0.004829\ttest-error:0.193001+0.020134 \n",
      "[673]\ttrain-error:0.125139+0.005174\ttest-error:0.194124+0.019832 \n",
      "[674]\ttrain-error:0.124859+0.004414\ttest-error:0.193001+0.020134 \n",
      "[675]\ttrain-error:0.125139+0.004621\ttest-error:0.193001+0.020134 \n",
      "[676]\ttrain-error:0.124578+0.004083\ttest-error:0.193001+0.020134 \n",
      "[677]\ttrain-error:0.124578+0.004083\ttest-error:0.194124+0.020459 \n",
      "[678]\ttrain-error:0.124298+0.004281\ttest-error:0.194124+0.020459 \n",
      "[679]\ttrain-error:0.124859+0.004414\ttest-error:0.193001+0.020134 \n",
      "[680]\ttrain-error:0.124578+0.004083\ttest-error:0.193001+0.020134 \n",
      "[681]\ttrain-error:0.124298+0.004281\ttest-error:0.194124+0.020459 \n",
      "[682]\ttrain-error:0.123737+0.004535\ttest-error:0.194124+0.020459 \n",
      "[683]\ttrain-error:0.124298+0.004962\ttest-error:0.194124+0.020459 \n",
      "[684]\ttrain-error:0.124578+0.004529\ttest-error:0.194124+0.020459 \n",
      "[685]\ttrain-error:0.124578+0.005253\ttest-error:0.194124+0.020459 \n",
      "[686]\ttrain-error:0.124298+0.004281\ttest-error:0.194124+0.020459 \n",
      "[687]\ttrain-error:0.124859+0.004126\ttest-error:0.193001+0.020134 \n",
      "[688]\ttrain-error:0.124859+0.004126\ttest-error:0.193001+0.020134 \n",
      "[689]\ttrain-error:0.124858+0.004738\ttest-error:0.193001+0.020134 \n",
      "[690]\ttrain-error:0.124859+0.004126\ttest-error:0.193001+0.020134 \n",
      "[691]\ttrain-error:0.125139+0.005088\ttest-error:0.193001+0.020134 \n",
      "[692]\ttrain-error:0.124858+0.004901\ttest-error:0.193001+0.020134 \n",
      "[693]\ttrain-error:0.124858+0.004901\ttest-error:0.193001+0.020134 \n",
      "[694]\ttrain-error:0.124858+0.004901\ttest-error:0.193001+0.020134 \n",
      "[695]\ttrain-error:0.124578+0.004773\ttest-error:0.193001+0.020134 \n",
      "[696]\ttrain-error:0.125139+0.004611\ttest-error:0.193001+0.020134 \n",
      "[697]\ttrain-error:0.124859+0.004990\ttest-error:0.193001+0.020134 \n",
      "[698]\ttrain-error:0.125139+0.004940\ttest-error:0.193001+0.020134 \n",
      "[699]\ttrain-error:0.125420+0.004540\ttest-error:0.191877+0.020676 \n",
      "[700]\ttrain-error:0.125139+0.004256\ttest-error:0.191884+0.018161 \n",
      "[701]\ttrain-error:0.125139+0.004347\ttest-error:0.191884+0.018161 \n",
      "[702]\ttrain-error:0.124578+0.005177\ttest-error:0.191884+0.018161 \n",
      "[703]\ttrain-error:0.124859+0.004664\ttest-error:0.190760+0.018694 \n",
      "[704]\ttrain-error:0.124578+0.004615\ttest-error:0.189636+0.019473 \n",
      "[705]\ttrain-error:0.124578+0.004615\ttest-error:0.189636+0.019473 \n",
      "[706]\ttrain-error:0.124578+0.004615\ttest-error:0.189636+0.019473 \n",
      "[707]\ttrain-error:0.124017+0.005263\ttest-error:0.189636+0.019473 \n",
      "[708]\ttrain-error:0.124578+0.004615\ttest-error:0.188513+0.019197 \n",
      "[709]\ttrain-error:0.124859+0.004829\ttest-error:0.188513+0.019197 \n",
      "[710]\ttrain-error:0.124578+0.005253\ttest-error:0.188513+0.019197 \n",
      "[711]\ttrain-error:0.124859+0.004829\ttest-error:0.188513+0.019197 \n",
      "[712]\ttrain-error:0.125139+0.005174\ttest-error:0.188513+0.019197 \n",
      "[713]\ttrain-error:0.124859+0.004829\ttest-error:0.187389+0.019182 \n",
      "[714]\ttrain-error:0.124859+0.004829\ttest-error:0.188513+0.019197 \n",
      "[715]\ttrain-error:0.125139+0.004940\ttest-error:0.188513+0.019197 \n",
      "[716]\ttrain-error:0.124859+0.004829\ttest-error:0.188513+0.018528 \n",
      "[717]\ttrain-error:0.125139+0.004256\ttest-error:0.188513+0.018528 \n",
      "[718]\ttrain-error:0.124578+0.003873\ttest-error:0.188513+0.018528 \n",
      "[719]\ttrain-error:0.124578+0.003873\ttest-error:0.189636+0.018475 \n",
      "[720]\ttrain-error:0.124298+0.003580\ttest-error:0.190754+0.020540 \n",
      "[721]\ttrain-error:0.124298+0.003580\ttest-error:0.194124+0.020765 \n",
      "[722]\ttrain-error:0.124859+0.004221\ttest-error:0.193001+0.020445 \n",
      "[723]\ttrain-error:0.124578+0.003873\ttest-error:0.191877+0.021278 \n",
      "[724]\ttrain-error:0.124578+0.003873\ttest-error:0.190760+0.019357 \n",
      "[725]\ttrain-error:0.124578+0.003873\ttest-error:0.191884+0.018505 \n",
      "[726]\ttrain-error:0.125139+0.004256\ttest-error:0.191884+0.018505 \n",
      "[727]\ttrain-error:0.125139+0.004256\ttest-error:0.191884+0.018505 \n",
      "[728]\ttrain-error:0.124858+0.004569\ttest-error:0.190760+0.018353 \n",
      "[729]\ttrain-error:0.124858+0.004569\ttest-error:0.191884+0.018505 \n",
      "[730]\ttrain-error:0.124858+0.004569\ttest-error:0.191884+0.018505 \n",
      "[731]\ttrain-error:0.124858+0.004569\ttest-error:0.191884+0.018505 \n",
      "[732]\ttrain-error:0.125139+0.004851\ttest-error:0.189643+0.017510 \n",
      "[733]\ttrain-error:0.124858+0.005204\ttest-error:0.189643+0.017510 \n",
      "[734]\ttrain-error:0.125138+0.005380\ttest-error:0.189643+0.017510 \n",
      "[735]\ttrain-error:0.125138+0.005380\ttest-error:0.189649+0.014875 \n",
      "[736]\ttrain-error:0.125419+0.005024\ttest-error:0.190772+0.015556 \n",
      "[737]\ttrain-error:0.125419+0.005024\ttest-error:0.189649+0.014875 \n",
      "[738]\ttrain-error:0.125139+0.004851\ttest-error:0.184031+0.016404 \n",
      "[739]\ttrain-error:0.125139+0.004851\ttest-error:0.185154+0.016649 \n",
      "[740]\ttrain-error:0.125139+0.004851\ttest-error:0.187402+0.015747 \n",
      "[741]\ttrain-error:0.124858+0.004654\ttest-error:0.187402+0.014495 \n",
      "[742]\ttrain-error:0.124858+0.004654\ttest-error:0.189643+0.016393 \n",
      "[743]\ttrain-error:0.124858+0.004654\ttest-error:0.190766+0.016639 \n",
      "[744]\ttrain-error:0.124858+0.004569\ttest-error:0.187402+0.016529 \n",
      "[745]\ttrain-error:0.124578+0.004341\ttest-error:0.187402+0.016529 \n",
      "[746]\ttrain-error:0.124858+0.004569\ttest-error:0.188519+0.018271 \n",
      "[747]\ttrain-error:0.124858+0.004654\ttest-error:0.188519+0.018271 \n",
      "[748]\ttrain-error:0.124858+0.004654\ttest-error:0.189636+0.020111 \n",
      "[749]\ttrain-error:0.124578+0.004341\ttest-error:0.189636+0.018475 \n",
      "[750]\ttrain-error:0.124578+0.004341\ttest-error:0.189636+0.018475 \n",
      "[751]\ttrain-error:0.124578+0.003770\ttest-error:0.191877+0.020369 \n",
      "[752]\ttrain-error:0.124578+0.003873\ttest-error:0.193001+0.020445 \n",
      "[753]\ttrain-error:0.124859+0.004030\ttest-error:0.190754+0.021146 \n",
      "[754]\ttrain-error:0.124578+0.004615\ttest-error:0.190754+0.021734 \n",
      "[755]\ttrain-error:0.124578+0.004615\ttest-error:0.190760+0.019999 \n",
      "[756]\ttrain-error:0.124298+0.004188\ttest-error:0.191884+0.020450 \n",
      "[757]\ttrain-error:0.124017+0.005033\ttest-error:0.189636+0.020729 \n",
      "[758]\ttrain-error:0.124016+0.005329\ttest-error:0.191884+0.020139 \n",
      "[759]\ttrain-error:0.124016+0.005024\ttest-error:0.189643+0.019228 \n",
      "[760]\ttrain-error:0.124016+0.005024\ttest-error:0.189643+0.019228 \n",
      "[761]\ttrain-error:0.124016+0.005024\ttest-error:0.189643+0.019228 \n",
      "[762]\ttrain-error:0.123736+0.004769\ttest-error:0.190766+0.019761 \n",
      "[763]\ttrain-error:0.123455+0.004569\ttest-error:0.190766+0.019761 \n",
      "[764]\ttrain-error:0.123175+0.004431\ttest-error:0.189643+0.019228 \n",
      "[765]\ttrain-error:0.122894+0.004709\ttest-error:0.190766+0.019761 \n",
      "[766]\ttrain-error:0.123175+0.004773\ttest-error:0.189643+0.019228 \n",
      "[767]\ttrain-error:0.123175+0.004773\ttest-error:0.190766+0.019761 \n",
      "[768]\ttrain-error:0.123455+0.004901\ttest-error:0.190766+0.019761 \n",
      "[769]\ttrain-error:0.123736+0.004611\ttest-error:0.191884+0.021356 \n",
      "[770]\ttrain-error:0.124017+0.005033\ttest-error:0.190760+0.020924 \n",
      "[771]\ttrain-error:0.123455+0.005647\ttest-error:0.189636+0.020729 \n",
      "[772]\ttrain-error:0.123455+0.005287\ttest-error:0.188519+0.018949 \n",
      "[773]\ttrain-error:0.123175+0.005607\ttest-error:0.188519+0.018949 \n",
      "[774]\ttrain-error:0.122894+0.005481\ttest-error:0.187395+0.019910 \n",
      "[775]\ttrain-error:0.123455+0.005647\ttest-error:0.189643+0.019228 \n",
      "[776]\ttrain-error:0.124016+0.005474\ttest-error:0.188513+0.020776 \n",
      "[777]\ttrain-error:0.123174+0.005940\ttest-error:0.187395+0.018935 \n",
      "[778]\ttrain-error:0.123735+0.005803\ttest-error:0.187395+0.019910 \n",
      "[779]\ttrain-error:0.124016+0.005538\ttest-error:0.188519+0.020238 \n",
      "[780]\ttrain-error:0.124016+0.005538\ttest-error:0.187395+0.019910 \n",
      "[781]\ttrain-error:0.123735+0.005803\ttest-error:0.187395+0.019910 \n",
      "[782]\ttrain-error:0.123174+0.005806\ttest-error:0.188519+0.020238 \n",
      "[783]\ttrain-error:0.122613+0.005747\ttest-error:0.188519+0.020548 \n",
      "[784]\ttrain-error:0.122052+0.005778\ttest-error:0.188519+0.018949 \n",
      "[785]\ttrain-error:0.121772+0.004927\ttest-error:0.187395+0.019910 \n",
      "[786]\ttrain-error:0.122333+0.004770\ttest-error:0.188519+0.018949 \n",
      "[787]\ttrain-error:0.122332+0.005157\ttest-error:0.187395+0.019910 \n",
      "[788]\ttrain-error:0.122613+0.005538\ttest-error:0.188519+0.018949 \n",
      "[789]\ttrain-error:0.122613+0.005538\ttest-error:0.187395+0.019910 \n",
      "[790]\ttrain-error:0.121772+0.006072\ttest-error:0.188519+0.018949 \n",
      "[791]\ttrain-error:0.122052+0.005778\ttest-error:0.188519+0.018949 \n",
      "[792]\ttrain-error:0.121772+0.005385\ttest-error:0.188519+0.018949 \n",
      "[793]\ttrain-error:0.121772+0.005385\ttest-error:0.188519+0.018949 \n",
      "[794]\ttrain-error:0.122613+0.006271\ttest-error:0.187395+0.019910 \n",
      "[795]\ttrain-error:0.122333+0.006003\ttest-error:0.187395+0.019910 \n",
      "[796]\ttrain-error:0.122333+0.005743\ttest-error:0.188519+0.020548 \n",
      "[797]\ttrain-error:0.122052+0.006044\ttest-error:0.188519+0.020548 \n",
      "[798]\ttrain-error:0.121772+0.006326\ttest-error:0.188519+0.018949 \n",
      "[799]\ttrain-error:0.121491+0.006086\ttest-error:0.187395+0.019910 \n",
      "[800]\ttrain-error:0.122333+0.006322\ttest-error:0.187395+0.019910 \n",
      "[801]\ttrain-error:0.122613+0.006271\ttest-error:0.187395+0.019910 \n",
      "[802]\ttrain-error:0.122894+0.006013\ttest-error:0.188519+0.018949 \n",
      "[803]\ttrain-error:0.122613+0.005747\ttest-error:0.187395+0.019910 \n",
      "[804]\ttrain-error:0.122613+0.005747\ttest-error:0.187395+0.019910 \n",
      "[805]\ttrain-error:0.122613+0.005747\ttest-error:0.187395+0.019910 \n",
      "[806]\ttrain-error:0.122894+0.006143\ttest-error:0.187395+0.019910 \n",
      "[807]\ttrain-error:0.123174+0.005933\ttest-error:0.188519+0.020238 \n",
      "[808]\ttrain-error:0.123174+0.005799\ttest-error:0.188519+0.018949 \n",
      "[809]\ttrain-error:0.122894+0.006013\ttest-error:0.188519+0.018949 \n",
      "[810]\ttrain-error:0.122894+0.006013\ttest-error:0.188519+0.018949 \n",
      "[811]\ttrain-error:0.122894+0.006013\ttest-error:0.188519+0.018949 \n",
      "[812]\ttrain-error:0.122613+0.005747\ttest-error:0.187395+0.018599 \n",
      "[813]\ttrain-error:0.122894+0.005537\ttest-error:0.187402+0.017276 \n",
      "[814]\ttrain-error:0.122894+0.005537\ttest-error:0.188525+0.017653 \n",
      "[815]\ttrain-error:0.122333+0.006003\ttest-error:0.189643+0.019228 \n",
      "[816]\ttrain-error:0.122052+0.006044\ttest-error:0.189643+0.019228 \n",
      "[817]\ttrain-error:0.122052+0.006044\ttest-error:0.188519+0.018949 \n",
      "[818]\ttrain-error:0.122333+0.005804\ttest-error:0.187402+0.017276 \n",
      "[819]\ttrain-error:0.122613+0.005475\ttest-error:0.187402+0.017276 \n",
      "[820]\ttrain-error:0.122894+0.005753\ttest-error:0.187402+0.017276 \n",
      "[821]\ttrain-error:0.122333+0.005743\ttest-error:0.187402+0.017276 \n",
      "[822]\ttrain-error:0.122894+0.005955\ttest-error:0.187402+0.017276 \n",
      "[823]\ttrain-error:0.122894+0.005955\ttest-error:0.188519+0.018949 \n",
      "[824]\ttrain-error:0.122052+0.006657\ttest-error:0.188519+0.018949 \n",
      "[825]\ttrain-error:0.122333+0.006322\ttest-error:0.187402+0.017276 \n",
      "[826]\ttrain-error:0.121491+0.006636\ttest-error:0.187402+0.017276 \n",
      "[827]\ttrain-error:0.121210+0.006697\ttest-error:0.187402+0.017276 \n",
      "[828]\ttrain-error:0.120930+0.006803\ttest-error:0.187402+0.017276 \n",
      "[829]\ttrain-error:0.121491+0.007094\ttest-error:0.187402+0.017276 \n",
      "[830]\ttrain-error:0.121491+0.007094\ttest-error:0.186284+0.015743 \n",
      "[831]\ttrain-error:0.121210+0.006697\ttest-error:0.186284+0.015743 \n",
      "[832]\ttrain-error:0.121210+0.006697\ttest-error:0.186284+0.015743 \n",
      "[833]\ttrain-error:0.121771+0.006256\ttest-error:0.186284+0.015743 \n",
      "[834]\ttrain-error:0.121491+0.006456\ttest-error:0.187408+0.015021 \n",
      "[835]\ttrain-error:0.121210+0.006697\ttest-error:0.187408+0.015021 \n",
      "[836]\ttrain-error:0.122052+0.005913\ttest-error:0.187408+0.015021 \n",
      "[837]\ttrain-error:0.122333+0.006322\ttest-error:0.187408+0.015021 \n",
      "[838]\ttrain-error:0.122333+0.006322\ttest-error:0.187408+0.015021 \n",
      "[839]\ttrain-error:0.122052+0.006544\ttest-error:0.187408+0.015021 \n",
      "[840]\ttrain-error:0.121491+0.006401\ttest-error:0.187408+0.015021 \n",
      "[841]\ttrain-error:0.121491+0.006277\ttest-error:0.187408+0.015021 \n",
      "[842]\ttrain-error:0.121491+0.006277\ttest-error:0.187408+0.015021 \n",
      "[843]\ttrain-error:0.121491+0.006983\ttest-error:0.187408+0.015021 \n",
      "[844]\ttrain-error:0.121491+0.006462\ttest-error:0.187408+0.015021 \n",
      "[845]\ttrain-error:0.121491+0.006462\ttest-error:0.187408+0.015021 \n",
      "[846]\ttrain-error:0.121772+0.006325\ttest-error:0.187408+0.015021 \n",
      "[847]\ttrain-error:0.121491+0.006462\ttest-error:0.187408+0.015021 \n",
      "[848]\ttrain-error:0.121491+0.006462\ttest-error:0.187408+0.015021 \n",
      "[849]\ttrain-error:0.121211+0.006022\ttest-error:0.187402+0.018340 \n",
      "[850]\ttrain-error:0.121211+0.006022\ttest-error:0.186284+0.014490 \n",
      "[851]\ttrain-error:0.120930+0.006323\ttest-error:0.186284+0.014490 \n",
      "[852]\ttrain-error:0.121211+0.006022\ttest-error:0.186284+0.014490 \n",
      "[853]\ttrain-error:0.121210+0.006578\ttest-error:0.187408+0.015021 \n",
      "[854]\ttrain-error:0.121771+0.006799\ttest-error:0.188525+0.016545 \n",
      "[855]\ttrain-error:0.121772+0.006688\ttest-error:0.186284+0.014490 \n",
      "[856]\ttrain-error:0.121491+0.006875\ttest-error:0.186284+0.014490 \n",
      "[857]\ttrain-error:0.121491+0.006983\ttest-error:0.187402+0.016143 \n",
      "[858]\ttrain-error:0.121491+0.006983\ttest-error:0.186278+0.017907 \n",
      "[859]\ttrain-error:0.122052+0.006429\ttest-error:0.185167+0.015655 \n",
      "[860]\ttrain-error:0.121772+0.006636\ttest-error:0.185167+0.015655 \n",
      "[861]\ttrain-error:0.121772+0.006014\ttest-error:0.185167+0.015655 \n",
      "[862]\ttrain-error:0.121772+0.006636\ttest-error:0.187408+0.017721 \n",
      "[863]\ttrain-error:0.121492+0.006221\ttest-error:0.186284+0.016903 \n",
      "[864]\ttrain-error:0.121211+0.005831\ttest-error:0.187402+0.018340 \n",
      "[865]\ttrain-error:0.122333+0.006692\ttest-error:0.186278+0.017907 \n",
      "[866]\ttrain-error:0.121772+0.006516\ttest-error:0.185154+0.018448 \n",
      "[867]\ttrain-error:0.122052+0.006901\ttest-error:0.185154+0.018448 \n",
      "[868]\ttrain-error:0.122333+0.006802\ttest-error:0.184037+0.016872 \n",
      "[869]\ttrain-error:0.122333+0.006686\ttest-error:0.185154+0.018448 \n",
      "[870]\ttrain-error:0.120649+0.006953\ttest-error:0.185154+0.018448 \n",
      "[871]\ttrain-error:0.120650+0.006959\ttest-error:0.184037+0.016872 \n",
      "[872]\ttrain-error:0.120369+0.007204\ttest-error:0.184037+0.016872 \n",
      "[873]\ttrain-error:0.120650+0.008204\ttest-error:0.184037+0.016872 \n",
      "[874]\ttrain-error:0.120930+0.008078\ttest-error:0.184037+0.016872 \n",
      "[875]\ttrain-error:0.121211+0.007738\ttest-error:0.185161+0.017476 \n",
      "[876]\ttrain-error:0.120649+0.007761\ttest-error:0.185161+0.017476 \n",
      "[877]\ttrain-error:0.121211+0.007895\ttest-error:0.184037+0.016872 \n",
      "[878]\ttrain-error:0.120930+0.007581\ttest-error:0.184037+0.016872 \n",
      "[879]\ttrain-error:0.120369+0.008558\ttest-error:0.185161+0.017476 \n",
      "[880]\ttrain-error:0.120369+0.008558\ttest-error:0.184037+0.018308 \n",
      "[881]\ttrain-error:0.119808+0.008378\ttest-error:0.185161+0.017476 \n",
      "[882]\ttrain-error:0.120089+0.008700\ttest-error:0.184037+0.018308 \n",
      "[883]\ttrain-error:0.120089+0.008700\ttest-error:0.184037+0.018308 \n",
      "[884]\ttrain-error:0.119808+0.008378\ttest-error:0.184037+0.018308 \n",
      "[885]\ttrain-error:0.120089+0.008240\ttest-error:0.184037+0.018308 \n",
      "[886]\ttrain-error:0.120089+0.008700\ttest-error:0.184037+0.018308 \n",
      "[887]\ttrain-error:0.120369+0.008558\ttest-error:0.184037+0.018308 \n",
      "[888]\ttrain-error:0.120369+0.009045\ttest-error:0.184037+0.018308 \n",
      "[889]\ttrain-error:0.120369+0.008913\ttest-error:0.185154+0.019769 \n",
      "[890]\ttrain-error:0.120369+0.009093\ttest-error:0.186278+0.018935 \n",
      "[891]\ttrain-error:0.119527+0.009043\ttest-error:0.185161+0.017476 \n",
      "[892]\ttrain-error:0.119527+0.009043\ttest-error:0.184037+0.018308 \n",
      "[893]\ttrain-error:0.119527+0.008412\ttest-error:0.185154+0.019769 \n",
      "[894]\ttrain-error:0.120088+0.007938\ttest-error:0.187395+0.020534 \n",
      "[895]\ttrain-error:0.120088+0.008558\ttest-error:0.187395+0.020534 \n",
      "[896]\ttrain-error:0.120088+0.008558\ttest-error:0.186272+0.021365 \n",
      "[897]\ttrain-error:0.120369+0.008267\ttest-error:0.185154+0.019769 \n",
      "[898]\ttrain-error:0.119808+0.008875\ttest-error:0.184031+0.019237 \n",
      "[899]\ttrain-error:0.119246+0.008756\ttest-error:0.185154+0.019769 \n",
      "[900]\ttrain-error:0.118966+0.008409\ttest-error:0.184037+0.018308 \n",
      "[901]\ttrain-error:0.119246+0.008756\ttest-error:0.185161+0.018865 \n",
      "[902]\ttrain-error:0.118965+0.008267\ttest-error:0.185161+0.018865 \n",
      "[903]\ttrain-error:0.119246+0.008620\ttest-error:0.184037+0.018308 \n",
      "[904]\ttrain-error:0.118405+0.008231\ttest-error:0.184037+0.018308 \n",
      "[905]\ttrain-error:0.117843+0.008253\ttest-error:0.184037+0.018308 \n",
      "[906]\ttrain-error:0.118685+0.007479\ttest-error:0.184037+0.018308 \n",
      "[907]\ttrain-error:0.118405+0.008420\ttest-error:0.184037+0.018308 \n",
      "[908]\ttrain-error:0.118685+0.008740\ttest-error:0.184037+0.018308 \n",
      "[909]\ttrain-error:0.119246+0.008295\ttest-error:0.184037+0.018308 \n",
      "[910]\ttrain-error:0.118685+0.008085\ttest-error:0.184037+0.018308 \n",
      "[911]\ttrain-error:0.118124+0.008778\ttest-error:0.185161+0.018865 \n",
      "[912]\ttrain-error:0.118686+0.007537\ttest-error:0.185161+0.019197 \n",
      "[913]\ttrain-error:0.117844+0.007242\ttest-error:0.185161+0.019197 \n",
      "[914]\ttrain-error:0.118686+0.007537\ttest-error:0.184037+0.018308 \n",
      "[915]\ttrain-error:0.117283+0.006409\ttest-error:0.184037+0.018308 \n",
      "[916]\ttrain-error:0.117283+0.006470\ttest-error:0.184037+0.018308 \n",
      "[917]\ttrain-error:0.116722+0.006581\ttest-error:0.181790+0.017285 \n",
      "[918]\ttrain-error:0.117283+0.007844\ttest-error:0.182914+0.017662 \n",
      "[919]\ttrain-error:0.117844+0.007127\ttest-error:0.184037+0.018308 \n",
      "[920]\ttrain-error:0.117563+0.006870\ttest-error:0.185161+0.018865 \n",
      "[921]\ttrain-error:0.117563+0.006870\ttest-error:0.185161+0.018865 \n",
      "[922]\ttrain-error:0.117563+0.006870\ttest-error:0.185161+0.018865 \n",
      "[923]\ttrain-error:0.117283+0.006650\ttest-error:0.185161+0.018865 \n",
      "[924]\ttrain-error:0.117563+0.006870\ttest-error:0.186284+0.019665 \n",
      "[925]\ttrain-error:0.117283+0.006650\ttest-error:0.184037+0.018308 \n",
      "[926]\ttrain-error:0.117844+0.006788\ttest-error:0.184037+0.018308 \n",
      "[927]\ttrain-error:0.117563+0.006395\ttest-error:0.185161+0.018865 \n",
      "[928]\ttrain-error:0.117283+0.006470\ttest-error:0.184037+0.018308 \n",
      "[929]\ttrain-error:0.117844+0.006552\ttest-error:0.184037+0.018308 \n",
      "[930]\ttrain-error:0.117002+0.006153\ttest-error:0.182914+0.017662 \n",
      "[931]\ttrain-error:0.117002+0.006704\ttest-error:0.182914+0.017662 \n",
      "[932]\ttrain-error:0.116721+0.006454\ttest-error:0.182914+0.017662 \n",
      "[933]\ttrain-error:0.117282+0.006584\ttest-error:0.182914+0.017662 \n",
      "[934]\ttrain-error:0.117282+0.006637\ttest-error:0.182914+0.017662 \n",
      "[935]\ttrain-error:0.117001+0.006872\ttest-error:0.182914+0.017662 \n",
      "[936]\ttrain-error:0.117282+0.007102\ttest-error:0.182914+0.017662 \n",
      "[937]\ttrain-error:0.117282+0.007102\ttest-error:0.182914+0.017662 \n",
      "[938]\ttrain-error:0.116721+0.007466\ttest-error:0.184037+0.018308 \n",
      "[939]\ttrain-error:0.117282+0.006578\ttest-error:0.184037+0.018308 \n",
      "[940]\ttrain-error:0.117562+0.006444\ttest-error:0.182914+0.017662 \n",
      "[941]\ttrain-error:0.117562+0.006444\ttest-error:0.182914+0.017662 \n",
      "[942]\ttrain-error:0.117562+0.006258\ttest-error:0.182914+0.017662 \n",
      "[943]\ttrain-error:0.118123+0.006502\ttest-error:0.182914+0.017662 \n",
      "[944]\ttrain-error:0.118123+0.006502\ttest-error:0.182914+0.017662 \n",
      "[945]\ttrain-error:0.117843+0.006294\ttest-error:0.184037+0.018308 \n",
      "[946]\ttrain-error:0.116440+0.007440\ttest-error:0.180666+0.016826 \n",
      "[947]\ttrain-error:0.117282+0.006922\ttest-error:0.182914+0.018015 \n",
      "[948]\ttrain-error:0.116440+0.006776\ttest-error:0.182914+0.018015 \n",
      "[949]\ttrain-error:0.115879+0.006578\ttest-error:0.182914+0.018015 \n",
      "[950]\ttrain-error:0.116440+0.006782\ttest-error:0.181790+0.017285 \n",
      "[951]\ttrain-error:0.116440+0.006782\ttest-error:0.184037+0.018308 \n",
      "[952]\ttrain-error:0.116440+0.006891\ttest-error:0.184037+0.018308 \n",
      "[953]\ttrain-error:0.116159+0.007084\ttest-error:0.185161+0.018865 \n",
      "[954]\ttrain-error:0.115879+0.007315\ttest-error:0.184037+0.018308 \n",
      "[955]\ttrain-error:0.116160+0.007034\ttest-error:0.184037+0.018308 \n",
      "[956]\ttrain-error:0.116160+0.007034\ttest-error:0.181790+0.017285 \n",
      "[957]\ttrain-error:0.116440+0.006782\ttest-error:0.181790+0.017285 \n",
      "[958]\ttrain-error:0.116160+0.007034\ttest-error:0.181790+0.017285 \n",
      "[959]\ttrain-error:0.116440+0.006782\ttest-error:0.181790+0.017285 \n",
      "[960]\ttrain-error:0.115879+0.007315\ttest-error:0.182914+0.017662 \n",
      "[961]\ttrain-error:0.116441+0.006788\ttest-error:0.184037+0.018308 \n",
      "[962]\ttrain-error:0.115599+0.006704\ttest-error:0.184037+0.018308 \n",
      "[963]\ttrain-error:0.115879+0.007315\ttest-error:0.184037+0.018308 \n",
      "[964]\ttrain-error:0.115598+0.007423\ttest-error:0.182914+0.017662 \n",
      "[965]\ttrain-error:0.115318+0.006976\ttest-error:0.182914+0.017662 \n",
      "[966]\ttrain-error:0.115598+0.007423\ttest-error:0.184037+0.016872 \n",
      "[967]\ttrain-error:0.115318+0.007571\ttest-error:0.184037+0.016872 \n",
      "[968]\ttrain-error:0.114757+0.006690\ttest-error:0.184037+0.016872 \n",
      "[969]\ttrain-error:0.115318+0.006976\ttest-error:0.184043+0.016194 \n",
      "[970]\ttrain-error:0.114757+0.006921\ttest-error:0.184037+0.018308 \n",
      "[971]\ttrain-error:0.114757+0.006921\ttest-error:0.184037+0.018308 \n",
      "[972]\ttrain-error:0.114476+0.007532\ttest-error:0.184043+0.016194 \n",
      "[973]\ttrain-error:0.114477+0.007108\ttest-error:0.184043+0.016194 \n",
      "[974]\ttrain-error:0.115598+0.006757\ttest-error:0.184043+0.016194 \n",
      "[975]\ttrain-error:0.115318+0.006919\ttest-error:0.184043+0.016194 \n",
      "[976]\ttrain-error:0.114757+0.007362\ttest-error:0.184043+0.016194 \n",
      "[977]\ttrain-error:0.115318+0.006454\ttest-error:0.184043+0.016194 \n",
      "[978]\ttrain-error:0.115038+0.006671\ttest-error:0.182920+0.017015 \n",
      "[979]\ttrain-error:0.115318+0.006868\ttest-error:0.184043+0.016194 \n",
      "[980]\ttrain-error:0.115038+0.006671\ttest-error:0.182920+0.017015 \n",
      "[981]\ttrain-error:0.115038+0.006671\ttest-error:0.182920+0.017015 \n",
      "[982]\ttrain-error:0.115318+0.006454\ttest-error:0.182920+0.017015 \n",
      "[983]\ttrain-error:0.115879+0.007102\ttest-error:0.182920+0.017015 \n",
      "[984]\ttrain-error:0.115599+0.006645\ttest-error:0.182920+0.017015 \n",
      "[985]\ttrain-error:0.115318+0.006454\ttest-error:0.184037+0.018308 \n",
      "[986]\ttrain-error:0.115037+0.006724\ttest-error:0.184037+0.018308 \n",
      "[987]\ttrain-error:0.114757+0.006572\ttest-error:0.182914+0.019366 \n",
      "[988]\ttrain-error:0.114757+0.006572\ttest-error:0.182914+0.019366 \n",
      "[989]\ttrain-error:0.114757+0.006572\ttest-error:0.184037+0.018308 \n",
      "[990]\ttrain-error:0.114757+0.006572\ttest-error:0.184037+0.018308 \n",
      "[991]\ttrain-error:0.114196+0.006992\ttest-error:0.184037+0.018308 \n",
      "[992]\ttrain-error:0.114196+0.006992\ttest-error:0.184037+0.018308 \n",
      "[993]\ttrain-error:0.114757+0.006572\ttest-error:0.181790+0.018689 \n",
      "[994]\ttrain-error:0.114196+0.006992\ttest-error:0.182914+0.019366 \n",
      "[995]\ttrain-error:0.114196+0.006992\ttest-error:0.182914+0.019366 \n",
      "[996]\ttrain-error:0.113915+0.007252\ttest-error:0.182914+0.019366 \n",
      "[997]\ttrain-error:0.114476+0.007158\ttest-error:0.182920+0.017015 \n",
      "[998]\ttrain-error:0.114476+0.007158\ttest-error:0.181796+0.016241 \n",
      "[999]\ttrain-error:0.114477+0.006768\ttest-error:0.184043+0.017685 \n",
      "[1000]\ttrain-error:0.114196+0.007053\ttest-error:0.181796+0.016241 \n",
      "[1001]\ttrain-error:0.114477+0.007538\ttest-error:0.182920+0.017015 \n",
      "[1002]\ttrain-error:0.114757+0.007260\ttest-error:0.181796+0.016625 \n",
      "[1003]\ttrain-error:0.113915+0.007877\ttest-error:0.180673+0.017642 \n",
      "[1004]\ttrain-error:0.114196+0.007637\ttest-error:0.179555+0.016448 \n",
      "[1005]\ttrain-error:0.114196+0.007637\ttest-error:0.179555+0.016448 \n",
      "[1006]\ttrain-error:0.114196+0.007637\ttest-error:0.180679+0.015019 \n",
      "[1007]\ttrain-error:0.114196+0.007637\ttest-error:0.180679+0.015019 \n",
      "[1008]\ttrain-error:0.114476+0.007427\ttest-error:0.179555+0.014402 \n",
      "[1009]\ttrain-error:0.113915+0.007149\ttest-error:0.179555+0.014402 \n",
      "[1010]\ttrain-error:0.113915+0.007149\ttest-error:0.179555+0.014402 \n",
      "[1011]\ttrain-error:0.113915+0.007524\ttest-error:0.179555+0.014402 \n",
      "[1012]\ttrain-error:0.113635+0.007345\ttest-error:0.179555+0.014402 \n",
      "[1013]\ttrain-error:0.113074+0.007108\ttest-error:0.180679+0.015019 \n",
      "[1014]\ttrain-error:0.112793+0.007381\ttest-error:0.180679+0.015019 \n",
      "[1015]\ttrain-error:0.113074+0.007218\ttest-error:0.182926+0.017094 \n",
      "[1016]\ttrain-error:0.113074+0.007218\ttest-error:0.181803+0.015933 \n",
      "[1017]\ttrain-error:0.113354+0.007682\ttest-error:0.181803+0.015933 \n",
      "[1018]\ttrain-error:0.113354+0.007682\ttest-error:0.181803+0.015933 \n",
      "[1019]\ttrain-error:0.112793+0.006769\ttest-error:0.181803+0.015933 \n",
      "[1020]\ttrain-error:0.113074+0.007218\ttest-error:0.181803+0.015933 \n",
      "[1021]\ttrain-error:0.112793+0.006769\ttest-error:0.181803+0.015933 \n",
      "[1022]\ttrain-error:0.112513+0.007099\ttest-error:0.182926+0.017094 \n",
      "[1023]\ttrain-error:0.112232+0.007863\ttest-error:0.178432+0.017330 \n",
      "[1024]\ttrain-error:0.112232+0.007863\ttest-error:0.178432+0.017330 \n",
      "[1025]\ttrain-error:0.112232+0.007863\ttest-error:0.178432+0.017330 \n",
      "[1026]\ttrain-error:0.112232+0.007863\ttest-error:0.179555+0.016060 \n",
      "[1027]\ttrain-error:0.112232+0.007863\ttest-error:0.179555+0.016060 \n",
      "[1028]\ttrain-error:0.112232+0.007863\ttest-error:0.179555+0.016060 \n",
      "[1029]\ttrain-error:0.111951+0.007421\ttest-error:0.179555+0.016060 \n",
      "[1030]\ttrain-error:0.111951+0.007421\ttest-error:0.178432+0.017330 \n",
      "[1031]\ttrain-error:0.111951+0.007421\ttest-error:0.179555+0.016060 \n",
      "[1032]\ttrain-error:0.111390+0.008422\ttest-error:0.179555+0.016060 \n",
      "[1033]\ttrain-error:0.111671+0.008651\ttest-error:0.179555+0.016060 \n",
      "[1034]\ttrain-error:0.111390+0.008233\ttest-error:0.179555+0.016060 \n",
      "[1035]\ttrain-error:0.111671+0.008043\ttest-error:0.179555+0.016060 \n",
      "[1036]\ttrain-error:0.111390+0.008233\ttest-error:0.178432+0.015402 \n",
      "[1037]\ttrain-error:0.111670+0.007989\ttest-error:0.178432+0.015402 \n",
      "[1038]\ttrain-error:0.111390+0.008233\ttest-error:0.178432+0.015402 \n",
      "[1039]\ttrain-error:0.111671+0.007538\ttest-error:0.179555+0.016060 \n",
      "[1040]\ttrain-error:0.111671+0.008043\ttest-error:0.178432+0.015402 \n",
      "[1041]\ttrain-error:0.111671+0.008043\ttest-error:0.178432+0.015402 \n",
      "[1042]\ttrain-error:0.111109+0.007981\ttest-error:0.177308+0.014629 \n",
      "[1043]\ttrain-error:0.111390+0.007796\ttest-error:0.178432+0.015402 \n",
      "[1044]\ttrain-error:0.111390+0.007796\ttest-error:0.178432+0.015402 \n",
      "[1045]\ttrain-error:0.111671+0.007538\ttest-error:0.179555+0.016060 \n",
      "[1046]\ttrain-error:0.111110+0.007582\ttest-error:0.178432+0.015402 \n",
      "[1047]\ttrain-error:0.111110+0.007582\ttest-error:0.178432+0.015402 \n",
      "[1048]\ttrain-error:0.111110+0.007372\ttest-error:0.178432+0.015402 \n",
      "[1049]\ttrain-error:0.111390+0.007796\ttest-error:0.178432+0.015402 \n",
      "[1050]\ttrain-error:0.111110+0.007582\ttest-error:0.178432+0.015402 \n",
      "[1051]\ttrain-error:0.111110+0.007582\ttest-error:0.177308+0.015054 \n",
      "[1052]\ttrain-error:0.111390+0.007328\ttest-error:0.178432+0.016201 \n",
      "[1053]\ttrain-error:0.110830+0.007134\ttest-error:0.179555+0.016448 \n",
      "[1054]\ttrain-error:0.111110+0.007582\ttest-error:0.179555+0.016448 \n",
      "[1055]\ttrain-error:0.110830+0.007818\ttest-error:0.178432+0.015402 \n",
      "[1056]\ttrain-error:0.111110+0.007582\ttest-error:0.178432+0.015402 \n",
      "[1057]\ttrain-error:0.110830+0.007818\ttest-error:0.178432+0.015402 \n",
      "[1058]\ttrain-error:0.110549+0.007374\ttest-error:0.178432+0.015402 \n",
      "[1059]\ttrain-error:0.111110+0.007582\ttest-error:0.178432+0.015402 \n",
      "[1060]\ttrain-error:0.111110+0.007582\ttest-error:0.178432+0.015402 \n",
      "[1061]\ttrain-error:0.110830+0.007818\ttest-error:0.178432+0.015402 \n",
      "[1062]\ttrain-error:0.110549+0.007374\ttest-error:0.179555+0.016448 \n",
      "[1063]\ttrain-error:0.111110+0.007582\ttest-error:0.179555+0.016448 \n",
      "[1064]\ttrain-error:0.111110+0.007582\ttest-error:0.179555+0.016448 \n",
      "[1065]\ttrain-error:0.111671+0.008043\ttest-error:0.179555+0.016448 \n",
      "[1066]\ttrain-error:0.110829+0.007763\ttest-error:0.180679+0.015434 \n",
      "[1067]\ttrain-error:0.111109+0.007981\ttest-error:0.180679+0.015434 \n",
      "[1068]\ttrain-error:0.111109+0.007981\ttest-error:0.180679+0.015434 \n",
      "[1069]\ttrain-error:0.110829+0.007557\ttest-error:0.180679+0.015434 \n",
      "[1070]\ttrain-error:0.110829+0.007557\ttest-error:0.180679+0.015434 \n",
      "[1071]\ttrain-error:0.110829+0.008056\ttest-error:0.180679+0.015434 \n",
      "[1072]\ttrain-error:0.111110+0.007832\ttest-error:0.180679+0.015434 \n",
      "[1073]\ttrain-error:0.110268+0.007375\ttest-error:0.180679+0.015434 \n",
      "[1074]\ttrain-error:0.110268+0.007375\ttest-error:0.180679+0.015434 \n",
      "[1075]\ttrain-error:0.110829+0.007557\ttest-error:0.180679+0.015434 \n",
      "[1076]\ttrain-error:0.110268+0.007533\ttest-error:0.179555+0.016448 \n",
      "[1077]\ttrain-error:0.110829+0.007557\ttest-error:0.179555+0.016448 \n",
      "[1078]\ttrain-error:0.110829+0.007557\ttest-error:0.179555+0.016448 \n",
      "[1079]\ttrain-error:0.110829+0.007557\ttest-error:0.179555+0.016448 \n",
      "[1080]\ttrain-error:0.110829+0.007557\ttest-error:0.179555+0.016448 \n",
      "[1081]\ttrain-error:0.110549+0.007315\ttest-error:0.179555+0.016448 \n",
      "[1082]\ttrain-error:0.110268+0.007109\ttest-error:0.180679+0.015434 \n",
      "[1083]\ttrain-error:0.110268+0.006769\ttest-error:0.180679+0.015434 \n",
      "[1084]\ttrain-error:0.110268+0.006287\ttest-error:0.180679+0.015434 \n",
      "[1085]\ttrain-error:0.110268+0.006287\ttest-error:0.179555+0.016448 \n",
      "[1086]\ttrain-error:0.109988+0.006032\ttest-error:0.180679+0.015434 \n",
      "[1087]\ttrain-error:0.110830+0.006499\ttest-error:0.178432+0.015402 \n",
      "[1088]\ttrain-error:0.110549+0.006279\ttest-error:0.180679+0.015434 \n",
      "[1089]\ttrain-error:0.110549+0.006279\ttest-error:0.180679+0.015434 \n",
      "[1090]\ttrain-error:0.110268+0.006478\ttest-error:0.180679+0.015434 \n",
      "[1091]\ttrain-error:0.109987+0.006653\ttest-error:0.180679+0.015434 \n",
      "[1092]\ttrain-error:0.109987+0.006770\ttest-error:0.180679+0.015434 \n",
      "[1093]\ttrain-error:0.110268+0.006997\ttest-error:0.180679+0.015434 \n",
      "[1094]\ttrain-error:0.109987+0.006770\ttest-error:0.179555+0.014402 \n",
      "[1095]\ttrain-error:0.111391+0.007165\ttest-error:0.179555+0.016448 \n",
      "[1096]\ttrain-error:0.109987+0.006653\ttest-error:0.179555+0.014402 \n",
      "[1097]\ttrain-error:0.109987+0.007638\ttest-error:0.179555+0.014402 \n",
      "[1098]\ttrain-error:0.109987+0.006993\ttest-error:0.180679+0.013701 \n",
      "[1099]\ttrain-error:0.109707+0.007150\ttest-error:0.180679+0.013701 \n",
      "[1100]\ttrain-error:0.109707+0.006869\ttest-error:0.180679+0.013701 \n",
      "[1101]\ttrain-error:0.109426+0.006673\ttest-error:0.179555+0.016448 \n",
      "[1102]\ttrain-error:0.109707+0.006270\ttest-error:0.179555+0.016448 \n",
      "[1103]\ttrain-error:0.109426+0.006433\ttest-error:0.180679+0.015434 \n",
      "[1104]\ttrain-error:0.109987+0.007104\ttest-error:0.179555+0.014402 \n",
      "[1105]\ttrain-error:0.110548+0.007152\ttest-error:0.178432+0.015402 \n",
      "[1106]\ttrain-error:0.110829+0.007452\ttest-error:0.178432+0.015402 \n",
      "[1107]\ttrain-error:0.110548+0.007677\ttest-error:0.178432+0.015402 \n",
      "[1108]\ttrain-error:0.110548+0.007779\ttest-error:0.178432+0.015402 \n",
      "[1109]\ttrain-error:0.109987+0.007586\ttest-error:0.178432+0.015402 \n",
      "[1110]\ttrain-error:0.110548+0.007677\ttest-error:0.178432+0.015402 \n",
      "[1111]\ttrain-error:0.110548+0.008269\ttest-error:0.178432+0.015402 \n",
      "[1112]\ttrain-error:0.110548+0.007779\ttest-error:0.178432+0.015402 \n",
      "[1113]\ttrain-error:0.110268+0.007890\ttest-error:0.178432+0.015402 \n",
      "[1114]\ttrain-error:0.110548+0.007677\ttest-error:0.178432+0.015402 \n",
      "[1115]\ttrain-error:0.110548+0.008269\ttest-error:0.178432+0.015402 \n",
      "[1116]\ttrain-error:0.110548+0.008269\ttest-error:0.178432+0.015402 \n",
      "[1117]\ttrain-error:0.110268+0.007890\ttest-error:0.178432+0.015402 \n",
      "[1118]\ttrain-error:0.110268+0.008468\ttest-error:0.178432+0.015402 \n",
      "[1119]\ttrain-error:0.110268+0.008468\ttest-error:0.178432+0.015402 \n",
      "[1120]\ttrain-error:0.110829+0.008576\ttest-error:0.178432+0.015402 \n",
      "[1121]\ttrain-error:0.110548+0.008822\ttest-error:0.178432+0.015402 \n",
      "[1122]\ttrain-error:0.109987+0.008137\ttest-error:0.179555+0.014402 \n",
      "[1123]\ttrain-error:0.109426+0.007557\ttest-error:0.178438+0.013293 \n",
      "[1124]\ttrain-error:0.109426+0.007557\ttest-error:0.179555+0.014402 \n",
      "[1125]\ttrain-error:0.109707+0.007367\ttest-error:0.178432+0.013665 \n",
      "[1126]\ttrain-error:0.109146+0.007152\ttest-error:0.179555+0.014402 \n",
      "[1127]\ttrain-error:0.109426+0.006905\ttest-error:0.178432+0.013665 \n",
      "[1128]\ttrain-error:0.108865+0.006769\ttest-error:0.179555+0.014402 \n",
      "[1129]\ttrain-error:0.109987+0.007587\ttest-error:0.177308+0.014629 \n",
      "[1130]\ttrain-error:0.109987+0.007104\ttest-error:0.177308+0.014629 \n",
      "[1131]\ttrain-error:0.109987+0.007104\ttest-error:0.177308+0.014629 \n",
      "[1132]\ttrain-error:0.109707+0.007259\ttest-error:0.177308+0.015054 \n",
      "[1133]\ttrain-error:0.109707+0.007259\ttest-error:0.178432+0.014119 \n",
      "[1134]\ttrain-error:0.110268+0.007940\ttest-error:0.176191+0.013816 \n",
      "[1135]\ttrain-error:0.110829+0.007500\ttest-error:0.176191+0.011849 \n",
      "[1136]\ttrain-error:0.110268+0.007637\ttest-error:0.177314+0.011325 \n",
      "[1137]\ttrain-error:0.109426+0.007068\ttest-error:0.177314+0.011325 \n",
      "[1138]\ttrain-error:0.109426+0.007068\ttest-error:0.177314+0.011325 \n",
      "[1139]\ttrain-error:0.110829+0.006904\ttest-error:0.176191+0.011849 \n",
      "[1140]\ttrain-error:0.109707+0.007259\ttest-error:0.177314+0.012389 \n",
      "[1141]\ttrain-error:0.109146+0.006698\ttest-error:0.178438+0.011783 \n",
      "[1142]\ttrain-error:0.109146+0.006698\ttest-error:0.178438+0.011783 \n",
      "[1143]\ttrain-error:0.109146+0.006579\ttest-error:0.178432+0.013665 \n",
      "[1144]\ttrain-error:0.109146+0.006579\ttest-error:0.179555+0.013021 \n",
      "[1145]\ttrain-error:0.109426+0.006905\ttest-error:0.178432+0.013665 \n",
      "[1146]\ttrain-error:0.109707+0.007259\ttest-error:0.176185+0.015038 \n",
      "[1147]\ttrain-error:0.109707+0.007259\ttest-error:0.176185+0.015038 \n",
      "[1148]\ttrain-error:0.109707+0.007259\ttest-error:0.177308+0.015468 \n",
      "[1149]\ttrain-error:0.109988+0.006593\ttest-error:0.175067+0.013707 \n",
      "[1150]\ttrain-error:0.109988+0.006593\ttest-error:0.175067+0.013707 \n",
      "[1151]\ttrain-error:0.110268+0.006884\ttest-error:0.176191+0.011849 \n",
      "[1152]\ttrain-error:0.109988+0.006593\ttest-error:0.173944+0.013028 \n",
      "[1153]\ttrain-error:0.109707+0.006812\ttest-error:0.173944+0.013028 \n",
      "[1154]\ttrain-error:0.109707+0.006760\ttest-error:0.175067+0.013707 \n",
      "[1155]\ttrain-error:0.109707+0.006760\ttest-error:0.173944+0.013028 \n",
      "[1156]\ttrain-error:0.108865+0.006884\ttest-error:0.175067+0.013707 \n",
      "[1157]\ttrain-error:0.109146+0.006703\ttest-error:0.175067+0.013707 \n",
      "[1158]\ttrain-error:0.109146+0.006703\ttest-error:0.175067+0.013707 \n",
      "[1159]\ttrain-error:0.108585+0.007055\ttest-error:0.175067+0.013707 \n",
      "[1160]\ttrain-error:0.108865+0.006884\ttest-error:0.175067+0.013707 \n",
      "[1161]\ttrain-error:0.109426+0.007661\ttest-error:0.175067+0.013707 \n",
      "[1162]\ttrain-error:0.109146+0.007261\ttest-error:0.176191+0.013352 \n",
      "[1163]\ttrain-error:0.109146+0.007261\ttest-error:0.176191+0.013352 \n",
      "[1164]\ttrain-error:0.109146+0.007261\ttest-error:0.177308+0.014629 \n",
      "[1165]\ttrain-error:0.109146+0.007261\ttest-error:0.178432+0.014986 \n",
      "[1166]\ttrain-error:0.109145+0.007880\ttest-error:0.178432+0.014986 \n",
      "[1167]\ttrain-error:0.109145+0.007779\ttest-error:0.177314+0.013834 \n",
      "[1168]\ttrain-error:0.109426+0.008154\ttest-error:0.173944+0.013028 \n",
      "[1169]\ttrain-error:0.109426+0.008154\ttest-error:0.177314+0.011325 \n",
      "[1170]\ttrain-error:0.109426+0.008154\ttest-error:0.176191+0.010731 \n",
      "[1171]\ttrain-error:0.108865+0.007940\ttest-error:0.178438+0.011783 \n",
      "[1172]\ttrain-error:0.109145+0.008270\ttest-error:0.177308+0.013271 \n",
      "[1173]\ttrain-error:0.109146+0.008274\ttest-error:0.178432+0.012707 \n",
      "[1174]\ttrain-error:0.109146+0.007733\ttest-error:0.179555+0.013021 \n",
      "[1175]\ttrain-error:0.109426+0.008061\ttest-error:0.179555+0.013021 \n",
      "[1176]\ttrain-error:0.109145+0.008270\ttest-error:0.179555+0.013021 \n",
      "[1177]\ttrain-error:0.109145+0.008222\ttest-error:0.179555+0.013021 \n",
      "[1178]\ttrain-error:0.109145+0.008222\ttest-error:0.179555+0.013021 \n",
      "[1179]\ttrain-error:0.108865+0.007381\ttest-error:0.178432+0.013665 \n",
      "[1180]\ttrain-error:0.108585+0.006999\ttest-error:0.178432+0.013665 \n",
      "[1181]\ttrain-error:0.108585+0.006999\ttest-error:0.178432+0.013665 \n",
      "[1182]\ttrain-error:0.108584+0.006993\ttest-error:0.179555+0.014402 \n",
      "[1183]\ttrain-error:0.108584+0.006993\ttest-error:0.178432+0.014119 \n",
      "[1184]\ttrain-error:0.108023+0.007453\ttest-error:0.177308+0.013271 \n",
      "[1185]\ttrain-error:0.108584+0.007587\ttest-error:0.178432+0.012707 \n",
      "[1186]\ttrain-error:0.108304+0.007782\ttest-error:0.179555+0.013497 \n",
      "[1187]\ttrain-error:0.108865+0.007322\ttest-error:0.179555+0.013497 \n",
      "[1188]\ttrain-error:0.108585+0.006999\ttest-error:0.179555+0.013497 \n",
      "[1189]\ttrain-error:0.108584+0.007587\ttest-error:0.179555+0.013497 \n",
      "[1190]\ttrain-error:0.108303+0.007828\ttest-error:0.180679+0.014593 \n",
      "[1191]\ttrain-error:0.108303+0.007977\ttest-error:0.180679+0.014593 \n",
      "[1192]\ttrain-error:0.108303+0.007977\ttest-error:0.179555+0.013497 \n",
      "[1193]\ttrain-error:0.108303+0.007977\ttest-error:0.179555+0.013497 \n",
      "[1194]\ttrain-error:0.108303+0.007977\ttest-error:0.179555+0.013497 \n",
      "[1195]\ttrain-error:0.108304+0.007313\ttest-error:0.179555+0.013497 \n",
      "[1196]\ttrain-error:0.108304+0.007313\ttest-error:0.180679+0.014593 \n",
      "[1197]\ttrain-error:0.108584+0.007741\ttest-error:0.180679+0.014593 \n",
      "[1198]\ttrain-error:0.108584+0.007741\ttest-error:0.180679+0.014593 \n",
      "[1199]\ttrain-error:0.107742+0.007979\ttest-error:0.180679+0.014593 \n",
      "[1200]\ttrain-error:0.107742+0.007147\ttest-error:0.180679+0.014593 \n",
      "[1201]\ttrain-error:0.108303+0.007362\ttest-error:0.178432+0.012707 \n",
      "[1202]\ttrain-error:0.107462+0.007534\ttest-error:0.180679+0.014593 \n",
      "[1203]\ttrain-error:0.108023+0.007758\ttest-error:0.180679+0.014593 \n",
      "[1204]\ttrain-error:0.107742+0.007310\ttest-error:0.180679+0.014593 \n",
      "[1205]\ttrain-error:0.107462+0.007534\ttest-error:0.180679+0.014593 \n",
      "[1206]\ttrain-error:0.107462+0.007534\ttest-error:0.179555+0.013497 \n",
      "[1207]\ttrain-error:0.107743+0.007316\ttest-error:0.179555+0.013497 \n",
      "[1208]\ttrain-error:0.108024+0.007135\ttest-error:0.179555+0.013497 \n",
      "[1209]\ttrain-error:0.108304+0.007372\ttest-error:0.179555+0.013497 \n",
      "[1210]\ttrain-error:0.108024+0.007135\ttest-error:0.180679+0.011714 \n",
      "[1211]\ttrain-error:0.107743+0.007316\ttest-error:0.180679+0.011714 \n",
      "[1212]\ttrain-error:0.108023+0.007558\ttest-error:0.180679+0.011714 \n",
      "[1213]\ttrain-error:0.107742+0.007147\ttest-error:0.180679+0.011714 \n",
      "[1214]\ttrain-error:0.107462+0.006879\ttest-error:0.180679+0.011714 \n",
      "[1215]\ttrain-error:0.107462+0.006224\ttest-error:0.180673+0.014928 \n",
      "[1216]\ttrain-error:0.107462+0.006224\ttest-error:0.180679+0.014593 \n",
      "[1217]\ttrain-error:0.107182+0.006473\ttest-error:0.181803+0.012864 \n",
      "[1218]\ttrain-error:0.107181+0.006467\ttest-error:0.181803+0.012864 \n",
      "[1219]\ttrain-error:0.107181+0.006467\ttest-error:0.180679+0.011714 \n",
      "[1220]\ttrain-error:0.107181+0.006467\ttest-error:0.181796+0.013243 \n",
      "[1221]\ttrain-error:0.106900+0.006749\ttest-error:0.180673+0.012638 \n",
      "[1222]\ttrain-error:0.106900+0.006749\ttest-error:0.179549+0.014306 \n",
      "[1223]\ttrain-error:0.106900+0.006749\ttest-error:0.180673+0.014928 \n",
      "[1224]\ttrain-error:0.106620+0.006366\ttest-error:0.181796+0.015029 \n",
      "[1225]\ttrain-error:0.106900+0.006749\ttest-error:0.182920+0.013262 \n",
      "[1226]\ttrain-error:0.106900+0.006749\ttest-error:0.181796+0.013243 \n",
      "[1227]\ttrain-error:0.107462+0.006281\ttest-error:0.181796+0.013243 \n",
      "[1228]\ttrain-error:0.107461+0.006399\ttest-error:0.181796+0.013243 \n",
      "[1229]\ttrain-error:0.107461+0.005471\ttest-error:0.181796+0.013243 \n",
      "[1230]\ttrain-error:0.107181+0.005334\ttest-error:0.182920+0.014182 \n",
      "[1231]\ttrain-error:0.107181+0.005544\ttest-error:0.181796+0.013243 \n",
      "[1232]\ttrain-error:0.107462+0.005182\ttest-error:0.180673+0.013601 \n",
      "[1233]\ttrain-error:0.107181+0.005334\ttest-error:0.181796+0.013243 \n",
      "[1234]\ttrain-error:0.107181+0.005334\ttest-error:0.181796+0.013243 \n",
      "[1235]\ttrain-error:0.107181+0.005334\ttest-error:0.181796+0.013243 \n",
      "[1236]\ttrain-error:0.107181+0.005334\ttest-error:0.181796+0.013243 \n",
      "[1237]\ttrain-error:0.107181+0.005334\ttest-error:0.180673+0.014928 \n",
      "[1238]\ttrain-error:0.107462+0.005182\ttest-error:0.180679+0.011714 \n",
      "[1239]\ttrain-error:0.107181+0.005334\ttest-error:0.179562+0.010441 \n",
      "[1240]\ttrain-error:0.107181+0.005334\ttest-error:0.179562+0.010441 \n",
      "[1241]\ttrain-error:0.107181+0.005334\ttest-error:0.177314+0.009507 \n",
      "[1242]\ttrain-error:0.107462+0.005689\ttest-error:0.179562+0.010441 \n",
      "[1243]\ttrain-error:0.107462+0.005689\ttest-error:0.178438+0.010657 \n",
      "[1244]\ttrain-error:0.107742+0.005534\ttest-error:0.178432+0.013665 \n",
      "[1245]\ttrain-error:0.107461+0.006337\ttest-error:0.179562+0.010441 \n",
      "[1246]\ttrain-error:0.107742+0.006198\ttest-error:0.178438+0.010657 \n",
      "[1247]\ttrain-error:0.107742+0.006198\ttest-error:0.179562+0.010441 \n",
      "[1248]\ttrain-error:0.107461+0.005887\ttest-error:0.181809+0.010243 \n",
      "[1249]\ttrain-error:0.106900+0.005672\ttest-error:0.180685+0.010095 \n",
      "[1250]\ttrain-error:0.107181+0.005544\ttest-error:0.180685+0.010095 \n",
      "[1251]\ttrain-error:0.106900+0.005672\ttest-error:0.180685+0.010095 \n",
      "[1252]\ttrain-error:0.107181+0.005544\ttest-error:0.181809+0.010243 \n",
      "[1253]\ttrain-error:0.107181+0.005544\ttest-error:0.181809+0.010243 \n",
      "[1254]\ttrain-error:0.106900+0.005672\ttest-error:0.182926+0.011318 \n",
      "[1255]\ttrain-error:0.106619+0.006043\ttest-error:0.181809+0.010243 \n",
      "[1256]\ttrain-error:0.106619+0.006043\ttest-error:0.180685+0.010095 \n",
      "[1257]\ttrain-error:0.106900+0.005672\ttest-error:0.181803+0.011296 \n",
      "[1258]\ttrain-error:0.106900+0.005672\ttest-error:0.180685+0.010095 \n",
      "[1259]\ttrain-error:0.106619+0.006043\ttest-error:0.180685+0.010095 \n",
      "[1260]\ttrain-error:0.106900+0.005936\ttest-error:0.180685+0.010095 \n",
      "[1261]\ttrain-error:0.106900+0.005936\ttest-error:0.180685+0.010095 \n",
      "[1262]\ttrain-error:0.106900+0.005936\ttest-error:0.180685+0.010095 \n",
      "[1263]\ttrain-error:0.106619+0.005639\ttest-error:0.180685+0.010095 \n",
      "[1264]\ttrain-error:0.106900+0.005239\ttest-error:0.180685+0.010095 \n",
      "[1265]\ttrain-error:0.106619+0.005639\ttest-error:0.181803+0.011296 \n",
      "[1266]\ttrain-error:0.106619+0.005639\ttest-error:0.181809+0.010243 \n",
      "[1267]\ttrain-error:0.106900+0.005239\ttest-error:0.181809+0.010243 \n",
      "[1268]\ttrain-error:0.106900+0.005239\ttest-error:0.181809+0.010243 \n",
      "[1269]\ttrain-error:0.106620+0.004899\ttest-error:0.180685+0.009449 \n",
      "[1270]\ttrain-error:0.106620+0.004899\ttest-error:0.179562+0.009152 \n",
      "[1271]\ttrain-error:0.106620+0.004899\ttest-error:0.180685+0.010095 \n",
      "[1272]\ttrain-error:0.106620+0.004899\ttest-error:0.180685+0.010095 \n",
      "[1273]\ttrain-error:0.106620+0.004899\ttest-error:0.180685+0.010095 \n",
      "[1274]\ttrain-error:0.106339+0.004603\ttest-error:0.180685+0.009449 \n",
      "[1275]\ttrain-error:0.106059+0.004789\ttest-error:0.180685+0.009449 \n",
      "[1276]\ttrain-error:0.106059+0.005183\ttest-error:0.180685+0.009449 \n",
      "[1277]\ttrain-error:0.106339+0.005090\ttest-error:0.180685+0.009449 \n",
      "[1278]\ttrain-error:0.106339+0.005090\ttest-error:0.179562+0.009152 \n",
      "[1279]\ttrain-error:0.106059+0.005333\ttest-error:0.180685+0.009449 \n",
      "[1280]\ttrain-error:0.105778+0.005622\ttest-error:0.180685+0.009449 \n",
      "[1281]\ttrain-error:0.105778+0.005622\ttest-error:0.180685+0.009449 \n",
      "[1282]\ttrain-error:0.105497+0.005943\ttest-error:0.180685+0.009449 \n",
      "[1283]\ttrain-error:0.105498+0.005321\ttest-error:0.180685+0.009449 \n",
      "[1284]\ttrain-error:0.105778+0.005622\ttest-error:0.180685+0.009449 \n",
      "[1285]\ttrain-error:0.105778+0.005622\ttest-error:0.179562+0.009152 \n",
      "[1286]\ttrain-error:0.105778+0.005622\ttest-error:0.180679+0.010581 \n",
      "[1287]\ttrain-error:0.105498+0.005679\ttest-error:0.179562+0.009152 \n",
      "[1288]\ttrain-error:0.105498+0.005679\ttest-error:0.179562+0.009152 \n",
      "[1289]\ttrain-error:0.105498+0.006145\ttest-error:0.179562+0.009152 \n",
      "[1290]\ttrain-error:0.104937+0.006083\ttest-error:0.179562+0.009152 \n",
      "[1291]\ttrain-error:0.104937+0.006083\ttest-error:0.179562+0.009152 \n",
      "[1292]\ttrain-error:0.104937+0.006083\ttest-error:0.179562+0.009152 \n",
      "[1293]\ttrain-error:0.105217+0.006310\ttest-error:0.179562+0.009152 \n",
      "[1294]\ttrain-error:0.105217+0.006310\ttest-error:0.179562+0.009152 \n",
      "[1295]\ttrain-error:0.105217+0.006310\ttest-error:0.179562+0.009152 \n",
      "[1296]\ttrain-error:0.105217+0.006310\ttest-error:0.179562+0.009152 \n",
      "[1297]\ttrain-error:0.104937+0.006580\ttest-error:0.179562+0.009152 \n",
      "[1298]\ttrain-error:0.105779+0.006412\ttest-error:0.179562+0.009152 \n",
      "[1299]\ttrain-error:0.104937+0.006018\ttest-error:0.179562+0.009152 \n",
      "[1300]\ttrain-error:0.105217+0.006310\ttest-error:0.179562+0.009152 \n",
      "[1301]\ttrain-error:0.105498+0.006086\ttest-error:0.179562+0.009152 \n",
      "[1302]\ttrain-error:0.104937+0.005404\ttest-error:0.179562+0.009152 \n",
      "[1303]\ttrain-error:0.105498+0.006086\ttest-error:0.178438+0.009398 \n",
      "[1304]\ttrain-error:0.104937+0.005404\ttest-error:0.179562+0.009152 \n",
      "[1305]\ttrain-error:0.105217+0.006310\ttest-error:0.179562+0.009152 \n",
      "[1306]\ttrain-error:0.105498+0.006086\ttest-error:0.179562+0.009152 \n",
      "[1307]\ttrain-error:0.105217+0.006310\ttest-error:0.178438+0.009398 \n",
      "[1308]\ttrain-error:0.104937+0.005470\ttest-error:0.179562+0.009152 \n",
      "[1309]\ttrain-error:0.104937+0.005470\ttest-error:0.179562+0.009152 \n",
      "[1310]\ttrain-error:0.104937+0.005470\ttest-error:0.179562+0.009152 \n",
      "[1311]\ttrain-error:0.105779+0.005349\ttest-error:0.178438+0.009398 \n",
      "[1312]\ttrain-error:0.105779+0.005349\ttest-error:0.178438+0.009398 \n",
      "[1313]\ttrain-error:0.105498+0.005545\ttest-error:0.178438+0.009398 \n",
      "[1314]\ttrain-error:0.105498+0.005545\ttest-error:0.179562+0.009818 \n",
      "[1315]\ttrain-error:0.105498+0.005545\ttest-error:0.179562+0.009818 \n",
      "[1316]\ttrain-error:0.105498+0.005545\ttest-error:0.179562+0.009818 \n",
      "[1317]\ttrain-error:0.105218+0.005225\ttest-error:0.178438+0.009398 \n",
      "[1318]\ttrain-error:0.104937+0.005404\ttest-error:0.178438+0.009398 \n",
      "[1319]\ttrain-error:0.104657+0.005044\ttest-error:0.180685+0.009449 \n",
      "[1320]\ttrain-error:0.104937+0.005404\ttest-error:0.179562+0.009818 \n",
      "[1321]\ttrain-error:0.105218+0.005728\ttest-error:0.179562+0.009818 \n",
      "[1322]\ttrain-error:0.104937+0.006018\ttest-error:0.178438+0.009398 \n",
      "[1323]\ttrain-error:0.104937+0.006018\ttest-error:0.177314+0.008818 \n",
      "[1324]\ttrain-error:0.104937+0.006018\ttest-error:0.178438+0.009398 \n",
      "[1325]\ttrain-error:0.104656+0.005627\ttest-error:0.177314+0.008818 \n",
      "[1326]\ttrain-error:0.104656+0.005627\ttest-error:0.178438+0.009398 \n",
      "[1327]\ttrain-error:0.104656+0.005627\ttest-error:0.178438+0.009398 \n",
      "[1328]\ttrain-error:0.104656+0.005114\ttest-error:0.178438+0.009398 \n",
      "[1329]\ttrain-error:0.104656+0.005114\ttest-error:0.178438+0.009398 \n",
      "[1330]\ttrain-error:0.104376+0.005342\ttest-error:0.178438+0.009398 \n",
      "[1331]\ttrain-error:0.104376+0.005342\ttest-error:0.177314+0.008818 \n",
      "[1332]\ttrain-error:0.104657+0.005122\ttest-error:0.177314+0.008818 \n",
      "[1333]\ttrain-error:0.104376+0.005342\ttest-error:0.177314+0.008818 \n",
      "[1334]\ttrain-error:0.104657+0.005122\ttest-error:0.177314+0.008818 \n",
      "[1335]\ttrain-error:0.104657+0.005122\ttest-error:0.177314+0.008818 \n",
      "[1336]\ttrain-error:0.104937+0.004948\ttest-error:0.178438+0.008701 \n",
      "[1337]\ttrain-error:0.104937+0.004948\ttest-error:0.178438+0.008701 \n",
      "[1338]\ttrain-error:0.104937+0.004948\ttest-error:0.179562+0.009152 \n",
      "[1339]\ttrain-error:0.104656+0.005191\ttest-error:0.180679+0.010581 \n",
      "[1340]\ttrain-error:0.104937+0.005470\ttest-error:0.179555+0.010316 \n",
      "[1341]\ttrain-error:0.104095+0.005247\ttest-error:0.180679+0.010581 \n",
      "[1342]\ttrain-error:0.104376+0.005046\ttest-error:0.179562+0.009152 \n",
      "[1343]\ttrain-error:0.104937+0.005548\ttest-error:0.178438+0.008701 \n",
      "[1344]\ttrain-error:0.105218+0.005930\ttest-error:0.176191+0.008790 \n",
      "[1345]\ttrain-error:0.105218+0.005930\ttest-error:0.176191+0.008790 \n",
      "[1346]\ttrain-error:0.104657+0.005703\ttest-error:0.176191+0.008790 \n",
      "[1347]\ttrain-error:0.104937+0.006147\ttest-error:0.177314+0.008818 \n",
      "[1348]\ttrain-error:0.104376+0.005901\ttest-error:0.176191+0.008790 \n",
      "[1349]\ttrain-error:0.104937+0.006580\ttest-error:0.176191+0.008790 \n",
      "[1350]\ttrain-error:0.104656+0.006225\ttest-error:0.176191+0.008790 \n",
      "[1351]\ttrain-error:0.104656+0.005765\ttest-error:0.176191+0.008790 \n",
      "[1352]\ttrain-error:0.104937+0.006024\ttest-error:0.176191+0.008790 \n",
      "[1353]\ttrain-error:0.104376+0.005487\ttest-error:0.176191+0.008790 \n",
      "[1354]\ttrain-error:0.104377+0.004895\ttest-error:0.176191+0.008790 \n",
      "[1355]\ttrain-error:0.104657+0.005205\ttest-error:0.176191+0.008790 \n",
      "[1356]\ttrain-error:0.104096+0.005032\ttest-error:0.176191+0.008790 \n",
      "[1357]\ttrain-error:0.103254+0.005493\ttest-error:0.176191+0.008790 \n",
      "[1358]\ttrain-error:0.102693+0.004625\ttest-error:0.176191+0.008790 \n",
      "[1359]\ttrain-error:0.103535+0.004365\ttest-error:0.176191+0.008790 \n",
      "[1360]\ttrain-error:0.103535+0.005113\ttest-error:0.176191+0.008790 \n",
      "[1361]\ttrain-error:0.104096+0.004633\ttest-error:0.176191+0.008790 \n",
      "[1362]\ttrain-error:0.104096+0.004092\ttest-error:0.176191+0.008790 \n",
      "[1363]\ttrain-error:0.103816+0.003856\ttest-error:0.176191+0.008790 \n",
      "[1364]\ttrain-error:0.104377+0.004732\ttest-error:0.176191+0.008790 \n",
      "[1365]\ttrain-error:0.103535+0.004542\ttest-error:0.176191+0.008790 \n",
      "[1366]\ttrain-error:0.104377+0.004732\ttest-error:0.176191+0.008790 \n",
      "[1367]\ttrain-error:0.103535+0.004964\ttest-error:0.177314+0.008818 \n",
      "[1368]\ttrain-error:0.103254+0.004483\ttest-error:0.176191+0.008790 \n",
      "[1369]\ttrain-error:0.102693+0.004280\ttest-error:0.176191+0.008790 \n",
      "[1370]\ttrain-error:0.102693+0.004280\ttest-error:0.176191+0.008790 \n",
      "[1371]\ttrain-error:0.103535+0.005120\ttest-error:0.176191+0.008790 \n",
      "[1372]\ttrain-error:0.103816+0.005240\ttest-error:0.176191+0.008790 \n",
      "[1373]\ttrain-error:0.103255+0.004394\ttest-error:0.177314+0.008818 \n",
      "[1374]\ttrain-error:0.103815+0.004685\ttest-error:0.177314+0.008818 \n",
      "[1375]\ttrain-error:0.103255+0.004394\ttest-error:0.177314+0.008818 \n",
      "[1376]\ttrain-error:0.102974+0.004476\ttest-error:0.176191+0.008790 \n",
      "[1377]\ttrain-error:0.102974+0.004732\ttest-error:0.176191+0.010731 \n",
      "[1378]\ttrain-error:0.103254+0.004385\ttest-error:0.176191+0.008790 \n",
      "[1379]\ttrain-error:0.102973+0.004554\ttest-error:0.175067+0.010590 \n",
      "[1380]\ttrain-error:0.102412+0.004236\ttest-error:0.175067+0.010590 \n",
      "[1381]\ttrain-error:0.102693+0.004709\ttest-error:0.176191+0.010731 \n",
      "[1382]\ttrain-error:0.102693+0.004709\ttest-error:0.176191+0.010731 \n",
      "[1383]\ttrain-error:0.102412+0.004592\ttest-error:0.177314+0.011325 \n",
      "[1384]\ttrain-error:0.102693+0.004633\ttest-error:0.177314+0.011325 \n",
      "[1385]\ttrain-error:0.102413+0.004769\ttest-error:0.177314+0.011325 \n",
      "[1386]\ttrain-error:0.102693+0.004881\ttest-error:0.176191+0.010731 \n",
      "[1387]\ttrain-error:0.102693+0.004881\ttest-error:0.176191+0.010731 \n",
      "[1388]\ttrain-error:0.102693+0.004881\ttest-error:0.176191+0.010731 \n",
      "[1389]\ttrain-error:0.102413+0.004769\ttest-error:0.176191+0.010731 \n",
      "[1390]\ttrain-error:0.102693+0.004633\ttest-error:0.176191+0.010731 \n",
      "[1391]\ttrain-error:0.102693+0.004633\ttest-error:0.176191+0.010731 \n",
      "[1392]\ttrain-error:0.102413+0.004769\ttest-error:0.176191+0.010731 \n",
      "[1393]\ttrain-error:0.102693+0.004633\ttest-error:0.175067+0.010590 \n",
      "[1394]\ttrain-error:0.102974+0.005054\ttest-error:0.176191+0.010731 \n",
      "[1395]\ttrain-error:0.102974+0.005054\ttest-error:0.177314+0.011325 \n",
      "[1396]\ttrain-error:0.103254+0.005052\ttest-error:0.177314+0.011325 \n",
      "[1397]\ttrain-error:0.103254+0.005052\ttest-error:0.177314+0.011325 \n",
      "[1398]\ttrain-error:0.103535+0.004964\ttest-error:0.177314+0.011325 \n",
      "[1399]\ttrain-error:0.103535+0.004964\ttest-error:0.177314+0.011325 \n",
      "[1400]\ttrain-error:0.102974+0.004975\ttest-error:0.177314+0.011325 \n",
      "[1401]\ttrain-error:0.103255+0.005060\ttest-error:0.176191+0.011304 \n",
      "[1402]\ttrain-error:0.102132+0.004284\ttest-error:0.177314+0.011325 \n",
      "Stopping. Best iteration:\n",
      "[1152]\ttrain-error:0.109988+0.006593\ttest-error:0.173944+0.013028\n",
      "\n",
      "[1]\ttrain-error:0.367003 \n",
      "Will train until train_error hasn't improved in 250 rounds.\n",
      "\n",
      "[2]\ttrain-error:0.205387 \n",
      "[3]\ttrain-error:0.202020 \n",
      "[4]\ttrain-error:0.224467 \n",
      "[5]\ttrain-error:0.231201 \n",
      "[6]\ttrain-error:0.248036 \n",
      "[7]\ttrain-error:0.213244 \n",
      "[8]\ttrain-error:0.216611 \n",
      "[9]\ttrain-error:0.227834 \n",
      "[10]\ttrain-error:0.240180 \n",
      "[11]\ttrain-error:0.221100 \n",
      "[12]\ttrain-error:0.223345 \n",
      "[13]\ttrain-error:0.214366 \n",
      "[14]\ttrain-error:0.187430 \n",
      "[15]\ttrain-error:0.181818 \n",
      "[16]\ttrain-error:0.184063 \n",
      "[17]\ttrain-error:0.193042 \n",
      "[18]\ttrain-error:0.193042 \n",
      "[19]\ttrain-error:0.203143 \n",
      "[20]\ttrain-error:0.203143 \n",
      "[21]\ttrain-error:0.208754 \n",
      "[22]\ttrain-error:0.199776 \n",
      "[23]\ttrain-error:0.202020 \n",
      "[24]\ttrain-error:0.191919 \n",
      "[25]\ttrain-error:0.190797 \n",
      "[26]\ttrain-error:0.176207 \n",
      "[27]\ttrain-error:0.184063 \n",
      "[28]\ttrain-error:0.195286 \n",
      "[29]\ttrain-error:0.197531 \n",
      "[30]\ttrain-error:0.200898 \n",
      "[31]\ttrain-error:0.207632 \n",
      "[32]\ttrain-error:0.209877 \n",
      "[33]\ttrain-error:0.209877 \n",
      "[34]\ttrain-error:0.205387 \n",
      "[35]\ttrain-error:0.210999 \n",
      "[36]\ttrain-error:0.205387 \n",
      "[37]\ttrain-error:0.207632 \n",
      "[38]\ttrain-error:0.212121 \n",
      "[39]\ttrain-error:0.195286 \n",
      "[40]\ttrain-error:0.202020 \n",
      "[41]\ttrain-error:0.206510 \n",
      "[42]\ttrain-error:0.207632 \n",
      "[43]\ttrain-error:0.207632 \n",
      "[44]\ttrain-error:0.212121 \n",
      "[45]\ttrain-error:0.206510 \n",
      "[46]\ttrain-error:0.209877 \n",
      "[47]\ttrain-error:0.206510 \n",
      "[48]\ttrain-error:0.212121 \n",
      "[49]\ttrain-error:0.214366 \n",
      "[50]\ttrain-error:0.214366 \n",
      "[51]\ttrain-error:0.209877 \n",
      "[52]\ttrain-error:0.203143 \n",
      "[53]\ttrain-error:0.206510 \n",
      "[54]\ttrain-error:0.203143 \n",
      "[55]\ttrain-error:0.191919 \n",
      "[56]\ttrain-error:0.184063 \n",
      "[57]\ttrain-error:0.184063 \n",
      "[58]\ttrain-error:0.189675 \n",
      "[59]\ttrain-error:0.181818 \n",
      "[60]\ttrain-error:0.182941 \n",
      "[61]\ttrain-error:0.185185 \n",
      "[62]\ttrain-error:0.190797 \n",
      "[63]\ttrain-error:0.194164 \n",
      "[64]\ttrain-error:0.196409 \n",
      "[65]\ttrain-error:0.185185 \n",
      "[66]\ttrain-error:0.193042 \n",
      "[67]\ttrain-error:0.191919 \n",
      "[68]\ttrain-error:0.193042 \n",
      "[69]\ttrain-error:0.193042 \n",
      "[70]\ttrain-error:0.194164 \n",
      "[71]\ttrain-error:0.182941 \n",
      "[72]\ttrain-error:0.185185 \n",
      "[73]\ttrain-error:0.181818 \n",
      "[74]\ttrain-error:0.176207 \n",
      "[75]\ttrain-error:0.178451 \n",
      "[76]\ttrain-error:0.178451 \n",
      "[77]\ttrain-error:0.175084 \n",
      "[78]\ttrain-error:0.166105 \n",
      "[79]\ttrain-error:0.166105 \n",
      "[80]\ttrain-error:0.169473 \n",
      "[81]\ttrain-error:0.167228 \n",
      "[82]\ttrain-error:0.167228 \n",
      "[83]\ttrain-error:0.168350 \n",
      "[84]\ttrain-error:0.164983 \n",
      "[85]\ttrain-error:0.167228 \n",
      "[86]\ttrain-error:0.168350 \n",
      "[87]\ttrain-error:0.167228 \n",
      "[88]\ttrain-error:0.163861 \n",
      "[89]\ttrain-error:0.166105 \n",
      "[90]\ttrain-error:0.167228 \n",
      "[91]\ttrain-error:0.166105 \n",
      "[92]\ttrain-error:0.164983 \n",
      "[93]\ttrain-error:0.167228 \n",
      "[94]\ttrain-error:0.169473 \n",
      "[95]\ttrain-error:0.169473 \n",
      "[96]\ttrain-error:0.169473 \n",
      "[97]\ttrain-error:0.167228 \n",
      "[98]\ttrain-error:0.169473 \n",
      "[99]\ttrain-error:0.169473 \n",
      "[100]\ttrain-error:0.170595 \n",
      "[101]\ttrain-error:0.168350 \n",
      "[102]\ttrain-error:0.166105 \n",
      "[103]\ttrain-error:0.169473 \n",
      "[104]\ttrain-error:0.169473 \n",
      "[105]\ttrain-error:0.168350 \n",
      "[106]\ttrain-error:0.169473 \n",
      "[107]\ttrain-error:0.170595 \n",
      "[108]\ttrain-error:0.169473 \n",
      "[109]\ttrain-error:0.167228 \n",
      "[110]\ttrain-error:0.163861 \n",
      "[111]\ttrain-error:0.166105 \n",
      "[112]\ttrain-error:0.166105 \n",
      "[113]\ttrain-error:0.169473 \n",
      "[114]\ttrain-error:0.166105 \n",
      "[115]\ttrain-error:0.166105 \n",
      "[116]\ttrain-error:0.166105 \n",
      "[117]\ttrain-error:0.164983 \n",
      "[118]\ttrain-error:0.163861 \n",
      "[119]\ttrain-error:0.164983 \n",
      "[120]\ttrain-error:0.164983 \n",
      "[121]\ttrain-error:0.167228 \n",
      "[122]\ttrain-error:0.167228 \n",
      "[123]\ttrain-error:0.167228 \n",
      "[124]\ttrain-error:0.166105 \n",
      "[125]\ttrain-error:0.167228 \n",
      "[126]\ttrain-error:0.164983 \n",
      "[127]\ttrain-error:0.164983 \n",
      "[128]\ttrain-error:0.164983 \n",
      "[129]\ttrain-error:0.162739 \n",
      "[130]\ttrain-error:0.161616 \n",
      "[131]\ttrain-error:0.162739 \n",
      "[132]\ttrain-error:0.162739 \n",
      "[133]\ttrain-error:0.163861 \n",
      "[134]\ttrain-error:0.162739 \n",
      "[135]\ttrain-error:0.163861 \n",
      "[136]\ttrain-error:0.163861 \n",
      "[137]\ttrain-error:0.163861 \n",
      "[138]\ttrain-error:0.163861 \n",
      "[139]\ttrain-error:0.161616 \n",
      "[140]\ttrain-error:0.162739 \n",
      "[141]\ttrain-error:0.161616 \n",
      "[142]\ttrain-error:0.160494 \n",
      "[143]\ttrain-error:0.160494 \n",
      "[144]\ttrain-error:0.160494 \n",
      "[145]\ttrain-error:0.159371 \n",
      "[146]\ttrain-error:0.158249 \n",
      "[147]\ttrain-error:0.160494 \n",
      "[148]\ttrain-error:0.161616 \n",
      "[149]\ttrain-error:0.160494 \n",
      "[150]\ttrain-error:0.160494 \n",
      "[151]\ttrain-error:0.161616 \n",
      "[152]\ttrain-error:0.161616 \n",
      "[153]\ttrain-error:0.161616 \n",
      "[154]\ttrain-error:0.159371 \n",
      "[155]\ttrain-error:0.159371 \n",
      "[156]\ttrain-error:0.160494 \n",
      "[157]\ttrain-error:0.160494 \n",
      "[158]\ttrain-error:0.159371 \n",
      "[159]\ttrain-error:0.159371 \n",
      "[160]\ttrain-error:0.159371 \n",
      "[161]\ttrain-error:0.159371 \n",
      "[162]\ttrain-error:0.160494 \n",
      "[163]\ttrain-error:0.158249 \n",
      "[164]\ttrain-error:0.158249 \n",
      "[165]\ttrain-error:0.158249 \n",
      "[166]\ttrain-error:0.158249 \n",
      "[167]\ttrain-error:0.159371 \n",
      "[168]\ttrain-error:0.160494 \n",
      "[169]\ttrain-error:0.160494 \n",
      "[170]\ttrain-error:0.161616 \n",
      "[171]\ttrain-error:0.158249 \n",
      "[172]\ttrain-error:0.160494 \n",
      "[173]\ttrain-error:0.160494 \n",
      "[174]\ttrain-error:0.159371 \n",
      "[175]\ttrain-error:0.158249 \n",
      "[176]\ttrain-error:0.159371 \n",
      "[177]\ttrain-error:0.160494 \n",
      "[178]\ttrain-error:0.159371 \n",
      "[179]\ttrain-error:0.160494 \n",
      "[180]\ttrain-error:0.158249 \n",
      "[181]\ttrain-error:0.157127 \n",
      "[182]\ttrain-error:0.158249 \n",
      "[183]\ttrain-error:0.156004 \n",
      "[184]\ttrain-error:0.157127 \n",
      "[185]\ttrain-error:0.157127 \n",
      "[186]\ttrain-error:0.157127 \n",
      "[187]\ttrain-error:0.159371 \n",
      "[188]\ttrain-error:0.159371 \n",
      "[189]\ttrain-error:0.157127 \n",
      "[190]\ttrain-error:0.156004 \n",
      "[191]\ttrain-error:0.157127 \n",
      "[192]\ttrain-error:0.158249 \n",
      "[193]\ttrain-error:0.157127 \n",
      "[194]\ttrain-error:0.157127 \n",
      "[195]\ttrain-error:0.158249 \n",
      "[196]\ttrain-error:0.156004 \n",
      "[197]\ttrain-error:0.156004 \n",
      "[198]\ttrain-error:0.156004 \n",
      "[199]\ttrain-error:0.156004 \n",
      "[200]\ttrain-error:0.157127 \n",
      "[201]\ttrain-error:0.156004 \n",
      "[202]\ttrain-error:0.156004 \n",
      "[203]\ttrain-error:0.156004 \n",
      "[204]\ttrain-error:0.156004 \n",
      "[205]\ttrain-error:0.156004 \n",
      "[206]\ttrain-error:0.154882 \n",
      "[207]\ttrain-error:0.156004 \n",
      "[208]\ttrain-error:0.156004 \n",
      "[209]\ttrain-error:0.156004 \n",
      "[210]\ttrain-error:0.157127 \n",
      "[211]\ttrain-error:0.156004 \n",
      "[212]\ttrain-error:0.156004 \n",
      "[213]\ttrain-error:0.154882 \n",
      "[214]\ttrain-error:0.154882 \n",
      "[215]\ttrain-error:0.154882 \n",
      "[216]\ttrain-error:0.154882 \n",
      "[217]\ttrain-error:0.154882 \n",
      "[218]\ttrain-error:0.153760 \n",
      "[219]\ttrain-error:0.154882 \n",
      "[220]\ttrain-error:0.154882 \n",
      "[221]\ttrain-error:0.156004 \n",
      "[222]\ttrain-error:0.156004 \n",
      "[223]\ttrain-error:0.156004 \n",
      "[224]\ttrain-error:0.156004 \n",
      "[225]\ttrain-error:0.156004 \n",
      "[226]\ttrain-error:0.156004 \n",
      "[227]\ttrain-error:0.154882 \n",
      "[228]\ttrain-error:0.156004 \n",
      "[229]\ttrain-error:0.156004 \n",
      "[230]\ttrain-error:0.154882 \n",
      "[231]\ttrain-error:0.154882 \n",
      "[232]\ttrain-error:0.154882 \n",
      "[233]\ttrain-error:0.156004 \n",
      "[234]\ttrain-error:0.156004 \n",
      "[235]\ttrain-error:0.156004 \n",
      "[236]\ttrain-error:0.156004 \n",
      "[237]\ttrain-error:0.154882 \n",
      "[238]\ttrain-error:0.156004 \n",
      "[239]\ttrain-error:0.154882 \n",
      "[240]\ttrain-error:0.154882 \n",
      "[241]\ttrain-error:0.153760 \n",
      "[242]\ttrain-error:0.152637 \n",
      "[243]\ttrain-error:0.152637 \n",
      "[244]\ttrain-error:0.153760 \n",
      "[245]\ttrain-error:0.157127 \n",
      "[246]\ttrain-error:0.156004 \n",
      "[247]\ttrain-error:0.157127 \n",
      "[248]\ttrain-error:0.157127 \n",
      "[249]\ttrain-error:0.156004 \n",
      "[250]\ttrain-error:0.157127 \n",
      "[251]\ttrain-error:0.157127 \n",
      "[252]\ttrain-error:0.156004 \n",
      "[253]\ttrain-error:0.156004 \n",
      "[254]\ttrain-error:0.156004 \n",
      "[255]\ttrain-error:0.157127 \n",
      "[256]\ttrain-error:0.153760 \n",
      "[257]\ttrain-error:0.153760 \n",
      "[258]\ttrain-error:0.154882 \n",
      "[259]\ttrain-error:0.157127 \n",
      "[260]\ttrain-error:0.157127 \n",
      "[261]\ttrain-error:0.156004 \n",
      "[262]\ttrain-error:0.153760 \n",
      "[263]\ttrain-error:0.153760 \n",
      "[264]\ttrain-error:0.153760 \n",
      "[265]\ttrain-error:0.153760 \n",
      "[266]\ttrain-error:0.153760 \n",
      "[267]\ttrain-error:0.154882 \n",
      "[268]\ttrain-error:0.157127 \n",
      "[269]\ttrain-error:0.156004 \n",
      "[270]\ttrain-error:0.156004 \n",
      "[271]\ttrain-error:0.156004 \n",
      "[272]\ttrain-error:0.154882 \n",
      "[273]\ttrain-error:0.154882 \n",
      "[274]\ttrain-error:0.154882 \n",
      "[275]\ttrain-error:0.154882 \n",
      "[276]\ttrain-error:0.154882 \n",
      "[277]\ttrain-error:0.156004 \n",
      "[278]\ttrain-error:0.154882 \n",
      "[279]\ttrain-error:0.156004 \n",
      "[280]\ttrain-error:0.156004 \n",
      "[281]\ttrain-error:0.154882 \n",
      "[282]\ttrain-error:0.154882 \n",
      "[283]\ttrain-error:0.153760 \n",
      "[284]\ttrain-error:0.154882 \n",
      "[285]\ttrain-error:0.154882 \n",
      "[286]\ttrain-error:0.156004 \n",
      "[287]\ttrain-error:0.154882 \n",
      "[288]\ttrain-error:0.156004 \n",
      "[289]\ttrain-error:0.156004 \n",
      "[290]\ttrain-error:0.151515 \n",
      "[291]\ttrain-error:0.153760 \n",
      "[292]\ttrain-error:0.154882 \n",
      "[293]\ttrain-error:0.153760 \n",
      "[294]\ttrain-error:0.154882 \n",
      "[295]\ttrain-error:0.153760 \n",
      "[296]\ttrain-error:0.153760 \n",
      "[297]\ttrain-error:0.152637 \n",
      "[298]\ttrain-error:0.153760 \n",
      "[299]\ttrain-error:0.153760 \n",
      "[300]\ttrain-error:0.152637 \n",
      "[301]\ttrain-error:0.152637 \n",
      "[302]\ttrain-error:0.152637 \n",
      "[303]\ttrain-error:0.152637 \n",
      "[304]\ttrain-error:0.151515 \n",
      "[305]\ttrain-error:0.151515 \n",
      "[306]\ttrain-error:0.151515 \n",
      "[307]\ttrain-error:0.151515 \n",
      "[308]\ttrain-error:0.152637 \n",
      "[309]\ttrain-error:0.153760 \n",
      "[310]\ttrain-error:0.152637 \n",
      "[311]\ttrain-error:0.151515 \n",
      "[312]\ttrain-error:0.151515 \n",
      "[313]\ttrain-error:0.150393 \n",
      "[314]\ttrain-error:0.151515 \n",
      "[315]\ttrain-error:0.151515 \n",
      "[316]\ttrain-error:0.151515 \n",
      "[317]\ttrain-error:0.151515 \n",
      "[318]\ttrain-error:0.151515 \n",
      "[319]\ttrain-error:0.151515 \n",
      "[320]\ttrain-error:0.150393 \n",
      "[321]\ttrain-error:0.150393 \n",
      "[322]\ttrain-error:0.150393 \n",
      "[323]\ttrain-error:0.150393 \n",
      "[324]\ttrain-error:0.150393 \n",
      "[325]\ttrain-error:0.151515 \n",
      "[326]\ttrain-error:0.150393 \n",
      "[327]\ttrain-error:0.149270 \n",
      "[328]\ttrain-error:0.149270 \n",
      "[329]\ttrain-error:0.148148 \n",
      "[330]\ttrain-error:0.150393 \n",
      "[331]\ttrain-error:0.150393 \n",
      "[332]\ttrain-error:0.150393 \n",
      "[333]\ttrain-error:0.149270 \n",
      "[334]\ttrain-error:0.149270 \n",
      "[335]\ttrain-error:0.150393 \n",
      "[336]\ttrain-error:0.149270 \n",
      "[337]\ttrain-error:0.148148 \n",
      "[338]\ttrain-error:0.147026 \n",
      "[339]\ttrain-error:0.148148 \n",
      "[340]\ttrain-error:0.147026 \n",
      "[341]\ttrain-error:0.148148 \n",
      "[342]\ttrain-error:0.147026 \n",
      "[343]\ttrain-error:0.147026 \n",
      "[344]\ttrain-error:0.147026 \n",
      "[345]\ttrain-error:0.147026 \n",
      "[346]\ttrain-error:0.147026 \n",
      "[347]\ttrain-error:0.149270 \n",
      "[348]\ttrain-error:0.149270 \n",
      "[349]\ttrain-error:0.148148 \n",
      "[350]\ttrain-error:0.149270 \n",
      "[351]\ttrain-error:0.149270 \n",
      "[352]\ttrain-error:0.149270 \n",
      "[353]\ttrain-error:0.149270 \n",
      "[354]\ttrain-error:0.149270 \n",
      "[355]\ttrain-error:0.149270 \n",
      "[356]\ttrain-error:0.149270 \n",
      "[357]\ttrain-error:0.149270 \n",
      "[358]\ttrain-error:0.150393 \n",
      "[359]\ttrain-error:0.149270 \n",
      "[360]\ttrain-error:0.149270 \n",
      "[361]\ttrain-error:0.149270 \n",
      "[362]\ttrain-error:0.148148 \n",
      "[363]\ttrain-error:0.149270 \n",
      "[364]\ttrain-error:0.147026 \n",
      "[365]\ttrain-error:0.147026 \n",
      "[366]\ttrain-error:0.148148 \n",
      "[367]\ttrain-error:0.148148 \n",
      "[368]\ttrain-error:0.148148 \n",
      "[369]\ttrain-error:0.148148 \n",
      "[370]\ttrain-error:0.147026 \n",
      "[371]\ttrain-error:0.147026 \n",
      "[372]\ttrain-error:0.147026 \n",
      "[373]\ttrain-error:0.147026 \n",
      "[374]\ttrain-error:0.148148 \n",
      "[375]\ttrain-error:0.148148 \n",
      "[376]\ttrain-error:0.147026 \n",
      "[377]\ttrain-error:0.147026 \n",
      "[378]\ttrain-error:0.147026 \n",
      "[379]\ttrain-error:0.147026 \n",
      "[380]\ttrain-error:0.147026 \n",
      "[381]\ttrain-error:0.147026 \n",
      "[382]\ttrain-error:0.147026 \n",
      "[383]\ttrain-error:0.148148 \n",
      "[384]\ttrain-error:0.147026 \n",
      "[385]\ttrain-error:0.147026 \n",
      "[386]\ttrain-error:0.147026 \n",
      "[387]\ttrain-error:0.148148 \n",
      "[388]\ttrain-error:0.149270 \n",
      "[389]\ttrain-error:0.148148 \n",
      "[390]\ttrain-error:0.147026 \n",
      "[391]\ttrain-error:0.145903 \n",
      "[392]\ttrain-error:0.147026 \n",
      "[393]\ttrain-error:0.147026 \n",
      "[394]\ttrain-error:0.148148 \n",
      "[395]\ttrain-error:0.148148 \n",
      "[396]\ttrain-error:0.148148 \n",
      "[397]\ttrain-error:0.148148 \n",
      "[398]\ttrain-error:0.147026 \n",
      "[399]\ttrain-error:0.148148 \n",
      "[400]\ttrain-error:0.148148 \n",
      "[401]\ttrain-error:0.145903 \n",
      "[402]\ttrain-error:0.147026 \n",
      "[403]\ttrain-error:0.145903 \n",
      "[404]\ttrain-error:0.145903 \n",
      "[405]\ttrain-error:0.147026 \n",
      "[406]\ttrain-error:0.147026 \n",
      "[407]\ttrain-error:0.148148 \n",
      "[408]\ttrain-error:0.147026 \n",
      "[409]\ttrain-error:0.145903 \n",
      "[410]\ttrain-error:0.147026 \n",
      "[411]\ttrain-error:0.145903 \n",
      "[412]\ttrain-error:0.143659 \n",
      "[413]\ttrain-error:0.144781 \n",
      "[414]\ttrain-error:0.143659 \n",
      "[415]\ttrain-error:0.144781 \n",
      "[416]\ttrain-error:0.144781 \n",
      "[417]\ttrain-error:0.144781 \n",
      "[418]\ttrain-error:0.143659 \n",
      "[419]\ttrain-error:0.143659 \n",
      "[420]\ttrain-error:0.143659 \n",
      "[421]\ttrain-error:0.143659 \n",
      "[422]\ttrain-error:0.143659 \n",
      "[423]\ttrain-error:0.143659 \n",
      "[424]\ttrain-error:0.143659 \n",
      "[425]\ttrain-error:0.143659 \n",
      "[426]\ttrain-error:0.143659 \n",
      "[427]\ttrain-error:0.143659 \n",
      "[428]\ttrain-error:0.143659 \n",
      "[429]\ttrain-error:0.143659 \n",
      "[430]\ttrain-error:0.143659 \n",
      "[431]\ttrain-error:0.143659 \n",
      "[432]\ttrain-error:0.143659 \n",
      "[433]\ttrain-error:0.142536 \n",
      "[434]\ttrain-error:0.143659 \n",
      "[435]\ttrain-error:0.143659 \n",
      "[436]\ttrain-error:0.143659 \n",
      "[437]\ttrain-error:0.142536 \n",
      "[438]\ttrain-error:0.142536 \n",
      "[439]\ttrain-error:0.141414 \n",
      "[440]\ttrain-error:0.142536 \n",
      "[441]\ttrain-error:0.141414 \n",
      "[442]\ttrain-error:0.141414 \n",
      "[443]\ttrain-error:0.139169 \n",
      "[444]\ttrain-error:0.136925 \n",
      "[445]\ttrain-error:0.138047 \n",
      "[446]\ttrain-error:0.136925 \n",
      "[447]\ttrain-error:0.136925 \n",
      "[448]\ttrain-error:0.138047 \n",
      "[449]\ttrain-error:0.139169 \n",
      "[450]\ttrain-error:0.139169 \n",
      "[451]\ttrain-error:0.139169 \n",
      "[452]\ttrain-error:0.138047 \n",
      "[453]\ttrain-error:0.136925 \n",
      "[454]\ttrain-error:0.134680 \n",
      "[455]\ttrain-error:0.135802 \n",
      "[456]\ttrain-error:0.136925 \n",
      "[457]\ttrain-error:0.138047 \n",
      "[458]\ttrain-error:0.136925 \n",
      "[459]\ttrain-error:0.135802 \n",
      "[460]\ttrain-error:0.135802 \n",
      "[461]\ttrain-error:0.134680 \n",
      "[462]\ttrain-error:0.135802 \n",
      "[463]\ttrain-error:0.135802 \n",
      "[464]\ttrain-error:0.136925 \n",
      "[465]\ttrain-error:0.134680 \n",
      "[466]\ttrain-error:0.136925 \n",
      "[467]\ttrain-error:0.136925 \n",
      "[468]\ttrain-error:0.138047 \n",
      "[469]\ttrain-error:0.138047 \n",
      "[470]\ttrain-error:0.138047 \n",
      "[471]\ttrain-error:0.138047 \n",
      "[472]\ttrain-error:0.138047 \n",
      "[473]\ttrain-error:0.138047 \n",
      "[474]\ttrain-error:0.138047 \n",
      "[475]\ttrain-error:0.138047 \n",
      "[476]\ttrain-error:0.136925 \n",
      "[477]\ttrain-error:0.138047 \n",
      "[478]\ttrain-error:0.136925 \n",
      "[479]\ttrain-error:0.136925 \n",
      "[480]\ttrain-error:0.135802 \n",
      "[481]\ttrain-error:0.133558 \n",
      "[482]\ttrain-error:0.132435 \n",
      "[483]\ttrain-error:0.131313 \n",
      "[484]\ttrain-error:0.131313 \n",
      "[485]\ttrain-error:0.131313 \n",
      "[486]\ttrain-error:0.132435 \n",
      "[487]\ttrain-error:0.132435 \n",
      "[488]\ttrain-error:0.132435 \n",
      "[489]\ttrain-error:0.130191 \n",
      "[490]\ttrain-error:0.131313 \n",
      "[491]\ttrain-error:0.130191 \n",
      "[492]\ttrain-error:0.130191 \n",
      "[493]\ttrain-error:0.130191 \n",
      "[494]\ttrain-error:0.131313 \n",
      "[495]\ttrain-error:0.129068 \n",
      "[496]\ttrain-error:0.130191 \n",
      "[497]\ttrain-error:0.130191 \n",
      "[498]\ttrain-error:0.131313 \n",
      "[499]\ttrain-error:0.130191 \n",
      "[500]\ttrain-error:0.130191 \n",
      "[501]\ttrain-error:0.130191 \n",
      "[502]\ttrain-error:0.130191 \n",
      "[503]\ttrain-error:0.131313 \n",
      "[504]\ttrain-error:0.131313 \n",
      "[505]\ttrain-error:0.131313 \n",
      "[506]\ttrain-error:0.131313 \n",
      "[507]\ttrain-error:0.131313 \n",
      "[508]\ttrain-error:0.131313 \n",
      "[509]\ttrain-error:0.131313 \n",
      "[510]\ttrain-error:0.130191 \n",
      "[511]\ttrain-error:0.130191 \n",
      "[512]\ttrain-error:0.129068 \n",
      "[513]\ttrain-error:0.129068 \n",
      "[514]\ttrain-error:0.130191 \n",
      "[515]\ttrain-error:0.130191 \n",
      "[516]\ttrain-error:0.130191 \n",
      "[517]\ttrain-error:0.129068 \n",
      "[518]\ttrain-error:0.129068 \n",
      "[519]\ttrain-error:0.126824 \n",
      "[520]\ttrain-error:0.126824 \n",
      "[521]\ttrain-error:0.126824 \n",
      "[522]\ttrain-error:0.126824 \n",
      "[523]\ttrain-error:0.126824 \n",
      "[524]\ttrain-error:0.126824 \n",
      "[525]\ttrain-error:0.126824 \n",
      "[526]\ttrain-error:0.126824 \n",
      "[527]\ttrain-error:0.126824 \n",
      "[528]\ttrain-error:0.125701 \n",
      "[529]\ttrain-error:0.126824 \n",
      "[530]\ttrain-error:0.126824 \n",
      "[531]\ttrain-error:0.125701 \n",
      "[532]\ttrain-error:0.125701 \n",
      "[533]\ttrain-error:0.125701 \n",
      "[534]\ttrain-error:0.125701 \n",
      "[535]\ttrain-error:0.124579 \n",
      "[536]\ttrain-error:0.124579 \n",
      "[537]\ttrain-error:0.124579 \n",
      "[538]\ttrain-error:0.124579 \n",
      "[539]\ttrain-error:0.124579 \n",
      "[540]\ttrain-error:0.124579 \n",
      "[541]\ttrain-error:0.124579 \n",
      "[542]\ttrain-error:0.124579 \n",
      "[543]\ttrain-error:0.124579 \n",
      "[544]\ttrain-error:0.123457 \n",
      "[545]\ttrain-error:0.123457 \n",
      "[546]\ttrain-error:0.123457 \n",
      "[547]\ttrain-error:0.123457 \n",
      "[548]\ttrain-error:0.123457 \n",
      "[549]\ttrain-error:0.123457 \n",
      "[550]\ttrain-error:0.123457 \n",
      "[551]\ttrain-error:0.123457 \n",
      "[552]\ttrain-error:0.123457 \n",
      "[553]\ttrain-error:0.123457 \n",
      "[554]\ttrain-error:0.123457 \n",
      "[555]\ttrain-error:0.123457 \n",
      "[556]\ttrain-error:0.123457 \n",
      "[557]\ttrain-error:0.123457 \n",
      "[558]\ttrain-error:0.123457 \n",
      "[559]\ttrain-error:0.123457 \n",
      "[560]\ttrain-error:0.123457 \n",
      "[561]\ttrain-error:0.123457 \n",
      "[562]\ttrain-error:0.123457 \n",
      "[563]\ttrain-error:0.123457 \n",
      "[564]\ttrain-error:0.123457 \n",
      "[565]\ttrain-error:0.123457 \n",
      "[566]\ttrain-error:0.123457 \n",
      "[567]\ttrain-error:0.123457 \n",
      "[568]\ttrain-error:0.123457 \n",
      "[569]\ttrain-error:0.123457 \n",
      "[570]\ttrain-error:0.123457 \n",
      "[571]\ttrain-error:0.123457 \n",
      "[572]\ttrain-error:0.124579 \n",
      "[573]\ttrain-error:0.124579 \n",
      "[574]\ttrain-error:0.124579 \n",
      "[575]\ttrain-error:0.124579 \n",
      "[576]\ttrain-error:0.124579 \n",
      "[577]\ttrain-error:0.124579 \n",
      "[578]\ttrain-error:0.124579 \n",
      "[579]\ttrain-error:0.124579 \n",
      "[580]\ttrain-error:0.124579 \n",
      "[581]\ttrain-error:0.124579 \n",
      "[582]\ttrain-error:0.124579 \n",
      "[583]\ttrain-error:0.124579 \n",
      "[584]\ttrain-error:0.124579 \n",
      "[585]\ttrain-error:0.124579 \n",
      "[586]\ttrain-error:0.124579 \n",
      "[587]\ttrain-error:0.124579 \n",
      "[588]\ttrain-error:0.124579 \n",
      "[589]\ttrain-error:0.124579 \n",
      "[590]\ttrain-error:0.124579 \n",
      "[591]\ttrain-error:0.124579 \n",
      "[592]\ttrain-error:0.124579 \n",
      "[593]\ttrain-error:0.124579 \n",
      "[594]\ttrain-error:0.126824 \n",
      "[595]\ttrain-error:0.125701 \n",
      "[596]\ttrain-error:0.126824 \n",
      "[597]\ttrain-error:0.125701 \n",
      "[598]\ttrain-error:0.125701 \n",
      "[599]\ttrain-error:0.125701 \n",
      "[600]\ttrain-error:0.124579 \n",
      "[601]\ttrain-error:0.125701 \n",
      "[602]\ttrain-error:0.125701 \n",
      "[603]\ttrain-error:0.125701 \n",
      "[604]\ttrain-error:0.125701 \n",
      "[605]\ttrain-error:0.125701 \n",
      "[606]\ttrain-error:0.125701 \n",
      "[607]\ttrain-error:0.126824 \n",
      "[608]\ttrain-error:0.126824 \n",
      "[609]\ttrain-error:0.126824 \n",
      "[610]\ttrain-error:0.126824 \n",
      "[611]\ttrain-error:0.126824 \n",
      "[612]\ttrain-error:0.126824 \n",
      "[613]\ttrain-error:0.126824 \n",
      "[614]\ttrain-error:0.126824 \n",
      "[615]\ttrain-error:0.126824 \n",
      "[616]\ttrain-error:0.126824 \n",
      "[617]\ttrain-error:0.125701 \n",
      "[618]\ttrain-error:0.126824 \n",
      "[619]\ttrain-error:0.126824 \n",
      "[620]\ttrain-error:0.125701 \n",
      "[621]\ttrain-error:0.126824 \n",
      "[622]\ttrain-error:0.126824 \n",
      "[623]\ttrain-error:0.126824 \n",
      "[624]\ttrain-error:0.126824 \n",
      "[625]\ttrain-error:0.126824 \n",
      "[626]\ttrain-error:0.126824 \n",
      "[627]\ttrain-error:0.126824 \n",
      "[628]\ttrain-error:0.126824 \n",
      "[629]\ttrain-error:0.126824 \n",
      "[630]\ttrain-error:0.126824 \n",
      "[631]\ttrain-error:0.126824 \n",
      "[632]\ttrain-error:0.126824 \n",
      "[633]\ttrain-error:0.126824 \n",
      "[634]\ttrain-error:0.127946 \n",
      "[635]\ttrain-error:0.127946 \n",
      "[636]\ttrain-error:0.127946 \n",
      "[637]\ttrain-error:0.127946 \n",
      "[638]\ttrain-error:0.127946 \n",
      "[639]\ttrain-error:0.127946 \n",
      "[640]\ttrain-error:0.127946 \n",
      "[641]\ttrain-error:0.127946 \n",
      "[642]\ttrain-error:0.127946 \n",
      "[643]\ttrain-error:0.127946 \n",
      "[644]\ttrain-error:0.127946 \n",
      "[645]\ttrain-error:0.127946 \n",
      "[646]\ttrain-error:0.127946 \n",
      "[647]\ttrain-error:0.127946 \n",
      "[648]\ttrain-error:0.127946 \n",
      "[649]\ttrain-error:0.127946 \n",
      "[650]\ttrain-error:0.127946 \n",
      "[651]\ttrain-error:0.127946 \n",
      "[652]\ttrain-error:0.127946 \n",
      "[653]\ttrain-error:0.127946 \n",
      "[654]\ttrain-error:0.125701 \n",
      "[655]\ttrain-error:0.126824 \n",
      "[656]\ttrain-error:0.126824 \n",
      "[657]\ttrain-error:0.126824 \n",
      "[658]\ttrain-error:0.129068 \n",
      "[659]\ttrain-error:0.127946 \n",
      "[660]\ttrain-error:0.127946 \n",
      "[661]\ttrain-error:0.129068 \n",
      "[662]\ttrain-error:0.126824 \n",
      "[663]\ttrain-error:0.126824 \n",
      "[664]\ttrain-error:0.126824 \n",
      "[665]\ttrain-error:0.126824 \n",
      "[666]\ttrain-error:0.126824 \n",
      "[667]\ttrain-error:0.126824 \n",
      "[668]\ttrain-error:0.127946 \n",
      "[669]\ttrain-error:0.129068 \n",
      "[670]\ttrain-error:0.130191 \n",
      "[671]\ttrain-error:0.129068 \n",
      "[672]\ttrain-error:0.129068 \n",
      "[673]\ttrain-error:0.129068 \n",
      "[674]\ttrain-error:0.127946 \n",
      "[675]\ttrain-error:0.127946 \n",
      "[676]\ttrain-error:0.127946 \n",
      "[677]\ttrain-error:0.126824 \n",
      "[678]\ttrain-error:0.126824 \n",
      "[679]\ttrain-error:0.126824 \n",
      "[680]\ttrain-error:0.126824 \n",
      "[681]\ttrain-error:0.129068 \n",
      "[682]\ttrain-error:0.129068 \n",
      "[683]\ttrain-error:0.129068 \n",
      "[684]\ttrain-error:0.127946 \n",
      "[685]\ttrain-error:0.129068 \n",
      "[686]\ttrain-error:0.127946 \n",
      "[687]\ttrain-error:0.129068 \n",
      "[688]\ttrain-error:0.127946 \n",
      "[689]\ttrain-error:0.127946 \n",
      "[690]\ttrain-error:0.127946 \n",
      "[691]\ttrain-error:0.129068 \n",
      "[692]\ttrain-error:0.127946 \n",
      "[693]\ttrain-error:0.127946 \n",
      "[694]\ttrain-error:0.127946 \n",
      "[695]\ttrain-error:0.127946 \n",
      "[696]\ttrain-error:0.127946 \n",
      "[697]\ttrain-error:0.129068 \n",
      "[698]\ttrain-error:0.129068 \n",
      "[699]\ttrain-error:0.129068 \n",
      "[700]\ttrain-error:0.129068 \n",
      "[701]\ttrain-error:0.129068 \n",
      "[702]\ttrain-error:0.129068 \n",
      "[703]\ttrain-error:0.129068 \n",
      "[704]\ttrain-error:0.129068 \n",
      "[705]\ttrain-error:0.129068 \n",
      "[706]\ttrain-error:0.127946 \n",
      "[707]\ttrain-error:0.127946 \n",
      "[708]\ttrain-error:0.127946 \n",
      "[709]\ttrain-error:0.126824 \n",
      "[710]\ttrain-error:0.126824 \n",
      "[711]\ttrain-error:0.126824 \n",
      "[712]\ttrain-error:0.126824 \n",
      "[713]\ttrain-error:0.126824 \n",
      "[714]\ttrain-error:0.126824 \n",
      "[715]\ttrain-error:0.126824 \n",
      "[716]\ttrain-error:0.126824 \n",
      "[717]\ttrain-error:0.126824 \n",
      "[718]\ttrain-error:0.125701 \n",
      "[719]\ttrain-error:0.126824 \n",
      "[720]\ttrain-error:0.125701 \n",
      "[721]\ttrain-error:0.125701 \n",
      "[722]\ttrain-error:0.125701 \n",
      "[723]\ttrain-error:0.125701 \n",
      "[724]\ttrain-error:0.125701 \n",
      "[725]\ttrain-error:0.125701 \n",
      "[726]\ttrain-error:0.125701 \n",
      "[727]\ttrain-error:0.125701 \n",
      "[728]\ttrain-error:0.125701 \n",
      "[729]\ttrain-error:0.125701 \n",
      "[730]\ttrain-error:0.125701 \n",
      "[731]\ttrain-error:0.125701 \n",
      "[732]\ttrain-error:0.125701 \n",
      "[733]\ttrain-error:0.125701 \n",
      "[734]\ttrain-error:0.125701 \n",
      "[735]\ttrain-error:0.125701 \n",
      "[736]\ttrain-error:0.125701 \n",
      "[737]\ttrain-error:0.125701 \n",
      "[738]\ttrain-error:0.125701 \n",
      "[739]\ttrain-error:0.125701 \n",
      "[740]\ttrain-error:0.125701 \n",
      "[741]\ttrain-error:0.126824 \n",
      "[742]\ttrain-error:0.126824 \n",
      "[743]\ttrain-error:0.126824 \n",
      "[744]\ttrain-error:0.126824 \n",
      "[745]\ttrain-error:0.126824 \n",
      "[746]\ttrain-error:0.126824 \n",
      "[747]\ttrain-error:0.126824 \n",
      "[748]\ttrain-error:0.126824 \n",
      "[749]\ttrain-error:0.126824 \n",
      "[750]\ttrain-error:0.126824 \n",
      "[751]\ttrain-error:0.126824 \n",
      "[752]\ttrain-error:0.126824 \n",
      "[753]\ttrain-error:0.126824 \n",
      "[754]\ttrain-error:0.126824 \n",
      "[755]\ttrain-error:0.126824 \n",
      "[756]\ttrain-error:0.126824 \n",
      "[757]\ttrain-error:0.126824 \n",
      "[758]\ttrain-error:0.126824 \n",
      "[759]\ttrain-error:0.126824 \n",
      "[760]\ttrain-error:0.126824 \n",
      "[761]\ttrain-error:0.126824 \n",
      "[762]\ttrain-error:0.126824 \n",
      "[763]\ttrain-error:0.126824 \n",
      "[764]\ttrain-error:0.125701 \n",
      "[765]\ttrain-error:0.126824 \n",
      "[766]\ttrain-error:0.125701 \n",
      "[767]\ttrain-error:0.126824 \n",
      "[768]\ttrain-error:0.126824 \n",
      "[769]\ttrain-error:0.125701 \n",
      "[770]\ttrain-error:0.125701 \n",
      "[771]\ttrain-error:0.125701 \n",
      "[772]\ttrain-error:0.125701 \n",
      "[773]\ttrain-error:0.125701 \n",
      "[774]\ttrain-error:0.125701 \n",
      "[775]\ttrain-error:0.125701 \n",
      "[776]\ttrain-error:0.125701 \n",
      "[777]\ttrain-error:0.126824 \n",
      "[778]\ttrain-error:0.126824 \n",
      "[779]\ttrain-error:0.126824 \n",
      "[780]\ttrain-error:0.126824 \n",
      "[781]\ttrain-error:0.126824 \n",
      "[782]\ttrain-error:0.126824 \n",
      "[783]\ttrain-error:0.126824 \n",
      "[784]\ttrain-error:0.126824 \n",
      "[785]\ttrain-error:0.126824 \n",
      "[786]\ttrain-error:0.126824 \n",
      "[787]\ttrain-error:0.126824 \n",
      "[788]\ttrain-error:0.126824 \n",
      "[789]\ttrain-error:0.126824 \n",
      "[790]\ttrain-error:0.126824 \n",
      "[791]\ttrain-error:0.127946 \n",
      "[792]\ttrain-error:0.126824 \n",
      "[793]\ttrain-error:0.127946 \n",
      "[794]\ttrain-error:0.127946 \n",
      "Stopping. Best iteration:\n",
      "[544]\ttrain-error:0.123457\n",
      "\n",
      "   Feature       Gain      Cover  Frequency\n",
      "1:    Fare 0.27415713 0.29007723 0.34616977\n",
      "2:  SexNum 0.22524923 0.08450968 0.03450656\n",
      "3:     Age 0.21414858 0.23863092 0.28612836\n",
      "4: Pclass3 0.06195227 0.04921699 0.03229814\n",
      "5: Pclass1 0.03881301 0.04603832 0.02815735\n",
      "6:  SibSp0 0.02439367 0.03585911 0.03505866\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAACslBMVEUAAAABAQECAgIDAwME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\ngMySPrJ6/xoAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC61BMVEUAAAABAQECAgIDAwME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\ngg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Titanic survival classification problem\n",
    "\n",
    "library(data.table)\n",
    "library(xgboost)\n",
    "library(Metrics)\n",
    "library(Matrix)\n",
    "library(mice)\n",
    "library(dplyr)\n",
    "library('ggplot2')\n",
    "library('ggthemes')\n",
    "library('scales')\n",
    "library(bit64)  # may be needed for fread() for bit64::integer64 type properly displayed\n",
    "library(moments)  # imports skewness\n",
    "library(caret)\n",
    "library(car)\n",
    "library(stringr)\n",
    "library(gridExtra)\n",
    "library(cowplot)\n",
    "library(lattice)\n",
    "library(readr)\n",
    "# library(Hmisc)  # not working\n",
    "# library(Formula)\n",
    "# library(VIM)\n",
    "\n",
    "Titanic <- setClass(\n",
    "  # Set name of class\n",
    "  \"Titanic\",\n",
    "  \n",
    "  # Define slots\n",
    "  slots = c(\n",
    "    df = \"data.frame\",\n",
    "    df_test = \"data.frame\",\n",
    "    # df_train_test_merged = \"numeric\"\n",
    "    numerical_feature_names = \"character\",\n",
    "    non_numerical_feature_names = \"character\",\n",
    "    feature_names_num = \"character\",\n",
    "    feature_names_num_drop = \"character\",\n",
    "    is_one_hot_encoder = \"logical\",\n",
    "    is_with_log1p_SalePrice = \"logical\"\n",
    "    \n",
    "  ),\n",
    "  \n",
    "  # Set default values\n",
    "  prototype=list(\n",
    "    df = fread('/home/mizio/Documents/Kaggle/Titanic/train.csv', showProgress = T, data.table = FALSE),\n",
    "    df_test = fread('/home/mizio/Documents/Kaggle/Titanic/test.csv', showProgress = T, data.table = FALSE),\n",
    "    numerical_feature_names = c(),\n",
    "    non_numerical_feature_names = c(),\n",
    "    feature_names_num = c(),\n",
    "    feature_names_num_drop = c(),\n",
    "    is_one_hot_encoder = F,\n",
    "    is_with_log1p_SalePrice = F\n",
    "  )\n",
    ")\n",
    "\n",
    "setGeneric(name=\"merge_train_and_test_dataframe\",\n",
    "           def=function(theObject, df, df_test)\n",
    "           {\n",
    "             standardGeneric(\"merge_train_and_test_dataframe\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"merge_train_and_test_dataframe\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df, df_test)\n",
    "          {\n",
    "            # Remove classLabel (stored in y_train)\n",
    "            df$Survived <- NULL\n",
    "            # df_test$classLabel <- NULL\n",
    "            return(rbind(df, df_test))\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"drop_variable_before_preparation\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"drop_variable_before_preparation\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"drop_variable_before_preparation\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            # Drop features that have certain procentage of missing values considering the training data and test, \n",
    "            # since they will undergo imputation together.\n",
    "            # print(colSums(is.na(df)))\n",
    "            number_of_missing_values_in_features <- colSums(is.na(df))\n",
    "            features_with_many_missing_values <- character(0)\n",
    "            features_in_df <- names(df)\n",
    "            for(feature in features_in_df)\n",
    "            {\n",
    "              if(number_of_missing_values_in_features[[feature]] >= 0.3*nrow(df))  # 0.3*nrow(df))\n",
    "              {\n",
    "                features_with_many_missing_values <- append(features_with_many_missing_values, feature)\n",
    "              }\n",
    "            }\n",
    "            # print(features_with_many_missing_values)\n",
    "            df <- df[, !(names(df) %in% features_with_many_missing_values)]\n",
    "            features_to_drop <- c(\"Name\", \"PassengerId\", \"Cabin\", \"Ticket\")\n",
    "            df[, features_to_drop] <- NULL\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"clean_data\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"clean_data\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"clean_data\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            if(sum(is.na(df)) > 0)\n",
    "            {\n",
    "              is_with_MICE <- T\n",
    "              if(is_with_MICE)\n",
    "              {\n",
    "                # Imputation with MICE\n",
    "                set.seed(0)\n",
    "                df <- as.data.frame(df)\n",
    "                df_imputed <- complete(mice(df))  # method='rf'))\n",
    "              } else\n",
    "              {\n",
    "                # Remove all rows with NA values\n",
    "                df_imputed <- df[complete.cases(df),]\n",
    "              }\n",
    "              \n",
    "            }\n",
    "            return(df_imputed)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"numerical_feature_logical_incl_hidden_num\",\n",
    "           def=function(theObject, df, numerical_features)\n",
    "           {\n",
    "             standardGeneric(\"numerical_feature_logical_incl_hidden_num\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"numerical_feature_logical_incl_hidden_num\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df, numerical_features)\n",
    "          {\n",
    "            for(feature in rownames(numerical_features))\n",
    "            {\n",
    "              if(!numerical_features[feature,])\n",
    "              {\n",
    "                if(any(!is.na(as.numeric(unlist(strsplit(unlist(df[,feature]), \"[^0-9]+\"))))))\n",
    "                {\n",
    "                  numerical_features[feature,] = T\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "            return(numerical_features)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"numerical_feature_logical\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"numerical_feature_logical\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"numerical_feature_logical\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            # Numeric data types in R: 'numeric', 'integer'\n",
    "            numerical_features <- data.frame(logical(dim(df)[2]), row.names = names(df))\n",
    "            for(feature in rownames(numerical_features))\n",
    "            {\n",
    "              # if(class(df[, get(feature)]) == \"numeric\" || class(df[, get(feature)]) == \"integer\")\n",
    "              if(class(df[, feature]) == \"numeric\" || class(df[, feature]) == \"integer\")\n",
    "              {\n",
    "                numerical_features[feature,] = T\n",
    "              }\n",
    "            }\n",
    "            return(numerical_features)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"extract_numerical_features\",\n",
    "           def=function(theObject, numerical_features)\n",
    "           {\n",
    "             standardGeneric(\"extract_numerical_features\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"extract_numerical_features\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, numerical_features)\n",
    "          {\n",
    "            mask_index <- which(numerical_features$logical.dim.df..2..)\n",
    "            return(rownames(numerical_features)[mask_index])\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"extract_non_numerical_features\",\n",
    "           def=function(theObject, numerical_features)\n",
    "           {\n",
    "             standardGeneric(\"extract_non_numerical_features\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"extract_non_numerical_features\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, numerical_features)\n",
    "          {\n",
    "            mask_index <- which(numerical_features$logical.dim.df..2.. == F)\n",
    "            return(rownames(numerical_features)[mask_index])\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"encode_labels_in_numeric_format\",\n",
    "           def=function(theObject, df, feature)\n",
    "           {\n",
    "             standardGeneric(\"encode_labels_in_numeric_format\")\n",
    "           }\n",
    ")\n",
    "setMethod(f=\"encode_labels_in_numeric_format\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df, feature)\n",
    "          {\n",
    "            # Encode categorical features as integers\n",
    "            feature_name_num <- paste0(feature, 'Num', collapse='')\n",
    "            levels <- sort(unique(df[[feature]]))\n",
    "            df[[feature_name_num]] <- as.integer(factor(df[[feature]], levels=levels))\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"one_hot_encoder\",\n",
    "           def=function(theObject, df, feature)\n",
    "           {\n",
    "             standardGeneric(\"one_hot_encoder\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"one_hot_encoder\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df, feature)\n",
    "          {\n",
    "            levels <- sort(unique(df[[feature]]))\n",
    "            levels_num <- lapply(levels, function(x) paste0(feature, x, collapse=''))\n",
    "            feature_num <- paste0(feature, 'Num', collapse='')\n",
    "            ith <- 1\n",
    "            for(level in levels_num)\n",
    "            {\n",
    "              df[level] <- as.integer(df[feature_num] == ith)\n",
    "              ith <- ith + 1\n",
    "            }\n",
    "            \n",
    "            # df_all_dummy <- acm.disjonctif(df[feature])\n",
    "            # df[feature] <- NULL\n",
    "            # df <- cbind(df, df_all_dummy)\n",
    "            return(df)\n",
    "            \n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"feature_mapping_to_numerical_values\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"feature_mapping_to_numerical_values\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"feature_mapping_to_numerical_values\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            for(feature in theObject@non_numerical_feature_names)\n",
    "            {\n",
    "              if(feature == 'Embarked')\n",
    "              {\n",
    "                embarked_logical_NA <- df$Embarked == \"\"\n",
    "                df[which(embarked_logical_NA), feature] <- NA \n",
    "                \n",
    "              }\n",
    "              # Check that feature var consist of more than 3 labels before dummy labels are assigned\n",
    "              if(length(sort(unique(df[[feature]]))) > 2L)\n",
    "              {\n",
    "                df <- encode_labels_in_numeric_format(theObject, df, feature)\n",
    "                \n",
    "                if(theObject@is_one_hot_encoder)\n",
    "                {\n",
    "                  df <- one_hot_encoder(theObject, df, feature)\n",
    "                }\n",
    "              } else\n",
    "              {\n",
    "                feature_num <- paste0(feature, 'Num', collapse='')\n",
    "                df[, feature_num] <- as.integer(df[, feature] == sort(unique(df[[feature]]))[1])\n",
    "              }\n",
    "            }\n",
    "            \n",
    "            for(feature in theObject@numerical_feature_names)\n",
    "            {\n",
    "              # Check that feature var consist of more than 3 labels but less than 10 before dummy labels are assigned\n",
    "              if(length(sort(unique(df[[feature]]))) < 10L)\n",
    "              {\n",
    "                if(length(sort(unique(df[[feature]]))) > 2L)\n",
    "                {\n",
    "                  df <- encode_labels_in_numeric_format(theObject, df, feature)\n",
    "                  \n",
    "                  if(theObject@is_one_hot_encoder)\n",
    "                  {\n",
    "                    df <- one_hot_encoder(theObject, df, feature)\n",
    "                  }\n",
    "                } else\n",
    "                {\n",
    "                  feature_num <- paste0(feature, 'Num', collapse='')\n",
    "                  df[, feature_num] <- as.integer(df[, feature] == sort(unique(df[[feature]]))[1])\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "            \n",
    "            \n",
    "                        \n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"feature_names_num_drop\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"feature_names_num_drop\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"feature_names_num_drop\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            feature_names_num_drop <- vector(\"character\")\n",
    "            for(feature in theObject@feature_names_num)\n",
    "            {\n",
    "              if(length(sort(unique(df[[feature]]))) > 2L)\n",
    "              {\n",
    "                feature_names_num_drop <- c(feature_names_num_drop, feature)\n",
    "              }\n",
    "            }\n",
    "            return(feature_names_num_drop)\n",
    "          }\n",
    ")\n",
    "    \n",
    "    \n",
    "setGeneric(name=\"feature_names_num\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"feature_names_num\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"feature_names_num\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            feature_names_num <- vector(\"character\", length=length(theObject@non_numerical_feature_names))\n",
    "            ith <- 1\n",
    "            for(feature in theObject@non_numerical_feature_names)\n",
    "            {\n",
    "              feature_name_num <- paste0(feature, 'Num', collapse='')\n",
    "              feature_names_num[ith] <- feature_name_num\n",
    "              ith = ith + 1\n",
    "            }\n",
    "            \n",
    "            for(feature in theObject@numerical_feature_names)\n",
    "            {\n",
    "              if(length(sort(unique(df[[feature]]))) < 10L)\n",
    "              {\n",
    "                feature_names_num <- c(feature_names_num, paste0(feature, 'Num', collapse=''))\n",
    "              }\n",
    "            }\n",
    "            return(feature_names_num)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"drop_features_num\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"drop_features_num\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"drop_features_num\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            df <- df[, !(names(df) %in% theObject@feature_names_num_drop)]\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"get_is_one_hot_encoder\",\n",
    "           def=function(theObject)\n",
    "           {\n",
    "             standarGeneric(\"get_is_one_hot_encoder\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"get_is_one_hot_encoder\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject)\n",
    "          {\n",
    "            return(theObject@is_one_hot_encoder)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"set_is_one_hot_encoder\",\n",
    "           def=function(theObject, is_one_hot_encoder)\n",
    "           {\n",
    "             standarGeneric(\"set_is_one_hot_encoder\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"set_is_one_hot_encoder\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, is_one_hot_encoder)\n",
    "          {\n",
    "            theObject@is_one_hot_encoder <- is_one_hot_encoder\n",
    "            return(theObject)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"skew_correction\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"skew_correction\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"skew_correction\",\n",
    "          signature=c(\"Titanic\", \"data.frame\"),\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            skewed_feats <- lapply(df, function(x) skewness(x[!is.na(x)]))  # compute skewness\n",
    "            skewed_feats <- skewed_feats[skewed_feats > 0.75]\n",
    "            skewed_feats = names(skewed_feats)\n",
    "            df[, skewed_feats] <- log1p(df[skewed_feats])\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setMethod(f=\"skew_correction\",\n",
    "          signature=c(\"Titanic\", \"integer\"),\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            # browser()\n",
    "            is_skewed_feat <- skewness(df) > 0.75  # compute skewness\n",
    "            if(is_skewed_feat)\n",
    "            {\n",
    "              df <- log1p(df)\n",
    "            }\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"feature_engineering\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"feature_engineering\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"feature_engineering\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            is_skewness_correction_for_all_features <-  1\n",
    "            if(is_skewness_correction_for_all_features)\n",
    "            {\n",
    "              # Correcting for skewness\n",
    "              # Treat all numerical variables that were not one-hot encoded\n",
    "              numerical_feature_names_of_non_modified_df <- theObject@numerical_feature_names\n",
    "              if(!(theObject@is_one_hot_encoder))\n",
    "              {\n",
    "                numerical_feature_names_of_non_modified_df <- c(theObject@feature_names_num, \n",
    "                                                                numerical_feature_names_of_non_modified_df)\n",
    "              }\n",
    "              relevant_features <- numerical_feature_names_of_non_modified_df[(numerical_feature_names_of_non_modified_df %in% colnames(df))]\n",
    "              df[, relevant_features] <- skew_correction(theObject, df[, relevant_features])\n",
    "            } else\n",
    "            {\n",
    "              # Only scale down sale price and leave other numerical features standardized.\n",
    "              if(any(names(df) %in% 'SalePrice'))\n",
    "              {\n",
    "                df$SalePrice <- log1p(df$SalePrice)\n",
    "              }\n",
    "            }\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"feature_scaling\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"feature_scaling\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"feature_scaling\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            is_scaling_for_all_features <-  1\n",
    "            if(is_scaling_for_all_features)\n",
    "            {\n",
    "              # Correcting for skewness\n",
    "              # Treat all numerical variables that were not one-hot encoded\n",
    "              numerical_feature_names_of_non_modified_df <- theObject@numerical_feature_names\n",
    "              if(!(theObject@is_one_hot_encoder))\n",
    "              {\n",
    "                numerical_feature_names_of_non_modified_df <- c(theObject@feature_names_num, \n",
    "                                                                numerical_feature_names_of_non_modified_df)\n",
    "              }\n",
    "              relevant_features <- numerical_feature_names_of_non_modified_df[(numerical_feature_names_of_non_modified_df %in% colnames(df))]\n",
    "              df[, relevant_features] <- scale(df[, relevant_features])\n",
    "            } else\n",
    "            {\n",
    "              # Only scale down sale price and leave other numerical features standardized.\n",
    "              if(any(names(df) %in% 'SalePrice'))\n",
    "              {\n",
    "                df$SalePrice <- scale(df$SalePrice)\n",
    "              }\n",
    "            }\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"plot_histogram\",\n",
    "           def=function(theObject, df, feature_col_index)\n",
    "           {\n",
    "             standardGeneric(\"plot_histogram\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"plot_histogram\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df, feature_col_index)\n",
    "          {\n",
    "            return(ggplot(data=df[feature_col_index], aes(x=factor(df[[feature_col_index]]))) + \n",
    "                     stat_count() + xlab(colnames(df[feature_col_index])) + theme_light() + theme(axis.text.x=element_text(angle=90, hjust=1)))\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"plot_function\",\n",
    "           def=function(theObject, df, function_to_plot, feature_column_indices, ncol=2)\n",
    "           {\n",
    "             standardGeneric(\"plot_function\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"plot_function\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df, function_to_plot, feature_column_indices, ncol=2)\n",
    "          {\n",
    "            feature_plots <- list()\n",
    "            for(ite in feature_column_indices)\n",
    "            {\n",
    "              feature_plot <- function_to_plot(theObject, df=df, feature_col_index=ite)\n",
    "              feature_plots <- c(feature_plots, list(feature_plot))\n",
    "            }\n",
    "            do.call(\"grid.arrange\", c(feature_plots, ncol=ncol))\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"plot_density\",\n",
    "           def=function(theObject, df, feature_col_index, target_column_name)\n",
    "           {\n",
    "             standardGeneric(\"plot_density\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"plot_density\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df, feature_col_index, target_column_name)\n",
    "          {\n",
    "            # Todo: check if commented version has error\n",
    "            # df_to_plot <- data.frame(x=df[[feature_col_index]], SalePrice=df[, target_column_name])\n",
    "            # feature_plot <- ggplot(data=df_to_plot) + geom_line(aes(x=df[[feature_col_index]]), stat='Sale price density', size=1, alpha=1.0) +\n",
    "            #   xlab(paste0((colnames(df[[feature_col_index]])), '\\n', 'Skewness: ', round(skewness(df[[feature_col_index]], na.rm=T), 2))) +\n",
    "            #   theme_light()\n",
    "            feature_plot <- ggplot(data=df_to_plot) + geom_line(aes(x=x), stat='Sale price density', size=1, alpha=1.0) +\n",
    "              xlab(paste0((colnames(df[[feature_col_index]])), '\\n', 'Skewness: ', round(skewness(df[[feature_col_index]], na.rm=T), 2))) +\n",
    "              theme_light()\n",
    "            return(feature_plot)\n",
    "          }\n",
    ")\n",
    "\n",
    "setGeneric(name=\"extract_numerical_value_from_character\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"extract_numerical_value_from_character\")\n",
    "           }\n",
    "           )\n",
    "\n",
    "setMethod(f=\"extract_numerical_value_from_character\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            # Extract numerical value residing in character object using regex\n",
    "            for(feature in theObject@non_numerical_feature_names)\n",
    "            {\n",
    "              if(any(!is.na(as.numeric(unlist(strsplit(unlist(df[,feature]), \"[^0-9]+\"))))) && \n",
    "                 any(unlist(strsplit(unlist(df[,feature]), \"[^A-Z]+\")) == \"\" || unlist(strsplit(unlist(df[,feature]), \"[^A-Z]+\")) == \"NA\"))\n",
    "              {\n",
    "                df[,feature] <- as.numeric(gsub(\",\", \".\", gsub(\"\\\\.\", \"\", df[,feature])))\n",
    "              }\n",
    "            }\n",
    "            return(df)\n",
    "          }\n",
    "          )\n",
    "\n",
    "setGeneric(name=\"drop_features\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"drop_features\")\n",
    "           }\n",
    "           )\n",
    "\n",
    "setMethod(f=\"drop_features\",\n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            for(feature in theObject@numerical_feature_names)\n",
    "            {\n",
    "              if(length(sort(unique(df[[feature]]))) < 10L)\n",
    "              {\n",
    "                df[,feature] <- NULL\n",
    "              }\n",
    "            }\n",
    "            return(df)\n",
    "          }\n",
    "          )\n",
    "\n",
    "setGeneric(name=\"prepare_data\",\n",
    "           def=function(theObject, df)\n",
    "           {\n",
    "             standardGeneric(\"prepare_data\")\n",
    "           }\n",
    ")\n",
    "\n",
    "setMethod(f=\"prepare_data\", \n",
    "          signature=\"Titanic\",\n",
    "          definition=function(theObject, df)\n",
    "          {\n",
    "            df <- drop_variable_before_preparation(theObject, df)\n",
    "            numerical_feature_log <- numerical_feature_logical(theObject, df)\n",
    "            theObject@non_numerical_feature_names <- extract_non_numerical_features(theObject, numerical_feature_log)\n",
    "            df <- extract_numerical_value_from_character(theObject, df)\n",
    "            numerical_feature_log <- numerical_feature_logical(theObject, df)\n",
    "            theObject@non_numerical_feature_names <- extract_non_numerical_features(theObject, numerical_feature_log)\n",
    "            theObject@numerical_feature_names <- extract_numerical_features(theObject, numerical_feature_log)\n",
    "            \n",
    "            is_not_import_data <- 1\n",
    "            if(is_not_import_data)\n",
    "            {\n",
    "              theObject@feature_names_num <- feature_names_num(theObject, df)\n",
    "              df <- feature_mapping_to_numerical_values(theObject, df)\n",
    "              theObject@feature_names_num_drop <- feature_names_num_drop(theObject, df)\n",
    "              if(theObject@is_one_hot_encoder)\n",
    "              {\n",
    "                df <- drop_features_num(theObject, df)\n",
    "              }\n",
    "              df <- drop_features(theObject, df)\n",
    "              df <- feature_engineering(theObject, df)\n",
    "              df <- clean_data(theObject, df)\n",
    "              df <- feature_scaling(theObject, df)\n",
    "            }\n",
    "            return(df)\n",
    "          }\n",
    ")\n",
    "\n",
    "\n",
    "if(T)\n",
    "{\n",
    "  options(error=recover, show.error.locations=TRUE, warn=2)\n",
    "  \n",
    "  # Create instance of class\n",
    "  titanic <- Titanic()  # , is_with_log1p_SalePrice=T)\n",
    "  titanic@is_one_hot_encoder <- T\n",
    "  titanic@is_with_log1p_SalePrice <- F\n",
    "  \n",
    "  is.object(titanic)\n",
    "  isS4(titanic)\n",
    "  \n",
    "  # Create object to load data\n",
    "  df <- slot(titanic, \"df\") \n",
    "  df_test <- slot(titanic, \"df_test\")\n",
    "  \n",
    "  ## Prepare data\n",
    "  # Merge training and test data together\n",
    "  \n",
    "  y_train_prepared <- df$Survived\n",
    "  passengerId_df_test <- df_test$PassengerId\n",
    "  train_test_merged <- merge_train_and_test_dataframe(titanic, df, df_test)\n",
    "\n",
    "  is_kill_all_men <- 0\n",
    "  if(is_kill_all_men)\n",
    "  {\n",
    "    # Kill all men\n",
    "    all_male_logical <- df$Sex == 'male' \n",
    "    y_train_prepared[which(all_male_logical)] <- 0\n",
    "  }\n",
    "  \n",
    "    \n",
    "  # Number of rows in training data for later splitting\n",
    "  rows_in_train <- nrow(df)\n",
    "  train_test_merged_prepared <- prepare_data(titanic, train_test_merged)\n",
    "  \n",
    "  is_exclude_duplicates <- 0\n",
    "  if(is_exclude_duplicates)\n",
    "  {\n",
    "    df_unique <- unique(train_test_merged_prepared[1:rows_in_train,])\n",
    "    df_test_prep <- train_test_merged_prepared[(rows_in_train + 1):nrow(train_test_merged_prepared),]\n",
    "    train_test_merged_prepared <- rbind(df_unique, df_test_prep)\n",
    "    rows_in_train <- nrow(df_unique)\n",
    "  }\n",
    "  \n",
    "  # y_train_prepared <- train_test_merged_prepared[1:rows_in_train,]$classLabel\n",
    "  # y_test_prepared <- train_test_merged_prepared[(rows_in_train + 1):dim(train_test_merged_prepared)[1],]$classLabel\n",
    "\n",
    "  # Make repsentative data set by taking out 50/50 of \"yes.\" and \"no.\" samples.\n",
    "  is_50_50_distribution <- 0\n",
    "  if(is_50_50_distribution)\n",
    "  {\n",
    "    number_of_yes_train <- sum(y_train_prepared)  # 214\n",
    "    number_of_no_train <- length(y_train_prepared) - number_of_yes_train  # 276\n",
    "    yes_train_logical <- y_train_prepared == 1\n",
    "    yes_train_indices <- which(yes_train_logical)\n",
    "    no_train_indices <- which(!yes_train_logical)\n",
    "    if(number_of_yes_train < number_of_no_train)\n",
    "    {\n",
    "      no_train_indices <- no_train_indices[1:number_of_yes_train]\n",
    "    } else\n",
    "    {\n",
    "      yes_train_indices <- yes_train_indices[1:number_of_no_train]\n",
    "    }\n",
    "    extracted_50_50_indices <- sort(c(yes_train_indices, no_train_indices))\n",
    "    y_train_prepared <- y_train_prepared[extracted_50_50_indices]\n",
    "    df_prep <- train_test_merged_prepared[1:rows_in_train,]\n",
    "    df_test_prep <- train_test_merged_prepared[(rows_in_train + 1):nrow(train_test_merged_prepared),]\n",
    "    df_prep <- df_prep[extracted_50_50_indices,]\n",
    "    train_test_merged_prepared <- rbind(df_prep, df_test_prep)\n",
    "    rows_in_train <- nrow(df_prep)\n",
    "  }\n",
    "\n",
    "  is_get_unique_labels_of_test <- 1\n",
    "  if(is_get_unique_labels_of_test)\n",
    "  {\n",
    "    df_test_prep <- df_test\n",
    "    df_test_prep <- prepare_data(titanic, df_test_prep)\n",
    "    unique_feature_labels_test <- colnames(df_test_prep)\n",
    "    overlap_unique_features <- unique_feature_labels_test %in% colnames(train_test_merged_prepared)\n",
    "    unique_feature_labels_test <- unique_feature_labels_test[overlap_unique_features]\n",
    "    train_test_merged_prepared <- train_test_merged_prepared[, unique_feature_labels_test]\n",
    "  }else\n",
    "  {\n",
    "    train_test_merged_prepared$classLabel <- NULL\n",
    "  }\n",
    "\n",
    "  # Extracting numerical feature columns\n",
    "  train_test_merged_numerical_feature_log <- numerical_feature_logical(titanic, train_test_merged)\n",
    "  train_test_merged_numerical_feature_log_hidden_nums <- numerical_feature_logical_incl_hidden_num(titanic, df, train_test_merged_numerical_feature_log)\n",
    "  train_test_merged_non_numerical_features <- extract_non_numerical_features(titanic, train_test_merged_numerical_feature_log_hidden_nums)\n",
    "\n",
    "  train_test_merged_prepared_numerical_feature_log <- numerical_feature_logical(titanic, train_test_merged_prepared)\n",
    "  train_test_merged_prepared_numerical_features <- extract_numerical_features(titanic, train_test_merged_prepared_numerical_feature_log)\n",
    "  # Extracting non numerical feature columns\n",
    "  train_test_merged_prepared_non_numerical_features <- extract_non_numerical_features(titanic, train_test_merged_prepared_numerical_feature_log)\n",
    "  train_test_merged_prepared_only_categorical <- train_test_merged_prepared[, train_test_merged_prepared_non_numerical_features]\n",
    "  train_test_merged_prepared <- train_test_merged_prepared[, train_test_merged_prepared_numerical_features]\n",
    "  \n",
    "  # Splitting merged data set\n",
    "  x_train <- train_test_merged_prepared[1:rows_in_train,]\n",
    "  x_test <- train_test_merged_prepared[(rows_in_train + 1):nrow(train_test_merged_prepared),]\n",
    "  \n",
    "  # Casting all types to numeric type (also integer)\n",
    "  x_train[] <- lapply(x_train, as.numeric)\n",
    "  x_test[] <- lapply(x_test, as.numeric)\n",
    "  \n",
    "  is_explore_data <- T\n",
    "  if(is_explore_data)\n",
    "  {\n",
    "    # Information of df before preperation\n",
    "    print(as.data.frame(sort(sapply(train_test_merged, function(x) sum(is.na(x))), decreasing = TRUE)))\n",
    "    # print(colSums(is.na(train_test_merged)))\n",
    "    # print(summary(train_test_merged))\n",
    "    str(train_test_merged)\n",
    "    print(as.data.frame(colnames(train_test_merged)))\n",
    "    unique(train_test_merged$classLabel)\n",
    "    \n",
    "    # Check df after preparation\n",
    "    print('After preperation =================')\n",
    "    print(as.data.frame(colnames(train_test_merged_prepared)))\n",
    "    # print(colSums(is.na(train_test_merged_prepared)))\n",
    "    # print(summary(train_test_merged_prepared))\n",
    "    \n",
    "    cat('Train has', dim(df)[1], 'rows and', dim(df)[2], 'columns.', '\\n')\n",
    "    cat('Test has', dim(df_test)[1], 'rows and', dim(df_test)[2], ' columns.')\n",
    "    \n",
    "    # The percentage of data missing in train.\n",
    "    cat('The percentage of data missing in train', sum(is.na(df)) / (nrow(df) *ncol(df)), '\\n')\n",
    "    \n",
    "    # The percentage of data missing in test.\n",
    "    cat('The percentage of data missing in test', sum(is.na(df_test)) / (nrow(df_test) * ncol(df_test)), '\\n')\n",
    "    \n",
    "    # Check if any duplicate rows\n",
    "    cat(\"The number of row duplicates:\", nrow(df) - nrow(unique(df)), '\\n')\n",
    "    \n",
    "    # Check how distributions change after imputation\n",
    "    # Plot LotFrontage price distributions\n",
    "    # par(mfrow=c(1,2))\n",
    "    # hist(train_test_merged$v18, freq=F, main='v18: Original Data', \n",
    "    #      col='darkgreen')\n",
    "    # hist(train_test_merged_prepared$v18, freq=F, main='v18: Mice Imputed Data', \n",
    "    #      col='lightgreen')\n",
    "    \n",
    "    # Check how distributions change after imputation\n",
    "    # Plot LotFrontage price distributions\n",
    "    par(mfrow=c(1,2))\n",
    "    hist(y_train_prepared, freq=F, main='classlabel: Original Data', \n",
    "         col='darkgreen')\n",
    "    # hist(y_train_prepared, freq=F, main='classlabel: skewness corrected Data', \n",
    "    #      col='lightgreen')\n",
    "    \n",
    "    # Plot GarageYrBlt price distributions\n",
    "    # par(mfrow=c(1,2))\n",
    "    # hist(train_test_merged$v39, freq=F, main='GarageYrBlt: Original Data', \n",
    "    #      col='darkgreen')\n",
    "\n",
    "    is_clustering <- 0\n",
    "    if(is_clustering)\n",
    "    {\n",
    "      hel =1\n",
    "      # train_test_merged_prepared_clustered <- varclus(x_train, similarity=\"spearman\", minlev=0.05)\n",
    "      # train_test_merged_prepared_clustered <- varclus(as.matrix(train_test_merged_prepared), similarity=\"spearman\", minlev=0.05)\n",
    "      # plot(train_test_merged_prepared_clustered, cex=0.5)\n",
    "    }\n",
    "    \n",
    "    is_categorical_feature_plots <- T\n",
    "    if(is_categorical_feature_plots)\n",
    "    {\n",
    "      # Todo: implement categorical feature plots\n",
    "      \n",
    "      #Bar plots\n",
    "      # Categorical features are in total 38\n",
    "      plot_function(titanic, df[, train_test_merged_non_numerical_features], plot_histogram, 2, 2)\n",
    "      # plot_function(titanic, df[, train_test_merged_non_numerical_features], plot_histogram, 5:8, 2)\n",
    "      # plot_function(titanic, df[, train_test_merged_non_numerical_features], plot_histogram, 9:11, 2)\n",
    "      # plot_function(titanic, df[, train_test_merged_prepared_non_numerical_features], plot_histogram, 14, 2)\n",
    "      # plot_function(titanic, df[, train_test_merged_prepared_non_numerical_features], plot_histogram, 14:17, 2)\n",
    "      # plot_function(titanic, df[, train_test_merged_prepared_non_numerical_features], plot_histogram, 18:21, 2)\n",
    "    }  \n",
    "  }\n",
    "  \n",
    "  is_test_functions <- F\n",
    "  if(is_test_functions)\n",
    "  {\n",
    "    # Testing functions\n",
    "    # numerical_feature_log <- numerical_feature_logical(titanic, df)\n",
    "    # df_num <- extract_numerical_features(titanic, numerical_feature_log)\n",
    "  }\n",
    "  \n",
    "  is_make_prediction <- 1\n",
    "  if(is_make_prediction)\n",
    "  {\n",
    "    # Using sparse matrices\n",
    "    # x_train_sp <- as(as.matrix(x_train), \"sparseMatrix\")\n",
    "    # x_test_sp <- as(as.matrix(x_test), \"sparseMatrix\")\n",
    "    x_train <- as.matrix(x_train)\n",
    "    x_test <- as.matrix(x_test)\n",
    "    \n",
    "    is_xgb_cv <- T\n",
    "    if(is_xgb_cv)\n",
    "    {\n",
    "      # --- xgboost ---\n",
    "      save_path <- '/home/mizio/Documents/Kaggle/Titanic/titanic_R_git_clone_0/'\n",
    "      # dtrain <- xgb.DMatrix(x_train[1:dim(x_test)[1],], label=y_train_prepared[1:dim(x_test)[1]])\n",
    "      dtrain <- xgb.DMatrix(x_train, label=y_train_prepared)\n",
    "      dtest <- xgb.DMatrix(x_test)\n",
    "      # dtrain <- xgb.DMatrix(x_test, label=y_test_prepared)\n",
    "      # dtest <- xgb.DMatrix(x_train, label=y_train_prepared)\n",
    "      \n",
    "      # Saving xgb.DMatrix\n",
    "      xgb.DMatrix.save(dtrain, paste0(save_path, \"dtrain.buffer\", collapse=''))\n",
    "      xgb.DMatrix.save(dtest, paste0(save_path, \"dtest.buffer\", collapse=''))\n",
    "      # Loading xgb.DMatrix\n",
    "      # dtrain2 <- xgb.DMatrix(paste0(save_path, \"dtrain.buffer\", collapse=''))\n",
    "      # dtest2 <-  xgb.DMatrix(paste0(save_path, \"dtest.buffer\", collapse=''))\n",
    "      \n",
    "      # Params aggressive and prone to overfitting\n",
    "      # xgb_params <- list(\n",
    "      #   seed = 0,\n",
    "      #   colsample_bytree = 0.8,\n",
    "      #   silent = 1,\n",
    "      #   subsample = 0.6,\n",
    "      #   # learning_rate = 0.01,\n",
    "      #   eta = 0.06,  # low value means it is more robust to overfitting\n",
    "      #   # objective = 'reg:linear',\n",
    "      #   max_depth = 15,\n",
    "      #   num_parallel_tree = 1,\n",
    "      #   # alpha = 1,\n",
    "      #   gamma = 0,\n",
    "      #   min_child_weight = 0.1,\n",
    "      #   eval_metric = 'rmse',\n",
    "      #   booster = 'gbtree'\n",
    "      #   # booster = 'gblinear'\n",
    "      # )\n",
    "      \n",
    "      # Params conservative\n",
    "      # xgb_params <- list(\n",
    "      #   seed = 0,\n",
    "      #   colsample_bytree = 0.8,\n",
    "      #   silent = 1,\n",
    "      #   subsample = 0.6,\n",
    "      #   # learning_rate = 0.01,\n",
    "      #   eta = 0.02,  # low value means it is more robust to overfitting\n",
    "      #   # objective = 'reg:linear',\n",
    "      #   max_depth = 10,\n",
    "      #   num_parallel_tree = 100,\n",
    "      #   # alpha = 1,\n",
    "      #   gamma = 0,\n",
    "      #   min_child_weight = 1,\n",
    "      #   eval_metric = 'rmse',\n",
    "      #   booster = 'gbtree'\n",
    "      #   # booster = 'gblinear'\n",
    "      # )\n",
    "      \n",
    "      # Params classification problem\n",
    "      my_etas <- list(eta=c(10^(-6:0)))\n",
    "      my_gammas <- list(gamma=c((1:10)*0.1))\n",
    "      my_max_depths <- list(max_depth=c(1:10))\n",
    "      my_min_child_weights <- list(min_child_weight=c((1:10)*0.1))\n",
    "      my_subsamples <- list(subsample=c((1:10)*0.1))\n",
    "      my_colsample_bytree <- list(colsample_bytree=c((1:10)*0.1))\n",
    "      my_num_parallel_tree <- list(num_parallel_tree=c(1:10))\n",
    "      # nrounds <- length(my_num_parallel_tree$num_parallel_tree)\n",
    "      nrounds <- 10000\n",
    "      xgb_params <- list(\n",
    "        seed = 1,\n",
    "        colsample_bytree = my_colsample_bytree$colsample_bytree[3],\n",
    "        silent = 1,\n",
    "        subsample = my_subsamples$subsample[3],\n",
    "        # max_delta_step = 10,\n",
    "        eta = my_etas$eta[5],  # low value means it is more robust to overfitting\n",
    "        objective = \"binary:logistic\",\n",
    "        # objective = \"binary:logitraw\",  # not good\n",
    "        # objective = \"reg:logistic\",\n",
    "        max_depth = my_max_depths$max_depth[6],\n",
    "        num_parallel_tree = 1,  # my_num_parallel_tree$num_parallel_tree[2],\n",
    "        gamma = my_gammas$gamma[7], # minimum loss reduction required to make a further partition on a leaf node of the tree. the larger, the more conservative the algorithm will be\n",
    "        min_child_weight = my_min_child_weights$min_child_weight[2], # large => conservative\n",
    "        # eval_metric = \"auc\",\n",
    "        # eval_metric = \"error\",\n",
    "        # eval_metric = \"logloss\"\n",
    "        booster = 'gbtree'\n",
    "        # booster = 'gblinear'\n",
    "      )\n",
    "      \n",
    "      # xgb <- xgboost(data = as.matrix(x_train), \n",
    "      #                label = y_train_prepared, \n",
    "      #                eta = 0.01,\n",
    "      #                max_depth = 15, \n",
    "      #                nround=25, \n",
    "      #                subsample = 0.5,\n",
    "      #                colsample_bytree = 0.5,\n",
    "      #                seed = 1,\n",
    "      #                # eval_metric = \"merror\",\n",
    "      #                # objective = \"multi:softprob\",\n",
    "      #                objective = \"reg:logistic\",\n",
    "      #                # num_class = 12,\n",
    "      #                nthread = 3\n",
    "      # )\n",
    "      \n",
    "      # Classification problem\n",
    "      xgb_cv <- xgb.cv(xgb_params, data=dtrain, nrounds=nrounds, nfold=5, stratified=F, early_stopping_rounds=250, verbose=2)\n",
    "      # bst <- xgboost(data = dtrain, max_depth = 6, eta = 0.001, nrounds = 2, objective = \"binary:logistic\", verbose = 2)\n",
    "      # xgboost(data = dtrain, max_depth = 6, eta = 0.2, nrounds = 20, objective = \"binary:logistic\", verbose = 2)\n",
    "      \n",
    "      # xgb_cv <- xgb.cv(xgb_params, dtrain, nrounds=1000, nfold=5, stratified=F, early_stopping_rounds=100, verbose=2)\n",
    "      \n",
    "      best_nrounds <- xgb_cv$best_ntreelimit\n",
    "      \n",
    "      # Measure learning progress while building the model\n",
    "      set.seed(3410)\n",
    "      train_partition_index <- createDataPartition(y_train_prepared, p=0.8, list=F, times=1)\n",
    "      dtrain_bench = dtrain[train_partition_index,]\n",
    "      test_partition_index <- vector(\"logical\", length=length(y_train_prepared))\n",
    "      # test_partition_index[train_partition_index] <- T\n",
    "      test_partition_index <- which(!test_partition_index)\n",
    "      dtest_bench = dtrain[test_partition_index,]\n",
    "      # watchlist <- list(train=dtrain_bench, test=dtest_bench)\n",
    "      watchlist <- list(train=dtrain)#, test=dtest)\n",
    "      \n",
    "      # gbdt <- xgb.train(xgb_params, dtrain, nrounds=as.integer(best_nrounds))\n",
    "      # gs <- xgb.train(data=dtest_bench, max_depth=2, eta=0.02, nrounds=nrounds, watchlist=watchlist, objective = \"binary:logistic\")\n",
    "      gbdt <- xgb.train(params=xgb_params, data=dtrain, watchlist=watchlist, nrounds=as.integer(best_nrounds), print_every_n=1L, early_stopping_rounds=250)\n",
    "      # gbdt <- xgb.train(params=xgb_params, data=dtrain, watchlist=watchlist, nrounds=nrounds, print_every_n=1L, early_stopping_rounds=400)\n",
    "      \n",
    "      # gbdt <- xgb.train(xgb_params, data=dtrain, watchlist=watchlist, print_every_n=1, early_stopping_rounds=35, nrounds=nrounds,\n",
    "      #                   callbacks=list(cb.reset.parameters(my_num_parallel_tree)))\n",
    "      # gbdt <- xgb.train(xgb_params, dtrain, nrounds=as.integer(best_nrounds))\n",
    "      output_xgb_cv <- predict(gbdt, dtest)\n",
    "      output <- output_xgb_cv\n",
    "      \n",
    "      # Information from xgb.DMatrix\n",
    "      # label <- getinfo(dtest, \"label\")\n",
    "      # Only makes sense for binary classification where output is {0, 1}\n",
    "      # as.numeric(pred > 0.5) applies our rule that when the probability (<=> regression <=> prediction) \n",
    "      # is > 0.5 the observation is classified as 1 and 0 otherwise \n",
    "      # err <- as.numeric(sum(as.integer(output_xgb_cv > 0.5) != label))/length(label)\n",
    "      # print(paste(\"Custom test-error=\", err))\n",
    "      \n",
    "      # Feature importance\n",
    "      importance_matrix <- xgb.importance(feature_names=colnames(dtrain), model=gbdt)\n",
    "      print(head(importance_matrix))\n",
    "      # head(importance_matrix, 10)[[\"Feature\"]]\n",
    "      plot.new()\n",
    "      xgb.plot.importance(importance_matrix=importance_matrix)\n",
    "      # top_10_features <- head(importance_matrix, 10)[[\"Feature\"]]\n",
    "      # top_10_features <- colnames(dtrain)\n",
    "      # Deeper analysis of features\n",
    "      # importance_raw <- xgb.importance(feature_names=colnames(dtrain), model=gbdt, data=x_train, label=getinfo(dtrain, 'label'))\n",
    "      # importance_clean <- importance_raw[,`:=`(Cover=NULL, Frequency=NULL)]\n",
    "      # head(importance_clean)\n",
    "      \n",
    "      # Checking Chi^2 between features. Higher means more correlated\n",
    "      # chi2 <- chisq.test(x_train$OverallQual, y_train_prepared)\n",
    "      # print(chi2)\n",
    "      # chi2 <- chisq.test(x_train$GrLivArea)\n",
    "      # print(chi2)\n",
    "      \n",
    "      # Trees from model\n",
    "      # xgb.plot.tree(model=gbdt)\n",
    "    }\n",
    "    \n",
    "    # Todo: implement Regularized linear models (lasso, ridge)\n",
    "  }\n",
    "  \n",
    "  is_make_submission <- 1\n",
    "  if(is_make_submission && is_make_prediction)\n",
    "  {\n",
    "    name <- 'submission.csv'\n",
    "    # submission <- fread(paste0(save_path, name, collapse=''), colClasses=c(\"integer\", \"numeric\"))\n",
    "    submission <- data.frame(Survived=as.integer(output > 0.5))\n",
    "    # submission[which(submission$classLabel == 1L),] <- sort(unique(df_test$classLabel))[1]\n",
    "    # submission[which(submission$classLabel == 0),] <- sort(unique(df_test$classLabel))[2]\n",
    "    \n",
    "    if(is_make_prediction && is_xgb_cv)\n",
    "    {\n",
    "      # save model to binary local file\n",
    "      xgb.save(gbdt, paste0(save_path, \"xgboost.model\", collapse=''))\n",
    "      \n",
    "      # Test to see how identical our saved model is to the original by comparison of two predictions\n",
    "      # load binary model to R\n",
    "      # bst2 <- xgb.load(paste0(save_path, \"model_to_compare_xgboost.model\", collapse=''))\n",
    "      # pred2 <- predict(bst2, dtest)\n",
    "      \n",
    "      # And now the test\n",
    "      # print(paste(\"sum(abs(pred2 - pred))=\", sum(abs(pred2 - output_xgb_cv))))\n",
    "    }\n",
    "    \n",
    "    submission$PassengerId <- passengerId_df_test\n",
    "    write.csv(submission[, c(2,1)], paste0(save_path, name, collapse=''), row.names=F)\n",
    "  }\n",
    "  \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
